{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a1b731-b850-4b3c-ac62-2d46becc1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ml_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab8f960e-454b-4a6e-9e93-f7e721a531e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def awgn(signal, SNR, measured=False, return_true_snr=False):\n",
    "    \n",
    "    if measured:\n",
    "        # Measure signal power \n",
    "        s_p = np.mean(abs(signal)**2)\n",
    "    else:\n",
    "        s_p = 1\n",
    "    \n",
    "    # Calculate noise power\n",
    "    n_p = s_p/(10 **(SNR/10))\n",
    "    \n",
    "    # Generate complex noise\n",
    "    noise = np.sqrt(n_p/2)*(np.random.randn(*signal.shape) + \\\n",
    "                                np.random.randn(*signal.shape)*1j)\n",
    "    \n",
    "    # Add signal and noise \n",
    "    signal_noisy = signal + noise \n",
    "    \n",
    "    if not return_true_snr:\n",
    "        return signal_noisy\n",
    "    else:\n",
    "        return signal_noisy, s_p/(np.mean(abs(noise)**2))\n",
    "    \n",
    "def pulse_shape(symbols, sps=5):\n",
    "    num_weights = 251\n",
    "    x = np.arange(-int(num_weights/2),int(num_weights/2)+1,1)/sps\n",
    "    sinc_weights = np.sinc(x)\n",
    "    \n",
    "    padded_symbols = np.zeros(len(symbols)*sps, dtype=complex)\n",
    "    padded_symbols[np.arange(0,len(padded_symbols),sps)] = symbols\n",
    "    \n",
    "    return np.convolve(padded_symbols, sinc_weights, mode='same')\n",
    "\n",
    "# Function to generate BPSK\n",
    "def generate_bpsk(num_symbols, noise=50):\n",
    "    bits = np.random.randint(0,2,num_symbols)\n",
    "    bpsk_scheme = [1+0j, -1+0j]\n",
    "    bpsk_symbols = np.array([bpsk_scheme[i] for i in bits])\n",
    "    \n",
    "    bpsk_symbols = awgn(bpsk_symbols, noise)\n",
    "    \n",
    "    return bpsk_symbols\n",
    "\n",
    "# Function to generate QPSK\n",
    "def generate_qpsk(num_symbols, noise=50):\n",
    "    qpsk_scheme= [1+1j, 1-1j, -1+1j, -1-1j]\n",
    "    ints = np.random.randint(0,4,num_symbols)\n",
    "    qpsk_symbols = np.array([qpsk_scheme[i] for i in ints])/np.sqrt(2)\n",
    "    \n",
    "    return qpsk_symbols\n",
    "\n",
    "# Function to generate QAM\n",
    "def generate_qam(num_symbols, noise=50):\n",
    "    qam_scheme = [-3-3j, -3-1j, -3+3j, -3+1j,  \\\n",
    "                  -1-3j, -1-1j, -1+3j, -1+1j,  \\\n",
    "                   3-3j,  3-1j,  3+3j,  3+1j,  \\\n",
    "                   1-3j,  1-1j,  1+3j,  1+1j]\n",
    "    ints = np.random.randint(0,16,num_symbols)\n",
    "    qam_symbols = np.array([qam_scheme[i] for i in ints])\n",
    "    qam_symbols = qam_symbols/np.mean(np.abs(qam_scheme))\n",
    "    \n",
    "    return qam_symbols\n",
    "\n",
    "# Function to generate 4-ASK\n",
    "def generate_ask4(num_symbols, noise=50):\n",
    "    ask4_scheme = [3+0j, 1+0j, -1+0j, -3+0j]\n",
    "    ints = np.random.randint(0,4,num_symbols)\n",
    "    ask4_symbols = np.array([ask4_scheme[i] for i in ints])\n",
    "    ask4_symbols = ask4_symbols/np.mean(np.abs(ask4_scheme))\n",
    "    \n",
    "    return ask4_symbols\n",
    "\n",
    "# Function to generate 8-PSK\n",
    "def generate_psk8(num_symbols, noise=50):\n",
    "    psk8_scheme = [ 1+0j, 0.7071+0.7071j, 0+1j, -0.7071+0.7071j, \\\n",
    "                   -1+0j, -0.7071-0.7071j, 0-1j, 0.7071-0.7071j]\n",
    "    \n",
    "    ints = np.random.randint(0,8,num_symbols)\n",
    "    psk8_symbols = np.array([psk8_scheme[i] for i in ints])\n",
    "    psk8_symbols = psk8_symbols/np.mean(np.abs(psk8_scheme))\n",
    "    \n",
    "    return psk8_symbols\n",
    "\n",
    "def gen_tensor_data(mod_scheme, num_frames=32, samples_per_frame=128, sps=5, snr=30):\n",
    "            \n",
    "    symbols_required = int(np.ceil(samples_per_frame/sps))*num_frames\n",
    "        \n",
    "    # Mod scheme has to be one of: 'BPSK', 'QPSK', '16-QAM'\n",
    "    if mod_scheme == 'BPSK':\n",
    "        symbols = pulse_shape(generate_bpsk(symbols_required), sps=sps)[:num_frames*samples_per_frame]\n",
    "    elif mod_scheme == 'QPSK':\n",
    "        symbols = pulse_shape(generate_qpsk(symbols_required), sps=sps)[:num_frames*samples_per_frame]\n",
    "    elif mod_scheme == '8-PSK':\n",
    "        symbols = pulse_shape(generate_psk8(symbols_required), sps=sps)[:num_frames*samples_per_frame]\n",
    "    elif mod_scheme == '16-QAM':\n",
    "        symbols = pulse_shape(generate_qam(symbols_required), sps=sps)[:num_frames*samples_per_frame]\n",
    "    elif mod_scheme == '4-ASK':\n",
    "        symbols = pulse_shape(generate_ask4(symbols_required), sps=sps)[:num_frames*samples_per_frame]\n",
    "\n",
    "    # Add noise and split into frames\n",
    "    frames, sn = awgn(symbols.reshape(num_frames,-1), snr, measured=True, return_true_snr=True)\n",
    "\n",
    "    # Normalize to unit energy per frame\n",
    "    for i, frame in enumerate(frames):\n",
    "        power = np.mean((np.abs(frame)))\n",
    "        frames[i] = frame / power\n",
    "\n",
    "    # Split into I/Q, add extra channel to make a 4-D tensor\n",
    "    return torch.FloatTensor(np.stack((frames.real, frames.imag),axis=1)), sn\n",
    "\n",
    "def gen_data_from_list(mod_scheme, snr_range, num_frames=32, samples_per_frame=128, return_db=False):\n",
    "    \n",
    "    # total dataset size\n",
    "    frames = torch.zeros((num_frames*len(snr_range), 2, samples_per_frame), dtype=torch.float)\n",
    "    \n",
    "    # snrs dataset for multitask\n",
    "    snrs = torch.zeros(num_frames*len(snr_range), dtype=torch.float)\n",
    "    \n",
    "    for i, snr in enumerate(snr_range):\n",
    "        frames[i*num_frames:(i+1)*num_frames], sn = gen_tensor_data(mod_scheme, num_frames=num_frames, samples_per_frame=samples_per_frame, snr=snr)\n",
    "        if return_db:\n",
    "            snrs[i*num_frames:(i+1)*num_frames] = snr\n",
    "        else:\n",
    "            snrs[i*num_frames:(i+1)*num_frames] = sn\n",
    "    \n",
    "    return frames, snrs\n",
    "\n",
    "# Function returns a torch dataloader with specified batch_size and num_frames\n",
    "# number of examples per snr level\n",
    "def gen_loader(num_frames=32, samples_per_frame=1024, snr=[30], batch_size=32, case=1, return_db=False):\n",
    "    \n",
    "    if case == 1 or case == 2:\n",
    "        return_db=True\n",
    "    \n",
    "    # Generate the individual waveforms for each modulation scheme\n",
    "    bpsk_data, bpsk_snrs = gen_data_from_list('BPSK', snr, num_frames=num_frames, samples_per_frame=samples_per_frame, return_db=return_db)\n",
    "    qpsk_data, qpsk_snrs = gen_data_from_list('QPSK', snr, num_frames=num_frames, samples_per_frame=samples_per_frame, return_db=return_db)\n",
    "    psk_data, psk_snrs = gen_data_from_list('8-PSK', snr, num_frames=num_frames, samples_per_frame=samples_per_frame, return_db=return_db)\n",
    "    qam_data, qam_snrs = gen_data_from_list('16-QAM', snr, num_frames=num_frames, samples_per_frame=samples_per_frame, return_db=return_db)\n",
    "    ask_data, ask_snrs = gen_data_from_list('4-ASK', snr, num_frames=num_frames, samples_per_frame=samples_per_frame, return_db=return_db)\n",
    "    \n",
    "    # Concat them into a single training data tensor\n",
    "    train_data = torch.cat((bpsk_data, qpsk_data, psk_data, qam_data, ask_data))\n",
    "    \n",
    "    # Create class labels\n",
    "    bpsk_labels = torch.zeros(bpsk_data.shape[0])\n",
    "    qpsk_labels = torch.ones(qpsk_data.shape[0])\n",
    "    psk_labels = torch.ones(psk_data.shape[0])*2\n",
    "    qam_labels = torch.ones(qam_data.shape[0])*3\n",
    "    ask_labels = torch.ones(ask_data.shape[0])*4\n",
    "\n",
    "    # Concat class labels\n",
    "    # We will be using cross entropy loss, which expects a long tensor as the label hence the .long() here\n",
    "    train_labels = torch.cat((bpsk_labels, qpsk_labels, psk_labels, qam_labels, ask_labels)).long()\n",
    "    \n",
    "    # SNR labels\n",
    "    snr_labels = torch.cat((bpsk_snrs, qpsk_snrs, psk_snrs, qam_snrs, ask_snrs))\n",
    "    \n",
    "    if case == 0 or case == 1: \n",
    "#         snr_labels[snr_labels > 10] = 10\n",
    "        train_labels_snr = snr_labels # case 0 returns linear snrs, case 1 returns dBs\n",
    "    elif case == 2:\n",
    "        snr_db_labels = snr_labels.numpy().astype(int)\n",
    "        train_snr_range = np.arange(-15,16,2, dtype=int)\n",
    "        snr_indexes = {index:value for index, value in zip(train_snr_range, np.arange(len(train_snr_range)))}\n",
    "        train_labels_snr = torch.tensor(list(map(lambda label: snr_indexes[label], snr_db_labels)), dtype=int)\n",
    "    \n",
    "    # if gpu\n",
    "    train_data = train_data.cuda()\n",
    "    train_labels = train_labels.cuda()\n",
    "    train_labels_snr = train_labels_snr.cuda()\n",
    "    \n",
    "    # Create a Torch dataset\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_data, train_labels, train_labels_snr)\n",
    "    \n",
    "    return torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c2913d-4b51-4409-b886-1a4a1aa602af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class amc_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(amc_model, self).__init__()\n",
    "        \n",
    "        # 3 conv layers with a 9 sample wide kernel and padding so that the\n",
    "        # size of the output remains consistent with the input for each layer\n",
    "        self.convolutions = nn.Sequential(\n",
    "                    nn.Conv1d(2, 64, 3, padding=1),\n",
    "                    nn.MaxPool1d(2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv1d(64, 64, 3, padding=1),\n",
    "                    nn.MaxPool1d(2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv1d(64, 64, 3, padding=1),\n",
    "                    nn.MaxPool1d(2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv1d(64, 64, 3, padding=1),\n",
    "                    nn.MaxPool1d(2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv1d(64, 64, 3, padding=1),\n",
    "                    nn.MaxPool1d(2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv1d(64, 64, 3, padding=1),\n",
    "                    nn.MaxPool1d(2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv1d(64, 64, 3, padding=1),\n",
    "                    nn.MaxPool1d(2),\n",
    "                    nn.ReLU()\n",
    "                    )\n",
    "        \n",
    "        # 128 samples x 16 output filters x 2 channels (I/Q) = 4096\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Extract features with convolutional layers\n",
    "        x = self.convolutions(x)\n",
    "        \n",
    "        # Flatten so it's compatible with fully connected layers for classification\n",
    "        x = torch.flatten(x,1)\n",
    "#         print(x.shape)\n",
    "        \n",
    "#         First fully connected layer\n",
    "        x = F.selu(self.fc1(x))\n",
    "        \n",
    "        # Final layer responsible for classifying the 5 modulation schemes\n",
    "        x = F.selu(self.fc2(x))\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fbb8015-c67d-42fc-bb82-407d49bf529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, loss_fn, num_epochs=5, verbose=False):\n",
    "    losses, val_losses = [], []\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        \n",
    "        for x, y, _ in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss = loss_fn(y_hat,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        losses.append(running_loss/len(train_loader))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            running_val_loss = 0\n",
    "            for x, y, _ in val_loader:\n",
    "                y_hat = model(x)\n",
    "                \n",
    "                val_loss = loss_fn(y_hat, y)\n",
    "                running_val_loss += val_loss.item()\n",
    "            val_losses.append(running_val_loss/len(val_loader))\n",
    "        \n",
    "        if val_losses[-1] < best_loss:\n",
    "            print(f'val_losses[-1] = {val_losses[-1]}, best_loss = {best_loss}, model saved at {epoch}')\n",
    "            saved_model = model.state_dict()\n",
    "            best_loss = val_losses[-1]\n",
    "            \n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Loss: {losses[-1]}, Val loss: {val_losses[-1]}\")\n",
    "            \n",
    "    model.load_state_dict(saved_model)\n",
    "    \n",
    "    return model, losses, val_losses\n",
    "\n",
    "def test_model(model, snr_range, samples_per_frame=128, num_frames=512):\n",
    "    accs = []\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    model.eval().cpu()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for snr in snr_range:\n",
    "\n",
    "            bpsk_data, _ = gen_tensor_data('BPSK', num_frames=num_frames, samples_per_frame=samples_per_frame, snr=snr)\n",
    "            qpsk_data, _ = gen_tensor_data('QPSK', num_frames=num_frames, samples_per_frame=samples_per_frame, snr=snr)\n",
    "            psk_data, _ = gen_tensor_data('8-PSK', num_frames=num_frames, samples_per_frame=samples_per_frame, snr=snr)\n",
    "            qam_data, _ = gen_tensor_data('16-QAM', num_frames=num_frames, samples_per_frame=samples_per_frame, snr=snr)\n",
    "            ask_data, _ = gen_tensor_data('4-ASK', num_frames=num_frames, samples_per_frame=samples_per_frame, snr=snr)\n",
    "\n",
    "            test_data = torch.cat((bpsk_data, qpsk_data, psk_data, qam_data, ask_data))\n",
    "\n",
    "            bpsk_labels = torch.zeros(bpsk_data.shape[0])\n",
    "            qpsk_labels = torch.ones(qpsk_data.shape[0])\n",
    "            psk_labels = torch.ones(qam_data.shape[0])*2\n",
    "            qam_labels = torch.ones(qam_data.shape[0])*3\n",
    "            ask_labels = torch.ones(ask_data.shape[0])*4\n",
    "\n",
    "            test_labels = torch.cat((bpsk_labels, qpsk_labels, psk_labels, qam_labels, ask_labels))\n",
    "\n",
    "            results = torch.argmax(model(test_data),axis=1)\n",
    "            accs.append(torch.sum(results == test_labels).float() / test_data.shape[0])\n",
    "            \n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc25ff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_snr = np.arange(-15,16,2)\n",
    "\n",
    "train_loader = gen_loader(num_frames=512, snr=train_snr, batch_size=32)\n",
    "val_loader = gen_loader(num_frames=128, snr=train_snr, batch_size=32)\n",
    "\n",
    "dataset = {'train_loader': train_loader,\n",
    "           'val_loader': val_loader}\n",
    "\n",
    "torch.save(dataset, f\"data/amc_data_512.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a91b6e9-96af-46ec-b6c4-ca8b9710794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(f\"data/amc_data_512.pt\")\n",
    "train_loader = dataset['train_loader']\n",
    "val_loader = dataset['val_loader']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ac2191d-c275-4476-b4ea-9241a74bb4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "val_losses[-1] = 0.6098215421661735, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5410867038182914, best_loss = 0.6098215421661735, model saved at 1\n",
      "val_losses[-1] = 0.45861562471836803, best_loss = 0.5410867038182914, model saved at 2\n",
      "val_losses[-1] = 0.43123049661517143, best_loss = 0.45861562471836803, model saved at 5\n",
      "val_losses[-1] = 0.41598746962845323, best_loss = 0.43123049661517143, model saved at 9\n",
      "val_losses[-1] = 0.41280970107764003, best_loss = 0.41598746962845323, model saved at 12\n",
      "iter 1\n",
      "val_losses[-1] = 0.5979742417111993, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5439924504607916, best_loss = 0.5979742417111993, model saved at 1\n",
      "val_losses[-1] = 0.49414990106597545, best_loss = 0.5439924504607916, model saved at 2\n",
      "val_losses[-1] = 0.46247018948197366, best_loss = 0.49414990106597545, model saved at 3\n",
      "val_losses[-1] = 0.43003799449652436, best_loss = 0.46247018948197366, model saved at 8\n",
      "val_losses[-1] = 0.4147070019505918, best_loss = 0.43003799449652436, model saved at 13\n",
      "iter 2\n",
      "val_losses[-1] = 0.6953262547031045, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.553054592013359, best_loss = 0.6953262547031045, model saved at 1\n",
      "val_losses[-1] = 0.5523029393516481, best_loss = 0.553054592013359, model saved at 2\n",
      "val_losses[-1] = 0.46272031450644135, best_loss = 0.5523029393516481, model saved at 3\n",
      "val_losses[-1] = 0.45966324843466283, best_loss = 0.46272031450644135, model saved at 5\n",
      "val_losses[-1] = 0.455149835254997, best_loss = 0.45966324843466283, model saved at 6\n",
      "val_losses[-1] = 0.43455873262137173, best_loss = 0.455149835254997, model saved at 9\n",
      "val_losses[-1] = 0.425409400742501, best_loss = 0.43455873262137173, model saved at 10\n",
      "val_losses[-1] = 0.42306421212852, best_loss = 0.425409400742501, model saved at 11\n",
      "val_losses[-1] = 0.4115632629720494, best_loss = 0.42306421212852, model saved at 13\n",
      "val_losses[-1] = 0.4094133861362934, best_loss = 0.4115632629720494, model saved at 18\n",
      "iter 3\n",
      "val_losses[-1] = 0.6728327507153153, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5268394980579615, best_loss = 0.6728327507153153, model saved at 1\n",
      "val_losses[-1] = 0.516599056776613, best_loss = 0.5268394980579615, model saved at 2\n",
      "val_losses[-1] = 0.4732380140572786, best_loss = 0.516599056776613, model saved at 3\n",
      "val_losses[-1] = 0.4262209182605147, best_loss = 0.4732380140572786, model saved at 6\n",
      "val_losses[-1] = 0.42178998589515687, best_loss = 0.4262209182605147, model saved at 8\n",
      "val_losses[-1] = 0.40744784316048027, best_loss = 0.42178998589515687, model saved at 12\n",
      "iter 4\n",
      "val_losses[-1] = 0.6596149226650596, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5592956734821201, best_loss = 0.6596149226650596, model saved at 1\n",
      "val_losses[-1] = 0.5098230025731028, best_loss = 0.5592956734821201, model saved at 2\n",
      "val_losses[-1] = 0.4644898882135749, best_loss = 0.5098230025731028, model saved at 3\n",
      "val_losses[-1] = 0.45963335782289505, best_loss = 0.4644898882135749, model saved at 4\n",
      "val_losses[-1] = 0.4362456207163632, best_loss = 0.45963335782289505, model saved at 6\n",
      "val_losses[-1] = 0.41561772003769876, best_loss = 0.4362456207163632, model saved at 9\n",
      "iter 5\n",
      "val_losses[-1] = 0.6055034525692463, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5008836877532303, best_loss = 0.6055034525692463, model saved at 1\n",
      "val_losses[-1] = 0.4724189291708171, best_loss = 0.5008836877532303, model saved at 2\n",
      "val_losses[-1] = 0.449447906948626, best_loss = 0.4724189291708171, model saved at 3\n",
      "val_losses[-1] = 0.43357728188857436, best_loss = 0.449447906948626, model saved at 8\n",
      "val_losses[-1] = 0.429423104878515, best_loss = 0.43357728188857436, model saved at 9\n",
      "val_losses[-1] = 0.41816533301025627, best_loss = 0.429423104878515, model saved at 11\n",
      "val_losses[-1] = 0.41303332764655354, best_loss = 0.41816533301025627, model saved at 13\n",
      "iter 6\n",
      "val_losses[-1] = 0.7992758475244045, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.651320435013622, best_loss = 0.7992758475244045, model saved at 1\n",
      "val_losses[-1] = 0.5342466800473631, best_loss = 0.651320435013622, model saved at 2\n",
      "val_losses[-1] = 0.5204239884391427, best_loss = 0.5342466800473631, model saved at 3\n",
      "val_losses[-1] = 0.4918779071420431, best_loss = 0.5204239884391427, model saved at 4\n",
      "val_losses[-1] = 0.4516031065955758, best_loss = 0.4918779071420431, model saved at 5\n",
      "val_losses[-1] = 0.43052382925525307, best_loss = 0.4516031065955758, model saved at 8\n",
      "val_losses[-1] = 0.41640578554943203, best_loss = 0.43052382925525307, model saved at 18\n",
      "iter 7\n",
      "val_losses[-1] = 0.7521121488884092, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5241731453686953, best_loss = 0.7521121488884092, model saved at 1\n",
      "val_losses[-1] = 0.5166834282688797, best_loss = 0.5241731453686953, model saved at 2\n",
      "val_losses[-1] = 0.4515765585936606, best_loss = 0.5166834282688797, model saved at 4\n",
      "val_losses[-1] = 0.4423812194727361, best_loss = 0.4515765585936606, model saved at 6\n",
      "val_losses[-1] = 0.4298855918459594, best_loss = 0.4423812194727361, model saved at 7\n",
      "val_losses[-1] = 0.4226418098434806, best_loss = 0.4298855918459594, model saved at 9\n",
      "val_losses[-1] = 0.4220729861408472, best_loss = 0.4226418098434806, model saved at 12\n",
      "val_losses[-1] = 0.41454283581115303, best_loss = 0.4220729861408472, model saved at 16\n",
      "iter 8\n",
      "val_losses[-1] = 0.7476605881005526, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5485551431775093, best_loss = 0.7476605881005526, model saved at 1\n",
      "val_losses[-1] = 0.4626371650956571, best_loss = 0.5485551431775093, model saved at 2\n",
      "val_losses[-1] = 0.45495863715186713, best_loss = 0.4626371650956571, model saved at 6\n",
      "val_losses[-1] = 0.42632752964273096, best_loss = 0.45495863715186713, model saved at 7\n",
      "val_losses[-1] = 0.4233153813984245, best_loss = 0.42632752964273096, model saved at 8\n",
      "val_losses[-1] = 0.4157330509275198, best_loss = 0.4233153813984245, model saved at 12\n",
      "iter 9\n",
      "val_losses[-1] = 0.80753771699965, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5905724234879017, best_loss = 0.80753771699965, model saved at 1\n",
      "val_losses[-1] = 0.48921789983287456, best_loss = 0.5905724234879017, model saved at 2\n",
      "val_losses[-1] = 0.48629249129444363, best_loss = 0.48921789983287456, model saved at 3\n",
      "val_losses[-1] = 0.4685344845056534, best_loss = 0.48629249129444363, model saved at 4\n",
      "val_losses[-1] = 0.4500663742423058, best_loss = 0.4685344845056534, model saved at 5\n",
      "val_losses[-1] = 0.4330312843434513, best_loss = 0.4500663742423058, model saved at 7\n",
      "val_losses[-1] = 0.42880153805017474, best_loss = 0.4330312843434513, model saved at 8\n",
      "val_losses[-1] = 0.41815286814235153, best_loss = 0.42880153805017474, model saved at 16\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "num_iter = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "models = []\n",
    "for i in range(num_iter):\n",
    "    print(f\"iter {i}\")\n",
    "    \n",
    "    dataset = torch.load(f\"data/amc_data_512.pt\")\n",
    "    train_loader = dataset['train_loader']\n",
    "    val_loader = dataset['val_loader']\n",
    "    \n",
    "    torch.manual_seed(i)\n",
    "    model = amc_model()\n",
    "    model.cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.0001)\n",
    "\n",
    "    model, losses, val_losses = \\\n",
    "    train(model, optimizer, train_loader, val_loader, loss_fn, num_epochs=num_epochs, verbose=False)\n",
    "\n",
    "    model_config = {\"weights\": model.state_dict(),\n",
    "                    \"losses\": losses,\n",
    "                    \"val_losses\": val_losses}\n",
    "\n",
    "    models.append(model_config)\n",
    "torch.save(models, f'baselines/models/amc_baseline.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "071eb6da-1207-492a-bdb7-576a2a8892f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_range = np.arange(-15,16,2)\n",
    "\n",
    "results = []\n",
    "for model_config in torch.load(f'baselines/models/amc_baseline.pt'):\n",
    "    model = amc_model()\n",
    "    model.load_state_dict(model_config['weights'])\n",
    "    accs = np.array(test_model(model, snr_range, samples_per_frame=1024, num_frames=256))\n",
    "\n",
    "    result = {\"accs_mod\": accs,\n",
    "              \"snr_range\": snr_range,\n",
    "              \"model\": model_config}\n",
    "    results.append(result)\n",
    "torch.save(results, f'baselines/results/amc_baseline.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc35ed5-dd4d-47f6-a427-44152ae90c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fad19d3dca0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for result in torch.load(f'baselines/results/amc_baseline.pt'):\n",
    "    plt.plot(result['accs_mod'])\n",
    "plt.plot(np.mean([result['accs_mod'] for result in torch.load(f'baselines/results/amc_baseline.pt')], axis=0), 'k--', linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f3876d-a4d5-47c4-80ca-62c504d32bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model_config in torch.load(f'baselines/models/amc_baseline.pt'):\n",
    "    plt.plot(model_config['val_losses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5900df74-504b-4d67-98fb-0e004036339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = gen_loader(num_frames=32, snr=np.arange(-15,16,2), batch_size=32, case=0)\n",
    "\n",
    "y_test = np.zeros(len(test_loader)*32,)\n",
    "y_hats = np.zeros(len(test_loader)*32,)\n",
    "\n",
    "for i, (x,y,z) in enumerate(test_loader):\n",
    "    y_hats[32*i:32*(i+1)] = model(x).argmax(axis=1).detach().cpu()\n",
    "    y_test[32*i:32*(i+1)] = y.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "76eaf100-a933-494e-8ba5-a593b5108583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f52f1766070>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import confusion matrix function and use to get our cm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_hats, y_test) # y_test, and y_hat come from latest test loop above\n",
    "\n",
    "# Plot the confusion matrix, Blues cmap is probably most popular choice\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.xticks([0,1,2,3,4], ['bpsk', 'qpsk', '8-PSK', '16-qam', '4-ask'])\n",
    "plt.yticks([0,1,2,3,4], ['bpsk', 'qpsk', '8-PSK', '16-qam', '4-ask'])\n",
    "plt.ylabel('True Classes')\n",
    "plt.xlabel('Predicted Classes')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa9e4550-e04b-4d1f-9018-8d1176e00340",
   "metadata": {},
   "source": [
    "## Add MTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dd8dca6-9f96-4ec0-b601-a990aa22b9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class amc_model_mtl(nn.Module):\n",
    "    def __init__(self, case=0):\n",
    "        super(amc_model_mtl, self).__init__()\n",
    "            \n",
    "        # 3 conv layers with a 9 sample wide kernel and padding so that the\n",
    "        # size of the output remains consistent with the input for each layer\n",
    "        self.convolutions = nn.Sequential(\n",
    "                    nn.Conv1d(2, 64, 3, padding=1),\n",
    "                    nn.MaxPool1d(2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv1d(64, 64, 3, padding=1),\n",
    "                    nn.MaxPool1d(2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv1d(64, 64, 3, padding=1),\n",
    "                    nn.MaxPool1d(2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv1d(64, 64, 3, padding=1),\n",
    "                    nn.MaxPool1d(2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv1d(64, 64, 3, padding=1),\n",
    "                    nn.MaxPool1d(2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv1d(64, 64, 3, padding=1),\n",
    "                    nn.MaxPool1d(2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv1d(64, 64, 3, padding=1),\n",
    "                    nn.MaxPool1d(2),\n",
    "                    nn.ReLU()\n",
    "                    )\n",
    "        \n",
    "        # Noise estimator network\n",
    "        # Case 0 -> estimate linear SNR, no negative values\n",
    "        if case == 0:\n",
    "            self.noise_estimator = nn.Sequential(\n",
    "                                        nn.Linear(512,512),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(512,128),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(128,64),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(64,1),\n",
    "                                        nn.ReLU())\n",
    "        # Case 1 -> estimate SNR dBs, negative and positive possible\n",
    "        elif case == 1:\n",
    "            self.noise_estimator = nn.Sequential(\n",
    "                                        nn.Linear(512,512),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(512,128),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(128,64),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(64,1))\n",
    "        \n",
    "        # Case 2 -> 16 SNR levels = 16 classes going into CrossEntropyLoss softmax\n",
    "        elif case == 2:\n",
    "            self.noise_estimator = nn.Sequential(\n",
    "                                        nn.Linear(512,512),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(512,128),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(128,64),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(64,16))\n",
    "        \n",
    "        # 128 samples x 16 output filters x 2 channels (I/Q) = 4096\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Extract features with convolutional layers\n",
    "        x = self.convolutions(x)\n",
    "        \n",
    "        # Flatten so it's compatible with fully connected layers for classification\n",
    "        x_shared = torch.flatten(x,1)\n",
    "#         print(x.shape)\n",
    "        \n",
    "#         First fully connected layer\n",
    "        y = F.selu(self.fc1(x_shared))\n",
    "        \n",
    "        # Final layer responsible for classifying the 5 modulation schemes\n",
    "        y = F.selu(self.fc2(y))\n",
    "        \n",
    "        y = self.fc3(y)\n",
    "        \n",
    "        n = self.noise_estimator(x_shared).squeeze()\n",
    "        \n",
    "        return y, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88bb0346-2b30-4cd4-ac83-436bf314f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mtl(model, optimizer, train_loader, val_loader, loss_fns, loss_ratios=(0.5, 0.5),\n",
    "          num_epochs=5, verbose=False):\n",
    "    \n",
    "    loss_fn_amc = loss_fns[0]\n",
    "    loss_fn_snr = loss_fns[1]\n",
    "    \n",
    "    losses, val_losses = [], []\n",
    "    \n",
    "    losses_mod, val_losses_mod = [], []\n",
    "    losses_snr, val_losses_snr = [], []\n",
    "    \n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        running_mod_loss, running_snr_loss = 0, 0\n",
    "        \n",
    "        for x, y, z in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            y_hat, z_hat = model(x)\n",
    "            \n",
    "            loss_1 = loss_fn_amc(y_hat, y)\n",
    "            loss_2 = loss_fn_snr(z_hat, z)\n",
    "            loss = loss_1*loss_ratios[0] + loss_2*loss_ratios[1]\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            running_mod_loss += loss_1.item()\n",
    "            running_snr_loss += loss_2.item()\n",
    "            \n",
    "        losses.append(running_loss/len(train_loader))\n",
    "        losses_mod.append(running_mod_loss/len(train_loader))\n",
    "        losses_snr.append(running_snr_loss/len(train_loader))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            running_val_loss = 0\n",
    "            running_snr_val_loss = 0\n",
    "            for x, y, z in val_loader:\n",
    "                y_hat, z_hat = model(x)\n",
    "                \n",
    "                val_loss = loss_fn_amc(y_hat, y)\n",
    "                running_val_loss += val_loss.item()\n",
    "                \n",
    "                snr_val_loss = loss_fn_snr(z_hat, z)\n",
    "                running_snr_val_loss += snr_val_loss.item()\n",
    "                \n",
    "            val_losses.append(running_val_loss/len(val_loader))\n",
    "            val_losses_snr.append(running_snr_val_loss/len(val_loader))\n",
    "        \n",
    "        if val_losses[-1] < best_loss:\n",
    "            print(f'val_losses[-1] = {val_losses[-1]}, best_loss = {best_loss}, model saved at {epoch}')\n",
    "            saved_model = model.state_dict()\n",
    "            best_loss = val_losses[-1]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Loss: {losses[-1]}, Val loss: {val_losses[-1]}\")\n",
    "            \n",
    "    model.load_state_dict(saved_model)\n",
    "    \n",
    "    return model, losses, losses_mod, losses_snr, val_losses, val_losses_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33ae96f3-96b7-4749-abb7-9073555b4c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loss_ratios = []\n",
    "for i in range(1,10):\n",
    "    models = []\n",
    "\n",
    "    amc_weight = 1\n",
    "    snr_weight = round(1 - i*0.1, 1)\n",
    "    \n",
    "    loss_ratios = (amc_weight, snr_weight)\n",
    "    \n",
    "    all_loss_ratios.append(loss_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3657d3b2-75a3-4a3b-9a88-d3d31e29b849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.9),\n",
       " (1, 0.8),\n",
       " (1, 0.7),\n",
       " (1, 0.6),\n",
       " (1, 0.5),\n",
       " (1, 0.4),\n",
       " (1, 0.3),\n",
       " (1, 0.2),\n",
       " (1, 0.1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_loss_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86c6ab2f-c40b-4567-81e2-c56954a18a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "loss_fns = (nn.CrossEntropyLoss(), nn.MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec369453-fd30-4e5d-a7b7-5d81ba4fbb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.9)\n",
      "iter 0\n",
      "val_losses[-1] = 1.5908802591264248, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.5583900667726993, best_loss = 1.5908802591264248, model saved at 1\n",
      "val_losses[-1] = 1.4907583482563496, best_loss = 1.5583900667726993, model saved at 2\n",
      "val_losses[-1] = 1.4068447828292847, best_loss = 1.4907583482563496, model saved at 3\n",
      "val_losses[-1] = 1.0421560928225517, best_loss = 1.4068447828292847, model saved at 4\n",
      "val_losses[-1] = 0.8252004489302636, best_loss = 1.0421560928225517, model saved at 5\n",
      "val_losses[-1] = 0.7392387162894011, best_loss = 0.8252004489302636, model saved at 6\n",
      "val_losses[-1] = 0.6731798125430941, best_loss = 0.7392387162894011, model saved at 7\n",
      "val_losses[-1] = 0.6107279766350985, best_loss = 0.6731798125430941, model saved at 10\n",
      "val_losses[-1] = 0.595141552016139, best_loss = 0.6107279766350985, model saved at 18\n",
      "val_losses[-1] = 0.5842453259974718, best_loss = 0.595141552016139, model saved at 20\n",
      "val_losses[-1] = 0.5759552739560604, best_loss = 0.5842453259974718, model saved at 24\n",
      "val_losses[-1] = 0.5529786966741085, best_loss = 0.5759552739560604, model saved at 27\n",
      "val_losses[-1] = 0.5521701430901885, best_loss = 0.5529786966741085, model saved at 29\n",
      "iter 1\n",
      "val_losses[-1] = 1.3072763606905937, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.1086297079920768, best_loss = 1.3072763606905937, model saved at 1\n",
      "val_losses[-1] = 1.0387806337326766, best_loss = 1.1086297079920768, model saved at 2\n",
      "val_losses[-1] = 0.9909066963940859, best_loss = 1.0387806337326766, model saved at 4\n",
      "val_losses[-1] = 0.8941196650266647, best_loss = 0.9909066963940859, model saved at 5\n",
      "val_losses[-1] = 0.8444649688899517, best_loss = 0.8941196650266647, model saved at 6\n",
      "val_losses[-1] = 0.828762773051858, best_loss = 0.8444649688899517, model saved at 7\n",
      "val_losses[-1] = 0.8025086738169194, best_loss = 0.828762773051858, model saved at 8\n",
      "val_losses[-1] = 0.8017871048301458, best_loss = 0.8025086738169194, model saved at 9\n",
      "val_losses[-1] = 0.7921816535294056, best_loss = 0.8017871048301458, model saved at 10\n",
      "val_losses[-1] = 0.7666122283786535, best_loss = 0.7921816535294056, model saved at 11\n",
      "val_losses[-1] = 0.7455666672438384, best_loss = 0.7666122283786535, model saved at 16\n",
      "val_losses[-1] = 0.7284170351922512, best_loss = 0.7455666672438384, model saved at 18\n",
      "val_losses[-1] = 0.7090291185304523, best_loss = 0.7284170351922512, model saved at 20\n",
      "val_losses[-1] = 0.6916277112439275, best_loss = 0.7090291185304523, model saved at 24\n",
      "val_losses[-1] = 0.6233990182168782, best_loss = 0.6916277112439275, model saved at 29\n",
      "iter 2\n",
      "val_losses[-1] = 1.2988507218658925, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.2160050973296166, best_loss = 1.2988507218658925, model saved at 1\n",
      "val_losses[-1] = 1.0421044301241635, best_loss = 1.2160050973296166, model saved at 2\n",
      "val_losses[-1] = 1.0194178942590952, best_loss = 1.0421044301241635, model saved at 4\n",
      "val_losses[-1] = 1.0058808878064156, best_loss = 1.0194178942590952, model saved at 9\n",
      "val_losses[-1] = 0.9992529109120369, best_loss = 1.0058808878064156, model saved at 10\n",
      "val_losses[-1] = 0.9981619652360678, best_loss = 0.9992529109120369, model saved at 11\n",
      "val_losses[-1] = 0.9931720953434706, best_loss = 0.9981619652360678, model saved at 12\n",
      "val_losses[-1] = 0.9877274025231599, best_loss = 0.9931720953434706, model saved at 13\n",
      "val_losses[-1] = 0.9339678291231394, best_loss = 0.9877274025231599, model saved at 14\n",
      "val_losses[-1] = 0.8285331230610609, best_loss = 0.9339678291231394, model saved at 15\n",
      "val_losses[-1] = 0.7846215803176164, best_loss = 0.8285331230610609, model saved at 16\n",
      "val_losses[-1] = 0.7584503401070833, best_loss = 0.7846215803176164, model saved at 17\n",
      "val_losses[-1] = 0.7177502052858472, best_loss = 0.7584503401070833, model saved at 18\n",
      "val_losses[-1] = 0.708470812253654, best_loss = 0.7177502052858472, model saved at 21\n",
      "val_losses[-1] = 0.66052822843194, best_loss = 0.708470812253654, model saved at 25\n",
      "val_losses[-1] = 0.5608337733894586, best_loss = 0.66052822843194, model saved at 26\n",
      "iter 3\n",
      "val_losses[-1] = 0.7449545038864016, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.6659375609830022, best_loss = 0.7449545038864016, model saved at 6\n",
      "val_losses[-1] = 0.6058821706101298, best_loss = 0.6659375609830022, model saved at 8\n",
      "val_losses[-1] = 0.5983153020963072, best_loss = 0.6058821706101298, model saved at 11\n",
      "val_losses[-1] = 0.5801734847947955, best_loss = 0.5983153020963072, model saved at 13\n",
      "val_losses[-1] = 0.5687164264731109, best_loss = 0.5801734847947955, model saved at 14\n",
      "val_losses[-1] = 0.5545778453350068, best_loss = 0.5687164264731109, model saved at 15\n",
      "val_losses[-1] = 0.5491232548840344, best_loss = 0.5545778453350068, model saved at 16\n",
      "val_losses[-1] = 0.5356193421408534, best_loss = 0.5491232548840344, model saved at 18\n",
      "val_losses[-1] = 0.5116156866773963, best_loss = 0.5356193421408534, model saved at 20\n",
      "val_losses[-1] = 0.49043488698080184, best_loss = 0.5116156866773963, model saved at 23\n",
      "val_losses[-1] = 0.4836991029791534, best_loss = 0.49043488698080184, model saved at 25\n",
      "iter 4\n",
      "val_losses[-1] = 1.6098717033863068, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.6094750352203846, best_loss = 1.6098717033863068, model saved at 1\n",
      "val_losses[-1] = 1.609348587691784, best_loss = 1.6094750352203846, model saved at 2\n",
      "(1, 0.8)\n",
      "iter 0\n",
      "val_losses[-1] = 1.600596398115158, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.5717224426567555, best_loss = 1.600596398115158, model saved at 1\n",
      "val_losses[-1] = 1.5452346436679363, best_loss = 1.5717224426567555, model saved at 2\n",
      "val_losses[-1] = 1.2064875021576882, best_loss = 1.5452346436679363, model saved at 3\n",
      "val_losses[-1] = 0.8112689908593893, best_loss = 1.2064875021576882, model saved at 4\n",
      "val_losses[-1] = 0.785262949205935, best_loss = 0.8112689908593893, model saved at 5\n",
      "val_losses[-1] = 0.6801286913454533, best_loss = 0.785262949205935, model saved at 6\n",
      "val_losses[-1] = 0.6222209300845861, best_loss = 0.6801286913454533, model saved at 7\n",
      "val_losses[-1] = 0.593291648849845, best_loss = 0.6222209300845861, model saved at 8\n",
      "val_losses[-1] = 0.5895647216588259, best_loss = 0.593291648849845, model saved at 10\n",
      "val_losses[-1] = 0.570219667814672, best_loss = 0.5895647216588259, model saved at 11\n",
      "val_losses[-1] = 0.5565639834851026, best_loss = 0.570219667814672, model saved at 12\n",
      "val_losses[-1] = 0.550417164247483, best_loss = 0.5565639834851026, model saved at 13\n",
      "val_losses[-1] = 0.5314740102738142, best_loss = 0.550417164247483, model saved at 14\n",
      "val_losses[-1] = 0.5279496340081096, best_loss = 0.5314740102738142, model saved at 19\n",
      "val_losses[-1] = 0.5160379773005843, best_loss = 0.5279496340081096, model saved at 20\n",
      "val_losses[-1] = 0.5059339292347431, best_loss = 0.5160379773005843, model saved at 26\n",
      "val_losses[-1] = 0.5035629672929645, best_loss = 0.5059339292347431, model saved at 27\n",
      "val_losses[-1] = 0.49246600139886143, best_loss = 0.5035629672929645, model saved at 29\n",
      "iter 1\n",
      "val_losses[-1] = 1.184072496369481, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.15437569655478, best_loss = 1.184072496369481, model saved at 1\n",
      "val_losses[-1] = 1.1454127185046672, best_loss = 1.15437569655478, model saved at 2\n",
      "val_losses[-1] = 1.076211966201663, best_loss = 1.1454127185046672, model saved at 3\n",
      "val_losses[-1] = 1.049019367620349, best_loss = 1.076211966201663, model saved at 4\n",
      "val_losses[-1] = 1.0397060118615626, best_loss = 1.049019367620349, model saved at 5\n",
      "val_losses[-1] = 1.0328517463058233, best_loss = 1.0397060118615626, model saved at 6\n",
      "val_losses[-1] = 1.0266414783895015, best_loss = 1.0328517463058233, model saved at 9\n",
      "val_losses[-1] = 1.0003885082900523, best_loss = 1.0266414783895015, model saved at 10\n",
      "val_losses[-1] = 0.7824289381504059, best_loss = 1.0003885082900523, model saved at 11\n",
      "val_losses[-1] = 0.6902797099202871, best_loss = 0.7824289381504059, model saved at 12\n",
      "val_losses[-1] = 0.6517466984689235, best_loss = 0.6902797099202871, model saved at 13\n",
      "val_losses[-1] = 0.591242422349751, best_loss = 0.6517466984689235, model saved at 14\n",
      "val_losses[-1] = 0.5713419858366251, best_loss = 0.591242422349751, model saved at 15\n",
      "val_losses[-1] = 0.5409282643347979, best_loss = 0.5713419858366251, model saved at 20\n",
      "val_losses[-1] = 0.5389522654935718, best_loss = 0.5409282643347979, model saved at 21\n",
      "val_losses[-1] = 0.5189812825992703, best_loss = 0.5389522654935718, model saved at 27\n",
      "val_losses[-1] = 0.5026291745714844, best_loss = 0.5189812825992703, model saved at 29\n",
      "iter 2\n",
      "val_losses[-1] = 1.213496409356594, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.209661564975977, best_loss = 1.213496409356594, model saved at 1\n",
      "val_losses[-1] = 1.0376184940338136, best_loss = 1.209661564975977, model saved at 2\n",
      "val_losses[-1] = 1.0211562920361756, best_loss = 1.0376184940338136, model saved at 4\n",
      "val_losses[-1] = 1.0193161960691213, best_loss = 1.0211562920361756, model saved at 5\n",
      "val_losses[-1] = 1.0011017940938474, best_loss = 1.0193161960691213, model saved at 10\n",
      "val_losses[-1] = 0.9994206327944994, best_loss = 1.0011017940938474, model saved at 14\n",
      "val_losses[-1] = 0.9977424375712871, best_loss = 0.9994206327944994, model saved at 16\n",
      "val_losses[-1] = 0.9734969601035118, best_loss = 0.9977424375712871, model saved at 24\n",
      "val_losses[-1] = 0.8410827919840813, best_loss = 0.9734969601035118, model saved at 25\n",
      "val_losses[-1] = 0.7772942829877139, best_loss = 0.8410827919840813, model saved at 26\n",
      "val_losses[-1] = 0.7770998474210501, best_loss = 0.7772942829877139, model saved at 27\n",
      "val_losses[-1] = 0.7590880058705807, best_loss = 0.7770998474210501, model saved at 28\n",
      "iter 3\n",
      "val_losses[-1] = 0.8662061512470245, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7071051182225346, best_loss = 0.8662061512470245, model saved at 6\n",
      "val_losses[-1] = 0.6295050848275423, best_loss = 0.7071051182225346, model saved at 7\n",
      "val_losses[-1] = 0.5797069685533642, best_loss = 0.6295050848275423, model saved at 8\n",
      "val_losses[-1] = 0.5339828368276358, best_loss = 0.5797069685533642, model saved at 11\n",
      "val_losses[-1] = 0.5128750700503588, best_loss = 0.5339828368276358, model saved at 17\n",
      "val_losses[-1] = 0.5069472878240049, best_loss = 0.5128750700503588, model saved at 21\n",
      "iter 4\n",
      "val_losses[-1] = 1.6102978318929673, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.609211127460003, best_loss = 1.6102978318929673, model saved at 1\n",
      "(1, 0.7)\n",
      "iter 0\n",
      "val_losses[-1] = 1.6049829460680485, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.5839224621653556, best_loss = 1.6049829460680485, model saved at 1\n",
      "val_losses[-1] = 1.5213293440639972, best_loss = 1.5839224621653556, model saved at 2\n",
      "val_losses[-1] = 1.4168904334306718, best_loss = 1.5213293440639972, model saved at 3\n",
      "val_losses[-1] = 0.9306393787264824, best_loss = 1.4168904334306718, model saved at 4\n",
      "val_losses[-1] = 0.7038476219400763, best_loss = 0.9306393787264824, model saved at 5\n",
      "val_losses[-1] = 0.6819381862878799, best_loss = 0.7038476219400763, model saved at 6\n",
      "val_losses[-1] = 0.6114038065075874, best_loss = 0.6819381862878799, model saved at 7\n",
      "val_losses[-1] = 0.5940339479595422, best_loss = 0.6114038065075874, model saved at 8\n",
      "val_losses[-1] = 0.5900910634547472, best_loss = 0.5940339479595422, model saved at 10\n",
      "val_losses[-1] = 0.5860537562519312, best_loss = 0.5900910634547472, model saved at 12\n",
      "val_losses[-1] = 0.5841813312843442, best_loss = 0.5860537562519312, model saved at 18\n",
      "val_losses[-1] = 0.5722005443647504, best_loss = 0.5841813312843442, model saved at 19\n",
      "val_losses[-1] = 0.5554365923628211, best_loss = 0.5722005443647504, model saved at 20\n",
      "val_losses[-1] = 0.5544885661453008, best_loss = 0.5554365923628211, model saved at 26\n",
      "val_losses[-1] = 0.550039057340473, best_loss = 0.5544885661453008, model saved at 27\n",
      "val_losses[-1] = 0.5373312713578343, best_loss = 0.550039057340473, model saved at 28\n",
      "val_losses[-1] = 0.5082051441073417, best_loss = 0.5373312713578343, model saved at 29\n",
      "iter 1\n",
      "val_losses[-1] = 1.1824637174606323, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.146760806068778, best_loss = 1.1824637174606323, model saved at 1\n",
      "val_losses[-1] = 1.111362838000059, best_loss = 1.146760806068778, model saved at 2\n",
      "val_losses[-1] = 1.0613663334399461, best_loss = 1.111362838000059, model saved at 3\n",
      "val_losses[-1] = 1.032397336512804, best_loss = 1.0613663334399461, model saved at 4\n",
      "val_losses[-1] = 1.0112348422408104, best_loss = 1.032397336512804, model saved at 6\n",
      "val_losses[-1] = 0.8118543192744255, best_loss = 1.0112348422408104, model saved at 10\n",
      "val_losses[-1] = 0.7828510440886021, best_loss = 0.8118543192744255, model saved at 11\n",
      "val_losses[-1] = 0.7322390917688608, best_loss = 0.7828510440886021, model saved at 15\n",
      "val_losses[-1] = 0.7069665756076574, best_loss = 0.7322390917688608, model saved at 17\n",
      "val_losses[-1] = 0.6141147298738361, best_loss = 0.7069665756076574, model saved at 18\n",
      "val_losses[-1] = 0.5632385326549411, best_loss = 0.6141147298738361, model saved at 20\n",
      "val_losses[-1] = 0.5438885323703289, best_loss = 0.5632385326549411, model saved at 21\n",
      "val_losses[-1] = 0.5341535609215498, best_loss = 0.5438885323703289, model saved at 25\n",
      "val_losses[-1] = 0.5241089736111462, best_loss = 0.5341535609215498, model saved at 27\n",
      "iter 2\n",
      "val_losses[-1] = 1.2226925134658813, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.121385433524847, best_loss = 1.2226925134658813, model saved at 1\n",
      "val_losses[-1] = 1.0355484053492545, best_loss = 1.121385433524847, model saved at 2\n",
      "val_losses[-1] = 1.0186205949634313, best_loss = 1.0355484053492545, model saved at 4\n",
      "val_losses[-1] = 1.0077413253486156, best_loss = 1.0186205949634313, model saved at 9\n",
      "val_losses[-1] = 0.9948181666433811, best_loss = 1.0077413253486156, model saved at 10\n",
      "val_losses[-1] = 0.8904852036386728, best_loss = 0.9948181666433811, model saved at 13\n",
      "val_losses[-1] = 0.8278924979269504, best_loss = 0.8904852036386728, model saved at 14\n",
      "val_losses[-1] = 0.8016995776444673, best_loss = 0.8278924979269504, model saved at 16\n",
      "val_losses[-1] = 0.7563953887671232, best_loss = 0.8016995776444673, model saved at 20\n",
      "val_losses[-1] = 0.6384896064177156, best_loss = 0.7563953887671232, model saved at 21\n",
      "val_losses[-1] = 0.6284141849726439, best_loss = 0.6384896064177156, model saved at 22\n",
      "val_losses[-1] = 0.6142617128789425, best_loss = 0.6284141849726439, model saved at 23\n",
      "val_losses[-1] = 0.5732881980016827, best_loss = 0.6142617128789425, model saved at 26\n",
      "val_losses[-1] = 0.5619586203247309, best_loss = 0.5732881980016827, model saved at 27\n",
      "iter 3\n",
      "val_losses[-1] = 0.8596538281068206, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7503793444484472, best_loss = 0.8596538281068206, model saved at 3\n",
      "val_losses[-1] = 0.6518914056941867, best_loss = 0.7503793444484472, model saved at 5\n",
      "val_losses[-1] = 0.6037488026544452, best_loss = 0.6518914056941867, model saved at 6\n",
      "val_losses[-1] = 0.5968615742400288, best_loss = 0.6037488026544452, model saved at 9\n",
      "val_losses[-1] = 0.5546358369290829, best_loss = 0.5968615742400288, model saved at 10\n",
      "val_losses[-1] = 0.5314698847010731, best_loss = 0.5546358369290829, model saved at 11\n",
      "val_losses[-1] = 0.5262599140405655, best_loss = 0.5314698847010731, model saved at 18\n",
      "val_losses[-1] = 0.49960604710504414, best_loss = 0.5262599140405655, model saved at 19\n",
      "val_losses[-1] = 0.4948183878324926, best_loss = 0.49960604710504414, model saved at 25\n",
      "iter 4\n",
      "val_losses[-1] = 1.6100898213684558, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.6098575115203857, best_loss = 1.6100898213684558, model saved at 1\n",
      "val_losses[-1] = 1.6096789680421353, best_loss = 1.6098575115203857, model saved at 5\n",
      "val_losses[-1] = 1.6095267951488494, best_loss = 1.6096789680421353, model saved at 6\n",
      "val_losses[-1] = 1.6094768695533275, best_loss = 1.6095267951488494, model saved at 8\n",
      "val_losses[-1] = 1.6094445444643497, best_loss = 1.6094768695533275, model saved at 10\n",
      "val_losses[-1] = 1.6094388283789158, best_loss = 1.6094445444643497, model saved at 12\n",
      "val_losses[-1] = 1.6094356209039689, best_loss = 1.6094388283789158, model saved at 19\n",
      "(1, 0.6)\n",
      "iter 0\n",
      "val_losses[-1] = 1.6020526103675365, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.5408805847167968, best_loss = 1.6020526103675365, model saved at 1\n",
      "val_losses[-1] = 1.4304847620427608, best_loss = 1.5408805847167968, model saved at 2\n",
      "val_losses[-1] = 0.951230613514781, best_loss = 1.4304847620427608, model saved at 3\n",
      "val_losses[-1] = 0.7593236491084099, best_loss = 0.951230613514781, model saved at 4\n",
      "val_losses[-1] = 0.6490006860345602, best_loss = 0.7593236491084099, model saved at 5\n",
      "val_losses[-1] = 0.6274348059669137, best_loss = 0.6490006860345602, model saved at 6\n",
      "val_losses[-1] = 0.6269021788612008, best_loss = 0.6274348059669137, model saved at 7\n",
      "val_losses[-1] = 0.5940742287784815, best_loss = 0.6269021788612008, model saved at 8\n",
      "val_losses[-1] = 0.5930935675278306, best_loss = 0.5940742287784815, model saved at 10\n",
      "val_losses[-1] = 0.5712109060958028, best_loss = 0.5930935675278306, model saved at 12\n",
      "val_losses[-1] = 0.557320021931082, best_loss = 0.5712109060958028, model saved at 13\n",
      "val_losses[-1] = 0.5316906793043017, best_loss = 0.557320021931082, model saved at 15\n",
      "val_losses[-1] = 0.5180871093645691, best_loss = 0.5316906793043017, model saved at 18\n",
      "val_losses[-1] = 0.49714767914265395, best_loss = 0.5180871093645691, model saved at 20\n",
      "iter 1\n",
      "val_losses[-1] = 1.1354001197963952, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.092457129433751, best_loss = 1.1354001197963952, model saved at 1\n",
      "val_losses[-1] = 1.0454916700720787, best_loss = 1.092457129433751, model saved at 2\n",
      "val_losses[-1] = 1.03683961071074, best_loss = 1.0454916700720787, model saved at 3\n",
      "val_losses[-1] = 1.015711185336113, best_loss = 1.03683961071074, model saved at 4\n",
      "val_losses[-1] = 1.0103185381740332, best_loss = 1.015711185336113, model saved at 7\n",
      "val_losses[-1] = 1.0066580131649971, best_loss = 1.0103185381740332, model saved at 8\n",
      "val_losses[-1] = 0.9358339358121157, best_loss = 1.0066580131649971, model saved at 11\n",
      "val_losses[-1] = 0.8118087839335203, best_loss = 0.9358339358121157, model saved at 12\n",
      "val_losses[-1] = 0.7229000840336084, best_loss = 0.8118087839335203, model saved at 13\n",
      "val_losses[-1] = 0.6389188643544912, best_loss = 0.7229000840336084, model saved at 15\n",
      "val_losses[-1] = 0.6167410163208842, best_loss = 0.6389188643544912, model saved at 16\n",
      "val_losses[-1] = 0.6154454212635756, best_loss = 0.6167410163208842, model saved at 17\n",
      "val_losses[-1] = 0.6013218693435192, best_loss = 0.6154454212635756, model saved at 18\n",
      "val_losses[-1] = 0.5904813479632139, best_loss = 0.6013218693435192, model saved at 19\n",
      "val_losses[-1] = 0.5697962230071425, best_loss = 0.5904813479632139, model saved at 20\n",
      "val_losses[-1] = 0.5567278387024999, best_loss = 0.5697962230071425, model saved at 23\n",
      "val_losses[-1] = 0.552781829982996, best_loss = 0.5567278387024999, model saved at 25\n",
      "val_losses[-1] = 0.5494049627333879, best_loss = 0.552781829982996, model saved at 26\n",
      "val_losses[-1] = 0.5195759899914265, best_loss = 0.5494049627333879, model saved at 27\n",
      "iter 2\n",
      "val_losses[-1] = 1.2064768373966217, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.0170559491962194, best_loss = 1.2064768373966217, model saved at 2\n",
      "val_losses[-1] = 1.0068892151117326, best_loss = 1.0170559491962194, model saved at 4\n",
      "val_losses[-1] = 0.9403324481099844, best_loss = 1.0068892151117326, model saved at 7\n",
      "val_losses[-1] = 0.8755202665925026, best_loss = 0.9403324481099844, model saved at 8\n",
      "val_losses[-1] = 0.8320808563381433, best_loss = 0.8755202665925026, model saved at 9\n",
      "val_losses[-1] = 0.6372956443578005, best_loss = 0.8320808563381433, model saved at 10\n",
      "val_losses[-1] = 0.6358239850029349, best_loss = 0.6372956443578005, model saved at 12\n",
      "val_losses[-1] = 0.5993633959442377, best_loss = 0.6358239850029349, model saved at 13\n",
      "val_losses[-1] = 0.570555511303246, best_loss = 0.5993633959442377, model saved at 16\n",
      "val_losses[-1] = 0.5346410546451807, best_loss = 0.570555511303246, model saved at 17\n",
      "val_losses[-1] = 0.5165581505745649, best_loss = 0.5346410546451807, model saved at 21\n",
      "val_losses[-1] = 0.513795779645443, best_loss = 0.5165581505745649, model saved at 28\n",
      "iter 3\n",
      "val_losses[-1] = 0.7939168140292168, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.6691901154816151, best_loss = 0.7939168140292168, model saved at 4\n",
      "val_losses[-1] = 0.6614091148599982, best_loss = 0.6691901154816151, model saved at 5\n",
      "val_losses[-1] = 0.6334599265828729, best_loss = 0.6614091148599982, model saved at 6\n",
      "val_losses[-1] = 0.5851977815851569, best_loss = 0.6334599265828729, model saved at 10\n",
      "val_losses[-1] = 0.555773226171732, best_loss = 0.5851977815851569, model saved at 12\n",
      "val_losses[-1] = 0.5513475025072694, best_loss = 0.555773226171732, model saved at 14\n",
      "val_losses[-1] = 0.5508990844711661, best_loss = 0.5513475025072694, model saved at 16\n",
      "val_losses[-1] = 0.5492891972884536, best_loss = 0.5508990844711661, model saved at 18\n",
      "val_losses[-1] = 0.5471294473856687, best_loss = 0.5492891972884536, model saved at 19\n",
      "val_losses[-1] = 0.5447157490998507, best_loss = 0.5471294473856687, model saved at 20\n",
      "val_losses[-1] = 0.5425314685329795, best_loss = 0.5447157490998507, model saved at 22\n",
      "val_losses[-1] = 0.5410140717402101, best_loss = 0.5425314685329795, model saved at 23\n",
      "val_losses[-1] = 0.5214701156131923, best_loss = 0.5410140717402101, model saved at 25\n",
      "val_losses[-1] = 0.5146892748773098, best_loss = 0.5214701156131923, model saved at 28\n",
      "iter 4\n",
      "val_losses[-1] = 1.61052720323205, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.6085826359689235, best_loss = 1.61052720323205, model saved at 1\n",
      "(1, 0.5)\n",
      "iter 0\n",
      "val_losses[-1] = 1.599256120622158, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.569864096492529, best_loss = 1.599256120622158, model saved at 1\n",
      "val_losses[-1] = 1.5114184208214283, best_loss = 1.569864096492529, model saved at 2\n",
      "val_losses[-1] = 0.9268515300005674, best_loss = 1.5114184208214283, model saved at 3\n",
      "val_losses[-1] = 0.8040448989719152, best_loss = 0.9268515300005674, model saved at 4\n",
      "val_losses[-1] = 0.7275042839348316, best_loss = 0.8040448989719152, model saved at 5\n",
      "val_losses[-1] = 0.694206509180367, best_loss = 0.7275042839348316, model saved at 6\n",
      "val_losses[-1] = 0.6358325321227312, best_loss = 0.694206509180367, model saved at 7\n",
      "val_losses[-1] = 0.6052359774708748, best_loss = 0.6358325321227312, model saved at 8\n",
      "val_losses[-1] = 0.5955034228041768, best_loss = 0.6052359774708748, model saved at 10\n",
      "val_losses[-1] = 0.5521477216854691, best_loss = 0.5955034228041768, model saved at 12\n",
      "val_losses[-1] = 0.5128540072590113, best_loss = 0.5521477216854691, model saved at 19\n",
      "val_losses[-1] = 0.5069309121929109, best_loss = 0.5128540072590113, model saved at 22\n",
      "val_losses[-1] = 0.49724556151777505, best_loss = 0.5069309121929109, model saved at 25\n",
      "val_losses[-1] = 0.4971266838721931, best_loss = 0.49724556151777505, model saved at 26\n",
      "val_losses[-1] = 0.4955399246886373, best_loss = 0.4971266838721931, model saved at 28\n",
      "val_losses[-1] = 0.47179338689893485, best_loss = 0.4955399246886373, model saved at 29\n",
      "iter 1\n",
      "val_losses[-1] = 1.2461539596319198, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.0746885120868683, best_loss = 1.2461539596319198, model saved at 1\n",
      "val_losses[-1] = 1.0628330145031213, best_loss = 1.0746885120868683, model saved at 3\n",
      "val_losses[-1] = 1.0322015814483165, best_loss = 1.0628330145031213, model saved at 4\n",
      "val_losses[-1] = 1.0197543065994978, best_loss = 1.0322015814483165, model saved at 7\n",
      "val_losses[-1] = 1.005796643719077, best_loss = 1.0197543065994978, model saved at 8\n",
      "val_losses[-1] = 0.9635938066989184, best_loss = 1.005796643719077, model saved at 10\n",
      "val_losses[-1] = 0.9112486202269793, best_loss = 0.9635938066989184, model saved at 11\n",
      "val_losses[-1] = 0.9031415846198797, best_loss = 0.9112486202269793, model saved at 12\n",
      "val_losses[-1] = 0.8798458445817232, best_loss = 0.9031415846198797, model saved at 13\n",
      "val_losses[-1] = 0.8596671003848314, best_loss = 0.8798458445817232, model saved at 15\n",
      "val_losses[-1] = 0.7516372727230192, best_loss = 0.8596671003848314, model saved at 18\n",
      "val_losses[-1] = 0.6794292956590653, best_loss = 0.7516372727230192, model saved at 19\n",
      "val_losses[-1] = 0.5969358924776316, best_loss = 0.6794292956590653, model saved at 20\n",
      "val_losses[-1] = 0.5902842104434967, best_loss = 0.5969358924776316, model saved at 21\n",
      "val_losses[-1] = 0.5852629184722901, best_loss = 0.5902842104434967, model saved at 22\n",
      "val_losses[-1] = 0.5454916065558791, best_loss = 0.5852629184722901, model saved at 23\n",
      "val_losses[-1] = 0.5373533369973302, best_loss = 0.5454916065558791, model saved at 26\n",
      "val_losses[-1] = 0.5370706235058605, best_loss = 0.5373533369973302, model saved at 28\n",
      "val_losses[-1] = 0.5354281239211559, best_loss = 0.5370706235058605, model saved at 29\n",
      "iter 2\n",
      "val_losses[-1] = 1.1429293267428875, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.1077379118651152, best_loss = 1.1429293267428875, model saved at 1\n",
      "val_losses[-1] = 1.032819104939699, best_loss = 1.1077379118651152, model saved at 2\n",
      "val_losses[-1] = 0.7897329360246659, best_loss = 1.032819104939699, model saved at 9\n",
      "val_losses[-1] = 0.7670135580003261, best_loss = 0.7897329360246659, model saved at 10\n",
      "val_losses[-1] = 0.6016814330592751, best_loss = 0.7670135580003261, model saved at 11\n",
      "val_losses[-1] = 0.5657921709120274, best_loss = 0.6016814330592751, model saved at 13\n",
      "val_losses[-1] = 0.5606126753613353, best_loss = 0.5657921709120274, model saved at 14\n",
      "val_losses[-1] = 0.5205073558725417, best_loss = 0.5606126753613353, model saved at 16\n",
      "val_losses[-1] = 0.5152321697212756, best_loss = 0.5205073558725417, model saved at 18\n",
      "val_losses[-1] = 0.4857364041730762, best_loss = 0.5152321697212756, model saved at 20\n",
      "val_losses[-1] = 0.4633745728991926, best_loss = 0.4857364041730762, model saved at 26\n",
      "iter 3\n",
      "val_losses[-1] = 0.7145703047513962, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.611273049749434, best_loss = 0.7145703047513962, model saved at 3\n",
      "val_losses[-1] = 0.5860686633735895, best_loss = 0.611273049749434, model saved at 4\n",
      "val_losses[-1] = 0.5566818655468524, best_loss = 0.5860686633735895, model saved at 5\n",
      "val_losses[-1] = 0.5402490191161633, best_loss = 0.5566818655468524, model saved at 11\n",
      "val_losses[-1] = 0.5208629352971912, best_loss = 0.5402490191161633, model saved at 12\n",
      "val_losses[-1] = 0.4778972682543099, best_loss = 0.5208629352971912, model saved at 19\n",
      "val_losses[-1] = 0.46669378513470294, best_loss = 0.4778972682543099, model saved at 24\n",
      "val_losses[-1] = 0.461001661233604, best_loss = 0.46669378513470294, model saved at 28\n",
      "iter 4\n",
      "val_losses[-1] = 1.6099773585796355, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.6072882413864136, best_loss = 1.6099773585796355, model saved at 1\n",
      "val_losses[-1] = 1.600177164375782, best_loss = 1.6072882413864136, model saved at 2\n",
      "val_losses[-1] = 1.5489287205040454, best_loss = 1.600177164375782, model saved at 3\n",
      "val_losses[-1] = 0.9714490782469511, best_loss = 1.5489287205040454, model saved at 4\n",
      "val_losses[-1] = 0.708936333283782, best_loss = 0.9714490782469511, model saved at 5\n",
      "val_losses[-1] = 0.6240526679903269, best_loss = 0.708936333283782, model saved at 8\n",
      "val_losses[-1] = 0.6223514407873154, best_loss = 0.6240526679903269, model saved at 9\n",
      "val_losses[-1] = 0.6063149826601147, best_loss = 0.6223514407873154, model saved at 10\n",
      "val_losses[-1] = 0.5983374388888478, best_loss = 0.6063149826601147, model saved at 11\n",
      "val_losses[-1] = 0.5660175343975424, best_loss = 0.5983374388888478, model saved at 13\n",
      "val_losses[-1] = 0.5618541702628136, best_loss = 0.5660175343975424, model saved at 15\n",
      "val_losses[-1] = 0.5069836879149079, best_loss = 0.5618541702628136, model saved at 20\n",
      "val_losses[-1] = 0.4845797460526228, best_loss = 0.5069836879149079, model saved at 26\n",
      "(1, 0.4)\n",
      "iter 0\n",
      "val_losses[-1] = 1.5823619939386844, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.4825461611151696, best_loss = 1.5823619939386844, model saved at 1\n",
      "val_losses[-1] = 0.8603529285639524, best_loss = 1.4825461611151696, model saved at 2\n",
      "val_losses[-1] = 0.7238492671400308, best_loss = 0.8603529285639524, model saved at 3\n",
      "val_losses[-1] = 0.695734154060483, best_loss = 0.7238492671400308, model saved at 4\n",
      "val_losses[-1] = 0.6411652404814958, best_loss = 0.695734154060483, model saved at 5\n",
      "val_losses[-1] = 0.5886602571234107, best_loss = 0.6411652404814958, model saved at 8\n",
      "val_losses[-1] = 0.5764991050586105, best_loss = 0.5886602571234107, model saved at 11\n",
      "val_losses[-1] = 0.5466080486774445, best_loss = 0.5764991050586105, model saved at 12\n",
      "val_losses[-1] = 0.5353639266453684, best_loss = 0.5466080486774445, model saved at 13\n",
      "val_losses[-1] = 0.5305589342489838, best_loss = 0.5353639266453684, model saved at 16\n",
      "val_losses[-1] = 0.5103292296640575, best_loss = 0.5305589342489838, model saved at 17\n",
      "val_losses[-1] = 0.49922735765576365, best_loss = 0.5103292296640575, model saved at 21\n",
      "val_losses[-1] = 0.4980126625858247, best_loss = 0.49922735765576365, model saved at 26\n",
      "val_losses[-1] = 0.47423963230103255, best_loss = 0.4980126625858247, model saved at 29\n",
      "iter 1\n",
      "val_losses[-1] = 1.1461270041763783, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.0602240663021802, best_loss = 1.1461270041763783, model saved at 1\n",
      "val_losses[-1] = 1.0509694892913104, best_loss = 1.0602240663021802, model saved at 3\n",
      "val_losses[-1] = 1.0161062076687812, best_loss = 1.0509694892913104, model saved at 4\n",
      "val_losses[-1] = 0.930017652735114, best_loss = 1.0161062076687812, model saved at 6\n",
      "val_losses[-1] = 0.7452727869153023, best_loss = 0.930017652735114, model saved at 7\n",
      "val_losses[-1] = 0.6109827050939203, best_loss = 0.7452727869153023, model saved at 8\n",
      "val_losses[-1] = 0.6077206237241626, best_loss = 0.6109827050939203, model saved at 9\n",
      "val_losses[-1] = 0.573324760235846, best_loss = 0.6077206237241626, model saved at 10\n",
      "val_losses[-1] = 0.5501459443941712, best_loss = 0.573324760235846, model saved at 15\n",
      "val_losses[-1] = 0.5168528646230698, best_loss = 0.5501459443941712, model saved at 17\n",
      "val_losses[-1] = 0.5158957059495151, best_loss = 0.5168528646230698, model saved at 21\n",
      "val_losses[-1] = 0.5074659219942987, best_loss = 0.5158957059495151, model saved at 24\n",
      "val_losses[-1] = 0.5007642844691873, best_loss = 0.5074659219942987, model saved at 29\n",
      "iter 2\n",
      "val_losses[-1] = 1.1129625897854567, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.0446251608431338, best_loss = 1.1129625897854567, model saved at 2\n",
      "val_losses[-1] = 1.032741256058216, best_loss = 1.0446251608431338, model saved at 5\n",
      "val_losses[-1] = 0.9184173990041018, best_loss = 1.032741256058216, model saved at 6\n",
      "val_losses[-1] = 0.8930986568331718, best_loss = 0.9184173990041018, model saved at 7\n",
      "val_losses[-1] = 0.6610250815749168, best_loss = 0.8930986568331718, model saved at 8\n",
      "val_losses[-1] = 0.6528507154434919, best_loss = 0.6610250815749168, model saved at 9\n",
      "val_losses[-1] = 0.6334914326667785, best_loss = 0.6528507154434919, model saved at 10\n",
      "val_losses[-1] = 0.6090440148487687, best_loss = 0.6334914326667785, model saved at 12\n",
      "val_losses[-1] = 0.5364264451898635, best_loss = 0.6090440148487687, model saved at 16\n",
      "val_losses[-1] = 0.5133291588164866, best_loss = 0.5364264451898635, model saved at 18\n",
      "val_losses[-1] = 0.5013691866770387, best_loss = 0.5133291588164866, model saved at 20\n",
      "val_losses[-1] = 0.4908095756545663, best_loss = 0.5013691866770387, model saved at 26\n",
      "val_losses[-1] = 0.4825718767940998, best_loss = 0.4908095756545663, model saved at 28\n",
      "iter 3\n",
      "val_losses[-1] = 0.814750705845654, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7886592580005527, best_loss = 0.814750705845654, model saved at 2\n",
      "val_losses[-1] = 0.7127117834985256, best_loss = 0.7886592580005527, model saved at 3\n",
      "val_losses[-1] = 0.5746810957789421, best_loss = 0.7127117834985256, model saved at 5\n",
      "val_losses[-1] = 0.5466079480946064, best_loss = 0.5746810957789421, model saved at 10\n",
      "val_losses[-1] = 0.5189370304346085, best_loss = 0.5466079480946064, model saved at 11\n",
      "val_losses[-1] = 0.5111337693408131, best_loss = 0.5189370304346085, model saved at 12\n",
      "val_losses[-1] = 0.4994144602678716, best_loss = 0.5111337693408131, model saved at 19\n",
      "val_losses[-1] = 0.48719066502526404, best_loss = 0.4994144602678716, model saved at 25\n",
      "iter 4\n",
      "val_losses[-1] = 1.6098609387874603, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.609276432543993, best_loss = 1.6098609387874603, model saved at 1\n",
      "val_losses[-1] = 1.6092129550874232, best_loss = 1.609276432543993, model saved at 2\n",
      "(1, 0.3)\n",
      "iter 0\n",
      "val_losses[-1] = 1.579479194432497, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.3217005789279939, best_loss = 1.579479194432497, model saved at 1\n",
      "val_losses[-1] = 0.7992361977696418, best_loss = 1.3217005789279939, model saved at 2\n",
      "val_losses[-1] = 0.6919335309416056, best_loss = 0.7992361977696418, model saved at 3\n",
      "val_losses[-1] = 0.6738320151343942, best_loss = 0.6919335309416056, model saved at 4\n",
      "val_losses[-1] = 0.6272950539365411, best_loss = 0.6738320151343942, model saved at 5\n",
      "val_losses[-1] = 0.5897376390174032, best_loss = 0.6272950539365411, model saved at 6\n",
      "val_losses[-1] = 0.5578597551211715, best_loss = 0.5897376390174032, model saved at 8\n",
      "val_losses[-1] = 0.5487315051257611, best_loss = 0.5578597551211715, model saved at 11\n",
      "val_losses[-1] = 0.5238411037251354, best_loss = 0.5487315051257611, model saved at 12\n",
      "val_losses[-1] = 0.5150708084926009, best_loss = 0.5238411037251354, model saved at 14\n",
      "val_losses[-1] = 0.5018265265971422, best_loss = 0.5150708084926009, model saved at 17\n",
      "val_losses[-1] = 0.5015543535351753, best_loss = 0.5018265265971422, model saved at 19\n",
      "val_losses[-1] = 0.46916790613904596, best_loss = 0.5015543535351753, model saved at 21\n",
      "iter 1\n",
      "val_losses[-1] = 1.215439537167549, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.0567443694919347, best_loss = 1.215439537167549, model saved at 1\n",
      "val_losses[-1] = 1.0473752912133931, best_loss = 1.0567443694919347, model saved at 3\n",
      "val_losses[-1] = 0.9842762388288975, best_loss = 1.0473752912133931, model saved at 4\n",
      "val_losses[-1] = 0.9265065547078848, best_loss = 0.9842762388288975, model saved at 5\n",
      "val_losses[-1] = 0.8769973542541265, best_loss = 0.9265065547078848, model saved at 6\n",
      "val_losses[-1] = 0.7220101892948151, best_loss = 0.8769973542541265, model saved at 7\n",
      "val_losses[-1] = 0.6095827231183648, best_loss = 0.7220101892948151, model saved at 8\n",
      "val_losses[-1] = 0.5920818574726582, best_loss = 0.6095827231183648, model saved at 9\n",
      "val_losses[-1] = 0.5518619542941451, best_loss = 0.5920818574726582, model saved at 10\n",
      "val_losses[-1] = 0.5232763379812241, best_loss = 0.5518619542941451, model saved at 12\n",
      "val_losses[-1] = 0.5198955874890089, best_loss = 0.5232763379812241, model saved at 15\n",
      "val_losses[-1] = 0.5076160514727235, best_loss = 0.5198955874890089, model saved at 17\n",
      "val_losses[-1] = 0.5001098678447307, best_loss = 0.5076160514727235, model saved at 21\n",
      "val_losses[-1] = 0.48407575115561485, best_loss = 0.5001098678447307, model saved at 22\n",
      "val_losses[-1] = 0.478492324706167, best_loss = 0.48407575115561485, model saved at 23\n",
      "val_losses[-1] = 0.47519733002409337, best_loss = 0.478492324706167, model saved at 26\n",
      "iter 2\n",
      "val_losses[-1] = 1.0953374568372964, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.06363046169281, best_loss = 1.0953374568372964, model saved at 1\n",
      "val_losses[-1] = 1.0201744526624679, best_loss = 1.06363046169281, model saved at 2\n",
      "val_losses[-1] = 0.89011175557971, best_loss = 1.0201744526624679, model saved at 6\n",
      "val_losses[-1] = 0.8124223195016385, best_loss = 0.89011175557971, model saved at 7\n",
      "val_losses[-1] = 0.6697471963241697, best_loss = 0.8124223195016385, model saved at 8\n",
      "val_losses[-1] = 0.6187296152114868, best_loss = 0.6697471963241697, model saved at 10\n",
      "val_losses[-1] = 0.5628674799576402, best_loss = 0.6187296152114868, model saved at 11\n",
      "val_losses[-1] = 0.5548240192234516, best_loss = 0.5628674799576402, model saved at 13\n",
      "val_losses[-1] = 0.527312783524394, best_loss = 0.5548240192234516, model saved at 14\n",
      "val_losses[-1] = 0.49652336481958625, best_loss = 0.527312783524394, model saved at 18\n",
      "val_losses[-1] = 0.4859581499360502, best_loss = 0.49652336481958625, model saved at 20\n",
      "val_losses[-1] = 0.4762772426940501, best_loss = 0.4859581499360502, model saved at 21\n",
      "val_losses[-1] = 0.4745632389560342, best_loss = 0.4762772426940501, model saved at 22\n",
      "val_losses[-1] = 0.4651194816455245, best_loss = 0.4745632389560342, model saved at 24\n",
      "val_losses[-1] = 0.4527780920267105, best_loss = 0.4651194816455245, model saved at 25\n",
      "iter 3\n",
      "val_losses[-1] = 0.9139232013374567, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8525744121521711, best_loss = 0.9139232013374567, model saved at 1\n",
      "val_losses[-1] = 0.5958943819627166, best_loss = 0.8525744121521711, model saved at 3\n",
      "val_losses[-1] = 0.5729262985289096, best_loss = 0.5958943819627166, model saved at 5\n",
      "val_losses[-1] = 0.5516792194917798, best_loss = 0.5729262985289096, model saved at 6\n",
      "val_losses[-1] = 0.545353971235454, best_loss = 0.5516792194917798, model saved at 10\n",
      "val_losses[-1] = 0.5065613922663033, best_loss = 0.545353971235454, model saved at 11\n",
      "val_losses[-1] = 0.4842600070871413, best_loss = 0.5065613922663033, model saved at 18\n",
      "val_losses[-1] = 0.48416848564520476, best_loss = 0.4842600070871413, model saved at 21\n",
      "val_losses[-1] = 0.46917724711820485, best_loss = 0.48416848564520476, model saved at 24\n",
      "val_losses[-1] = 0.46274314522743226, best_loss = 0.46917724711820485, model saved at 27\n",
      "val_losses[-1] = 0.4627321668900549, best_loss = 0.46274314522743226, model saved at 28\n",
      "iter 4\n",
      "val_losses[-1] = 1.6093367025256158, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.6081695057451726, best_loss = 1.6093367025256158, model saved at 1\n",
      "val_losses[-1] = 1.6062161214649677, best_loss = 1.6081695057451726, model saved at 2\n",
      "val_losses[-1] = 1.6042174354195595, best_loss = 1.6062161214649677, model saved at 3\n",
      "val_losses[-1] = 1.4438161343336104, best_loss = 1.6042174354195595, model saved at 4\n",
      "val_losses[-1] = 0.7463256165385246, best_loss = 1.4438161343336104, model saved at 5\n",
      "val_losses[-1] = 0.6466807600110769, best_loss = 0.7463256165385246, model saved at 7\n",
      "val_losses[-1] = 0.6413375766947865, best_loss = 0.6466807600110769, model saved at 9\n",
      "val_losses[-1] = 0.5732747642323375, best_loss = 0.6413375766947865, model saved at 10\n",
      "val_losses[-1] = 0.5651265267282725, best_loss = 0.5732747642323375, model saved at 12\n",
      "val_losses[-1] = 0.5557012075558305, best_loss = 0.5651265267282725, model saved at 14\n",
      "val_losses[-1] = 0.5457066260278225, best_loss = 0.5557012075558305, model saved at 15\n",
      "val_losses[-1] = 0.5336826050654053, best_loss = 0.5457066260278225, model saved at 19\n",
      "val_losses[-1] = 0.5308309733867645, best_loss = 0.5336826050654053, model saved at 22\n",
      "val_losses[-1] = 0.5242071905173361, best_loss = 0.5308309733867645, model saved at 23\n",
      "val_losses[-1] = 0.49989911876618864, best_loss = 0.5242071905173361, model saved at 25\n",
      "val_losses[-1] = 0.49738668082281945, best_loss = 0.49989911876618864, model saved at 26\n",
      "val_losses[-1] = 0.4888274561613798, best_loss = 0.49738668082281945, model saved at 27\n",
      "val_losses[-1] = 0.48682062793523073, best_loss = 0.4888274561613798, model saved at 29\n",
      "(1, 0.2)\n",
      "iter 0\n",
      "val_losses[-1] = 1.5552005186676978, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.906992555782199, best_loss = 1.5552005186676978, model saved at 1\n",
      "val_losses[-1] = 0.70529371984303, best_loss = 0.906992555782199, model saved at 2\n",
      "val_losses[-1] = 0.6516605829820037, best_loss = 0.70529371984303, model saved at 3\n",
      "val_losses[-1] = 0.5683382079005241, best_loss = 0.6516605829820037, model saved at 4\n",
      "val_losses[-1] = 0.5300994349643589, best_loss = 0.5683382079005241, model saved at 5\n",
      "val_losses[-1] = 0.5277756264433264, best_loss = 0.5300994349643589, model saved at 6\n",
      "val_losses[-1] = 0.5034361658617854, best_loss = 0.5277756264433264, model saved at 8\n",
      "val_losses[-1] = 0.4900857276283205, best_loss = 0.5034361658617854, model saved at 9\n",
      "val_losses[-1] = 0.46140822060406206, best_loss = 0.4900857276283205, model saved at 12\n",
      "val_losses[-1] = 0.4499739928171039, best_loss = 0.46140822060406206, model saved at 13\n",
      "val_losses[-1] = 0.43859240962192414, best_loss = 0.4499739928171039, model saved at 16\n",
      "iter 1\n",
      "val_losses[-1] = 1.1129495158791542, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.042262229695916, best_loss = 1.1129495158791542, model saved at 1\n",
      "val_losses[-1] = 1.0353030506521463, best_loss = 1.042262229695916, model saved at 3\n",
      "val_losses[-1] = 0.9390386734157801, best_loss = 1.0353030506521463, model saved at 4\n",
      "val_losses[-1] = 0.6665945168584585, best_loss = 0.9390386734157801, model saved at 5\n",
      "val_losses[-1] = 0.6254963379353284, best_loss = 0.6665945168584585, model saved at 6\n",
      "val_losses[-1] = 0.5500019993633032, best_loss = 0.6254963379353284, model saved at 7\n",
      "val_losses[-1] = 0.5432716047391295, best_loss = 0.5500019993633032, model saved at 9\n",
      "val_losses[-1] = 0.5183095465414226, best_loss = 0.5432716047391295, model saved at 12\n",
      "val_losses[-1] = 0.5165420152246952, best_loss = 0.5183095465414226, model saved at 13\n",
      "val_losses[-1] = 0.49774223677814006, best_loss = 0.5165420152246952, model saved at 15\n",
      "val_losses[-1] = 0.4736305184662342, best_loss = 0.49774223677814006, model saved at 17\n",
      "val_losses[-1] = 0.46407335456460713, best_loss = 0.4736305184662342, model saved at 21\n",
      "val_losses[-1] = 0.46098622251302, best_loss = 0.46407335456460713, model saved at 22\n",
      "val_losses[-1] = 0.4480159865692258, best_loss = 0.46098622251302, model saved at 23\n",
      "val_losses[-1] = 0.443622780777514, best_loss = 0.4480159865692258, model saved at 25\n",
      "iter 2\n",
      "val_losses[-1] = 1.0968182940036058, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.0333664286881685, best_loss = 1.0968182940036058, model saved at 1\n",
      "val_losses[-1] = 1.0146338667720556, best_loss = 1.0333664286881685, model saved at 2\n",
      "val_losses[-1] = 1.0073443453758955, best_loss = 1.0146338667720556, model saved at 3\n",
      "val_losses[-1] = 1.00288723744452, best_loss = 1.0073443453758955, model saved at 6\n",
      "val_losses[-1] = 0.7333721060305833, best_loss = 1.00288723744452, model saved at 10\n",
      "val_losses[-1] = 0.6025302100926637, best_loss = 0.7333721060305833, model saved at 11\n",
      "val_losses[-1] = 0.5770847951993346, best_loss = 0.6025302100926637, model saved at 12\n",
      "val_losses[-1] = 0.5359894727356732, best_loss = 0.5770847951993346, model saved at 16\n",
      "val_losses[-1] = 0.5311356704682112, best_loss = 0.5359894727356732, model saved at 17\n",
      "val_losses[-1] = 0.4987050863914192, best_loss = 0.5311356704682112, model saved at 18\n",
      "val_losses[-1] = 0.49725570539012554, best_loss = 0.4987050863914192, model saved at 21\n",
      "val_losses[-1] = 0.4732224363833666, best_loss = 0.49725570539012554, model saved at 24\n",
      "val_losses[-1] = 0.4586753588169813, best_loss = 0.4732224363833666, model saved at 29\n",
      "iter 3\n",
      "val_losses[-1] = 0.7989346336573362, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7786468274891376, best_loss = 0.7989346336573362, model saved at 3\n",
      "val_losses[-1] = 0.7062307910993695, best_loss = 0.7786468274891376, model saved at 5\n",
      "val_losses[-1] = 0.6455105094239115, best_loss = 0.7062307910993695, model saved at 6\n",
      "val_losses[-1] = 0.5823908695951104, best_loss = 0.6455105094239115, model saved at 7\n",
      "val_losses[-1] = 0.5640768699347973, best_loss = 0.5823908695951104, model saved at 8\n",
      "val_losses[-1] = 0.5444303154945374, best_loss = 0.5640768699347973, model saved at 10\n",
      "val_losses[-1] = 0.5211615728214383, best_loss = 0.5444303154945374, model saved at 11\n",
      "val_losses[-1] = 0.5075352340005338, best_loss = 0.5211615728214383, model saved at 13\n",
      "val_losses[-1] = 0.502753446996212, best_loss = 0.5075352340005338, model saved at 17\n",
      "val_losses[-1] = 0.48067771550267935, best_loss = 0.502753446996212, model saved at 18\n",
      "val_losses[-1] = 0.4771847413852811, best_loss = 0.48067771550267935, model saved at 20\n",
      "val_losses[-1] = 0.473580502346158, best_loss = 0.4771847413852811, model saved at 23\n",
      "val_losses[-1] = 0.4614364566281438, best_loss = 0.473580502346158, model saved at 25\n",
      "iter 4\n",
      "val_losses[-1] = 1.610817976295948, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.6088421396911143, best_loss = 1.610817976295948, model saved at 1\n",
      "val_losses[-1] = 1.605709907412529, best_loss = 1.6088421396911143, model saved at 2\n",
      "val_losses[-1] = 1.2814002808183431, best_loss = 1.605709907412529, model saved at 3\n",
      "val_losses[-1] = 0.7063201025128365, best_loss = 1.2814002808183431, model saved at 4\n",
      "val_losses[-1] = 0.6407115276902914, best_loss = 0.7063201025128365, model saved at 5\n",
      "val_losses[-1] = 0.6125440204516053, best_loss = 0.6407115276902914, model saved at 7\n",
      "val_losses[-1] = 0.5688161220401525, best_loss = 0.6125440204516053, model saved at 10\n",
      "val_losses[-1] = 0.5662543524056673, best_loss = 0.5688161220401525, model saved at 12\n",
      "val_losses[-1] = 0.5519995087757706, best_loss = 0.5662543524056673, model saved at 13\n",
      "val_losses[-1] = 0.5481635235249996, best_loss = 0.5519995087757706, model saved at 14\n",
      "val_losses[-1] = 0.5398416256532073, best_loss = 0.5481635235249996, model saved at 16\n",
      "val_losses[-1] = 0.5365030976943672, best_loss = 0.5398416256532073, model saved at 18\n",
      "val_losses[-1] = 0.5059166193939746, best_loss = 0.5365030976943672, model saved at 19\n",
      "val_losses[-1] = 0.5037038959562778, best_loss = 0.5059166193939746, model saved at 20\n",
      "val_losses[-1] = 0.48041953397914766, best_loss = 0.5037038959562778, model saved at 22\n",
      "val_losses[-1] = 0.4623520506545901, best_loss = 0.48041953397914766, model saved at 26\n",
      "val_losses[-1] = 0.461646999232471, best_loss = 0.4623520506545901, model saved at 28\n",
      "(1, 0.1)\n",
      "iter 0\n",
      "val_losses[-1] = 1.4175239033997058, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7225383074954153, best_loss = 1.4175239033997058, model saved at 1\n",
      "val_losses[-1] = 0.6533057104796172, best_loss = 0.7225383074954153, model saved at 2\n",
      "val_losses[-1] = 0.5385827226564288, best_loss = 0.6533057104796172, model saved at 3\n",
      "val_losses[-1] = 0.5271679341793061, best_loss = 0.5385827226564288, model saved at 5\n",
      "val_losses[-1] = 0.5102057442069053, best_loss = 0.5271679341793061, model saved at 6\n",
      "val_losses[-1] = 0.4805579274892807, best_loss = 0.5102057442069053, model saved at 7\n",
      "val_losses[-1] = 0.4718097566626966, best_loss = 0.4805579274892807, model saved at 9\n",
      "val_losses[-1] = 0.4676962920464575, best_loss = 0.4718097566626966, model saved at 11\n",
      "val_losses[-1] = 0.4490087377373129, best_loss = 0.4676962920464575, model saved at 13\n",
      "val_losses[-1] = 0.44388928152620793, best_loss = 0.4490087377373129, model saved at 16\n",
      "val_losses[-1] = 0.44103371873497965, best_loss = 0.44388928152620793, model saved at 24\n",
      "iter 1\n",
      "val_losses[-1] = 1.116620361432433, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.0256861049681902, best_loss = 1.116620361432433, model saved at 1\n",
      "val_losses[-1] = 1.0090546939522027, best_loss = 1.0256861049681902, model saved at 2\n",
      "val_losses[-1] = 0.6952768731862307, best_loss = 1.0090546939522027, model saved at 4\n",
      "val_losses[-1] = 0.5788409883156419, best_loss = 0.6952768731862307, model saved at 5\n",
      "val_losses[-1] = 0.5507971657440066, best_loss = 0.5788409883156419, model saved at 6\n",
      "val_losses[-1] = 0.5335262896493077, best_loss = 0.5507971657440066, model saved at 7\n",
      "val_losses[-1] = 0.49885409949347376, best_loss = 0.5335262896493077, model saved at 8\n",
      "val_losses[-1] = 0.49457921255379916, best_loss = 0.49885409949347376, model saved at 13\n",
      "val_losses[-1] = 0.48483763691037896, best_loss = 0.49457921255379916, model saved at 15\n",
      "val_losses[-1] = 0.473655940592289, best_loss = 0.48483763691037896, model saved at 17\n",
      "val_losses[-1] = 0.47269760658964516, best_loss = 0.473655940592289, model saved at 19\n",
      "val_losses[-1] = 0.46354588558897375, best_loss = 0.47269760658964516, model saved at 20\n",
      "val_losses[-1] = 0.4484441517852247, best_loss = 0.46354588558897375, model saved at 21\n",
      "val_losses[-1] = 0.4475776990875602, best_loss = 0.4484441517852247, model saved at 29\n",
      "iter 2\n",
      "val_losses[-1] = 1.128143571689725, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.0146291524171829, best_loss = 1.128143571689725, model saved at 1\n",
      "val_losses[-1] = 0.9160937871783972, best_loss = 1.0146291524171829, model saved at 2\n",
      "val_losses[-1] = 0.6444419223815203, best_loss = 0.9160937871783972, model saved at 3\n",
      "val_losses[-1] = 0.5596914380788803, best_loss = 0.6444419223815203, model saved at 6\n",
      "val_losses[-1] = 0.5349105129018425, best_loss = 0.5596914380788803, model saved at 7\n",
      "val_losses[-1] = 0.49897311283275486, best_loss = 0.5349105129018425, model saved at 9\n",
      "val_losses[-1] = 0.4879959148354828, best_loss = 0.49897311283275486, model saved at 10\n",
      "val_losses[-1] = 0.4610143290832639, best_loss = 0.4879959148354828, model saved at 13\n",
      "val_losses[-1] = 0.45789886061102153, best_loss = 0.4610143290832639, model saved at 16\n",
      "val_losses[-1] = 0.4480897966772318, best_loss = 0.45789886061102153, model saved at 20\n",
      "iter 3\n",
      "val_losses[-1] = 0.826761045306921, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7713819783180952, best_loss = 0.826761045306921, model saved at 2\n",
      "val_losses[-1] = 0.544260280020535, best_loss = 0.7713819783180952, model saved at 3\n",
      "val_losses[-1] = 0.5261703725904227, best_loss = 0.544260280020535, model saved at 4\n",
      "val_losses[-1] = 0.49285770701244475, best_loss = 0.5261703725904227, model saved at 8\n",
      "val_losses[-1] = 0.47830330170691016, best_loss = 0.49285770701244475, model saved at 11\n",
      "val_losses[-1] = 0.4713786840438843, best_loss = 0.47830330170691016, model saved at 14\n",
      "val_losses[-1] = 0.4473342358134687, best_loss = 0.4713786840438843, model saved at 15\n",
      "val_losses[-1] = 0.4411384353414178, best_loss = 0.4473342358134687, model saved at 18\n",
      "val_losses[-1] = 0.4309561555273831, best_loss = 0.4411384353414178, model saved at 19\n",
      "val_losses[-1] = 0.4293485342524946, best_loss = 0.4309561555273831, model saved at 20\n",
      "iter 4\n",
      "val_losses[-1] = 1.6102238535881042, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.6092619650065898, best_loss = 1.6102238535881042, model saved at 1\n",
      "val_losses[-1] = 1.5975457713007928, best_loss = 1.6092619650065898, model saved at 2\n",
      "val_losses[-1] = 0.7392711281776428, best_loss = 1.5975457713007928, model saved at 3\n",
      "val_losses[-1] = 0.6283461343497038, best_loss = 0.7392711281776428, model saved at 4\n",
      "val_losses[-1] = 0.5884788170456886, best_loss = 0.6283461343497038, model saved at 5\n",
      "val_losses[-1] = 0.5881195353344083, best_loss = 0.5884788170456886, model saved at 7\n",
      "val_losses[-1] = 0.5747915579006075, best_loss = 0.5881195353344083, model saved at 8\n",
      "val_losses[-1] = 0.5379164803773164, best_loss = 0.5747915579006075, model saved at 10\n",
      "val_losses[-1] = 0.5047224745154381, best_loss = 0.5379164803773164, model saved at 11\n",
      "val_losses[-1] = 0.47550429543480277, best_loss = 0.5047224745154381, model saved at 12\n",
      "val_losses[-1] = 0.45841976236552, best_loss = 0.47550429543480277, model saved at 15\n",
      "val_losses[-1] = 0.44763669539242984, best_loss = 0.45841976236552, model saved at 16\n",
      "val_losses[-1] = 0.4427878988906741, best_loss = 0.44763669539242984, model saved at 20\n",
      "val_losses[-1] = 0.4416243053041399, best_loss = 0.4427878988906741, model saved at 23\n",
      "val_losses[-1] = 0.44159691147506236, best_loss = 0.4416243053041399, model saved at 25\n",
      "val_losses[-1] = 0.43619657373055815, best_loss = 0.44159691147506236, model saved at 26\n"
     ]
    }
   ],
   "source": [
    "num_iter = 5\n",
    "\n",
    "for loss_ratios in all_loss_ratios:\n",
    "    print(loss_ratios)\n",
    "    \n",
    "    models = []\n",
    "    for j in range(num_iter):\n",
    "        print(f\"iter {j}\")\n",
    "        dataset = torch.load(f\"data/amc_data_512_case_0.pt\")\n",
    "        train_loader = dataset['train_loader']\n",
    "        val_loader = dataset['val_loader']\n",
    "        \n",
    "        torch.manual_seed(j)\n",
    "        model_mtl = amc_model_mtl()\n",
    "        model_mtl.cuda()\n",
    "\n",
    "        optimizer = torch.optim.Adam(model_mtl.parameters(), lr=0.0005, weight_decay=0.0001)\n",
    "\n",
    "        model, losses, losses_mod, losses_snr, val_losses, val_losses_snr = train_mtl(model_mtl, optimizer, train_loader, \n",
    "                                                                                      val_loader, loss_fns, \n",
    "                                                                                      num_epochs=num_epochs, verbose=False, \n",
    "                                                                                      loss_ratios=loss_ratios)\n",
    "        \n",
    "        model_config = {\"weights\": model_mtl.state_dict(),\n",
    "                        \"losses\": losses,\n",
    "                        \"val_losses\": val_losses,\n",
    "                        \"losses_mod\": losses_mod,\n",
    "                        \"losses_snr\": losses_snr,\n",
    "                        \"val_losses_snr\": val_losses_snr}\n",
    "        \n",
    "        models.append(model_config)\n",
    "    torch.save(models, f'models/case_0/amc_{loss_ratios[0]}_{loss_ratios[1]}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "490cd119-93b0-486f-bcf9-56497eee2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_mtl(model, snr_range, num_frames=128, samples_per_frame=1024):\n",
    "    accs = []\n",
    "    snr_errs = []\n",
    "\n",
    "    model.eval().cpu()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for snr in snr_range:\n",
    "\n",
    "            bpsk_data, _ = gen_tensor_data('BPSK', num_frames=num_frames, samples_per_frame=samples_per_frame, snr=snr)\n",
    "            qpsk_data, _ = gen_tensor_data('QPSK', num_frames=num_frames, samples_per_frame=samples_per_frame, snr=snr)\n",
    "            psk_data, _ = gen_tensor_data('8-PSK', num_frames=num_frames, samples_per_frame=samples_per_frame, snr=snr)\n",
    "            qam_data, _ = gen_tensor_data('16-QAM', num_frames=num_frames, samples_per_frame=samples_per_frame, snr=snr)\n",
    "            ask_data, _ = gen_tensor_data('4-ASK', num_frames=num_frames, samples_per_frame=samples_per_frame, snr=snr)\n",
    "\n",
    "            test_data = torch.cat((bpsk_data, qpsk_data, psk_data, qam_data, ask_data))\n",
    "\n",
    "            bpsk_labels = torch.zeros(bpsk_data.shape[0])\n",
    "            qpsk_labels = torch.ones(qpsk_data.shape[0])\n",
    "            psk_labels = torch.ones(qam_data.shape[0])*2\n",
    "            qam_labels = torch.ones(qam_data.shape[0])*3\n",
    "            ask_labels = torch.ones(ask_data.shape[0])*4\n",
    "\n",
    "            test_labels = torch.cat((bpsk_labels, qpsk_labels, psk_labels, qam_labels, ask_labels))\n",
    "\n",
    "            y_hat, snr_hat = model(test_data)\n",
    "            \n",
    "            results = torch.argmax(y_hat, axis=1)\n",
    "            \n",
    "            accs.append(torch.sum(results == test_labels).float() / test_data.shape[0])\n",
    "            \n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0617de5f-6f76-46a8-b0dc-b64a09b74b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.9)\n",
      "(1, 0.8)\n",
      "(1, 0.7)\n",
      "(1, 0.6)\n",
      "(1, 0.5)\n",
      "(1, 0.4)\n",
      "(1, 0.3)\n",
      "(1, 0.2)\n",
      "(1, 0.1)\n"
     ]
    }
   ],
   "source": [
    "snr_range = np.arange(-15,16,2)\n",
    "\n",
    "# for models in sorted(os.listdir('models')):\n",
    "for loss_ratios in all_loss_ratios:\n",
    "    print(loss_ratios)\n",
    "    results = []\n",
    "    for model in torch.load(f'models/case_0/amc_{loss_ratios[0]}_{loss_ratios[1]}.pt'):\n",
    "        model_mtl = amc_model_mtl()\n",
    "        model_mtl.load_state_dict(model['weights'])\n",
    "        accs_mod = test_model_mtl(model_mtl, snr_range, num_frames=128)\n",
    "        \n",
    "        result = {\"accs_mod\": accs_mod,\n",
    "                   \"snr_range\": snr_range,\n",
    "                   \"model\": model}\n",
    "        results.append(result)\n",
    "    torch.save(results, f'results/case_0/amc_{loss_ratios[0]}_{loss_ratios[1]}.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8374c98-4563-43c0-b782-843db28e8f67",
   "metadata": {},
   "source": [
    "## Add MTL, case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05401873-89fc-4b31-bac4-5bf2ca0aa96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_snr = np.arange(-15,16,2)\n",
    "\n",
    "train_loader = gen_loader(num_frames=512, snr=train_snr, batch_size=32, case=1)\n",
    "val_loader = gen_loader(num_frames=64, snr=train_snr, batch_size=32, case=1)\n",
    "\n",
    "dataset = {'train_loader': train_loader,\n",
    "           'val_loader': val_loader}\n",
    "\n",
    "torch.save(dataset, f\"data/amc_data_512_case_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e3d3c81-10d8-42ef-8f16-7df00855ade2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.9)\n",
      "iter 0\n",
      "val_losses[-1] = 1.441458959132433, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.971820030361414, best_loss = 1.441458959132433, model saved at 1\n",
      "val_losses[-1] = 0.7484014149755239, best_loss = 0.971820030361414, model saved at 2\n",
      "val_losses[-1] = 0.7161662861704826, best_loss = 0.7484014149755239, model saved at 3\n",
      "val_losses[-1] = 0.6407490365207196, best_loss = 0.7161662861704826, model saved at 4\n",
      "val_losses[-1] = 0.6119059583172202, best_loss = 0.6407490365207196, model saved at 5\n",
      "val_losses[-1] = 0.5840258114039898, best_loss = 0.6119059583172202, model saved at 6\n",
      "val_losses[-1] = 0.574721753038466, best_loss = 0.5840258114039898, model saved at 7\n",
      "val_losses[-1] = 0.527362172678113, best_loss = 0.574721753038466, model saved at 9\n",
      "val_losses[-1] = 0.5004938848316669, best_loss = 0.527362172678113, model saved at 10\n",
      "val_losses[-1] = 0.4578455202281475, best_loss = 0.5004938848316669, model saved at 14\n",
      "val_losses[-1] = 0.4421844758559018, best_loss = 0.4578455202281475, model saved at 17\n",
      "val_losses[-1] = 0.43409531507641075, best_loss = 0.4421844758559018, model saved at 24\n",
      "val_losses[-1] = 0.4310732212848961, best_loss = 0.43409531507641075, model saved at 27\n",
      "iter 1\n",
      "val_losses[-1] = 1.2065691877156497, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8369298808276653, best_loss = 1.2065691877156497, model saved at 1\n",
      "val_losses[-1] = 0.7451147709041834, best_loss = 0.8369298808276653, model saved at 3\n",
      "val_losses[-1] = 0.6519248289987445, best_loss = 0.7451147709041834, model saved at 4\n",
      "val_losses[-1] = 0.5400918150320649, best_loss = 0.6519248289987445, model saved at 6\n",
      "val_losses[-1] = 0.4823295554146171, best_loss = 0.5400918150320649, model saved at 8\n",
      "val_losses[-1] = 0.4636588651686907, best_loss = 0.4823295554146171, model saved at 11\n",
      "val_losses[-1] = 0.4530723393894732, best_loss = 0.4636588651686907, model saved at 13\n",
      "val_losses[-1] = 0.4477542256936431, best_loss = 0.4530723393894732, model saved at 14\n",
      "val_losses[-1] = 0.43589276894927026, best_loss = 0.4477542256936431, model saved at 18\n",
      "val_losses[-1] = 0.4347468839026988, best_loss = 0.43589276894927026, model saved at 28\n",
      "iter 2\n",
      "val_losses[-1] = 1.6118403904139995, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8851194527000189, best_loss = 1.6118403904139995, model saved at 1\n",
      "val_losses[-1] = 0.7630913950502872, best_loss = 0.8851194527000189, model saved at 2\n",
      "val_losses[-1] = 0.7506432821974158, best_loss = 0.7630913950502872, model saved at 4\n",
      "val_losses[-1] = 0.62507827244699, best_loss = 0.7506432821974158, model saved at 5\n",
      "val_losses[-1] = 0.5866445673629641, best_loss = 0.62507827244699, model saved at 7\n",
      "val_losses[-1] = 0.5318067716434598, best_loss = 0.5866445673629641, model saved at 11\n",
      "val_losses[-1] = 0.4915599306114018, best_loss = 0.5318067716434598, model saved at 12\n",
      "val_losses[-1] = 0.47245982894673944, best_loss = 0.4915599306114018, model saved at 13\n",
      "val_losses[-1] = 0.45291751390323043, best_loss = 0.47245982894673944, model saved at 18\n",
      "val_losses[-1] = 0.4512118902988732, best_loss = 0.45291751390323043, model saved at 21\n",
      "val_losses[-1] = 0.4469877382740378, best_loss = 0.4512118902988732, model saved at 22\n",
      "val_losses[-1] = 0.4309975293464959, best_loss = 0.4469877382740378, model saved at 27\n",
      "iter 3\n",
      "val_losses[-1] = 1.603373397141695, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.26770511418581, best_loss = 1.603373397141695, model saved at 1\n",
      "val_losses[-1] = 0.8342394832521677, best_loss = 1.26770511418581, model saved at 2\n",
      "val_losses[-1] = 0.8278367914259434, best_loss = 0.8342394832521677, model saved at 3\n",
      "val_losses[-1] = 0.680289932154119, best_loss = 0.8278367914259434, model saved at 4\n",
      "val_losses[-1] = 0.6479088759049774, best_loss = 0.680289932154119, model saved at 5\n",
      "val_losses[-1] = 0.5948920782655478, best_loss = 0.6479088759049774, model saved at 6\n",
      "val_losses[-1] = 0.5120016905479133, best_loss = 0.5948920782655478, model saved at 8\n",
      "val_losses[-1] = 0.474077710416168, best_loss = 0.5120016905479133, model saved at 11\n",
      "val_losses[-1] = 0.4686712212860584, best_loss = 0.474077710416168, model saved at 14\n",
      "val_losses[-1] = 0.45380830205976963, best_loss = 0.4686712212860584, model saved at 16\n",
      "val_losses[-1] = 0.4477460809983313, best_loss = 0.45380830205976963, model saved at 19\n",
      "iter 4\n",
      "val_losses[-1] = 1.467377483844757, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.9990019552409649, best_loss = 1.467377483844757, model saved at 1\n",
      "val_losses[-1] = 0.7924758043140173, best_loss = 0.9990019552409649, model saved at 2\n",
      "val_losses[-1] = 0.7812780762091279, best_loss = 0.7924758043140173, model saved at 3\n",
      "val_losses[-1] = 0.7386119224131107, best_loss = 0.7812780762091279, model saved at 4\n",
      "val_losses[-1] = 0.6538483066484332, best_loss = 0.7386119224131107, model saved at 5\n",
      "val_losses[-1] = 0.6134062148630619, best_loss = 0.6538483066484332, model saved at 6\n",
      "val_losses[-1] = 0.6041960878297686, best_loss = 0.6134062148630619, model saved at 7\n",
      "val_losses[-1] = 0.55773662077263, best_loss = 0.6041960878297686, model saved at 8\n",
      "val_losses[-1] = 0.5294381261803209, best_loss = 0.55773662077263, model saved at 9\n",
      "val_losses[-1] = 0.4775606752373278, best_loss = 0.5294381261803209, model saved at 11\n",
      "val_losses[-1] = 0.45746817272156476, best_loss = 0.4775606752373278, model saved at 12\n",
      "val_losses[-1] = 0.45262272711843254, best_loss = 0.45746817272156476, model saved at 16\n",
      "val_losses[-1] = 0.44507154282182454, best_loss = 0.45262272711843254, model saved at 22\n",
      "val_losses[-1] = 0.43469662871211767, best_loss = 0.44507154282182454, model saved at 24\n",
      "val_losses[-1] = 0.4268490059301257, best_loss = 0.43469662871211767, model saved at 28\n",
      "(1, 0.8)\n",
      "iter 0\n",
      "val_losses[-1] = 1.539451827853918, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.9839578386396169, best_loss = 1.539451827853918, model saved at 1\n",
      "val_losses[-1] = 0.7737268969416619, best_loss = 0.9839578386396169, model saved at 2\n",
      "val_losses[-1] = 0.7276295833289623, best_loss = 0.7737268969416619, model saved at 3\n",
      "val_losses[-1] = 0.6585855390876532, best_loss = 0.7276295833289623, model saved at 4\n",
      "val_losses[-1] = 0.6414489848539233, best_loss = 0.6585855390876532, model saved at 5\n",
      "val_losses[-1] = 0.5883097518235445, best_loss = 0.6414489848539233, model saved at 6\n",
      "val_losses[-1] = 0.5137916320934892, best_loss = 0.5883097518235445, model saved at 8\n",
      "val_losses[-1] = 0.5091606019064784, best_loss = 0.5137916320934892, model saved at 9\n",
      "val_losses[-1] = 0.4965270522981882, best_loss = 0.5091606019064784, model saved at 10\n",
      "val_losses[-1] = 0.48575532604008914, best_loss = 0.4965270522981882, model saved at 12\n",
      "val_losses[-1] = 0.4639093725942075, best_loss = 0.48575532604008914, model saved at 14\n",
      "val_losses[-1] = 0.45702895177528263, best_loss = 0.4639093725942075, model saved at 15\n",
      "val_losses[-1] = 0.4412677283398807, best_loss = 0.45702895177528263, model saved at 17\n",
      "val_losses[-1] = 0.4388200841844082, best_loss = 0.4412677283398807, model saved at 25\n",
      "val_losses[-1] = 0.4387532946188003, best_loss = 0.4388200841844082, model saved at 26\n",
      "val_losses[-1] = 0.42909765476360917, best_loss = 0.4387532946188003, model saved at 27\n",
      "iter 1\n",
      "val_losses[-1] = 1.2497209165245295, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8271559979766607, best_loss = 1.2497209165245295, model saved at 1\n",
      "val_losses[-1] = 0.7687406282871961, best_loss = 0.8271559979766607, model saved at 3\n",
      "val_losses[-1] = 0.5988578401505947, best_loss = 0.7687406282871961, model saved at 4\n",
      "val_losses[-1] = 0.5801163677126169, best_loss = 0.5988578401505947, model saved at 6\n",
      "val_losses[-1] = 0.5413288188166916, best_loss = 0.5801163677126169, model saved at 7\n",
      "val_losses[-1] = 0.4743326151743531, best_loss = 0.5413288188166916, model saved at 8\n",
      "val_losses[-1] = 0.457181787211448, best_loss = 0.4743326151743531, model saved at 11\n",
      "val_losses[-1] = 0.44384250687435267, best_loss = 0.457181787211448, model saved at 13\n",
      "val_losses[-1] = 0.4368056905455887, best_loss = 0.44384250687435267, model saved at 18\n",
      "val_losses[-1] = 0.42795623978599906, best_loss = 0.4368056905455887, model saved at 20\n",
      "iter 2\n",
      "val_losses[-1] = 1.607857594639063, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.0826073084026575, best_loss = 1.607857594639063, model saved at 1\n",
      "val_losses[-1] = 0.8757015470415354, best_loss = 1.0826073084026575, model saved at 2\n",
      "val_losses[-1] = 0.7089599242433906, best_loss = 0.8757015470415354, model saved at 4\n",
      "val_losses[-1] = 0.6706059589982033, best_loss = 0.7089599242433906, model saved at 5\n",
      "val_losses[-1] = 0.6285196200013161, best_loss = 0.6706059589982033, model saved at 7\n",
      "val_losses[-1] = 0.600017799437046, best_loss = 0.6285196200013161, model saved at 8\n",
      "val_losses[-1] = 0.5428310973569751, best_loss = 0.600017799437046, model saved at 9\n",
      "val_losses[-1] = 0.5264931839890779, best_loss = 0.5428310973569751, model saved at 11\n",
      "val_losses[-1] = 0.48438114589080217, best_loss = 0.5264931839890779, model saved at 12\n",
      "val_losses[-1] = 0.4711502750404179, best_loss = 0.48438114589080217, model saved at 13\n",
      "val_losses[-1] = 0.46301424838602545, best_loss = 0.4711502750404179, model saved at 16\n",
      "val_losses[-1] = 0.45326772835105655, best_loss = 0.46301424838602545, model saved at 17\n",
      "val_losses[-1] = 0.43980701118707655, best_loss = 0.45326772835105655, model saved at 22\n",
      "val_losses[-1] = 0.4295516126789153, best_loss = 0.43980701118707655, model saved at 27\n",
      "iter 3\n",
      "val_losses[-1] = 1.5961070582270622, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.096156272664666, best_loss = 1.5961070582270622, model saved at 1\n",
      "val_losses[-1] = 0.7944150034338235, best_loss = 1.096156272664666, model saved at 2\n",
      "val_losses[-1] = 0.698326332308352, best_loss = 0.7944150034338235, model saved at 3\n",
      "val_losses[-1] = 0.6607150830328464, best_loss = 0.698326332308352, model saved at 4\n",
      "val_losses[-1] = 0.5783019740134477, best_loss = 0.6607150830328464, model saved at 6\n",
      "val_losses[-1] = 0.5639043901115656, best_loss = 0.5783019740134477, model saved at 7\n",
      "val_losses[-1] = 0.5209764142520725, best_loss = 0.5639043901115656, model saved at 8\n",
      "val_losses[-1] = 0.5152718957513571, best_loss = 0.5209764142520725, model saved at 10\n",
      "val_losses[-1] = 0.5000182037241757, best_loss = 0.5152718957513571, model saved at 11\n",
      "val_losses[-1] = 0.4930937680415809, best_loss = 0.5000182037241757, model saved at 12\n",
      "val_losses[-1] = 0.46153875924646853, best_loss = 0.4930937680415809, model saved at 15\n",
      "val_losses[-1] = 0.4488841426558793, best_loss = 0.46153875924646853, model saved at 17\n",
      "val_losses[-1] = 0.4296343468129635, best_loss = 0.4488841426558793, model saved at 20\n",
      "iter 4\n",
      "val_losses[-1] = 1.3419309005141258, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.9809491198509932, best_loss = 1.3419309005141258, model saved at 1\n",
      "val_losses[-1] = 0.7645765405148268, best_loss = 0.9809491198509932, model saved at 2\n",
      "val_losses[-1] = 0.7644649202004075, best_loss = 0.7645765405148268, model saved at 4\n",
      "val_losses[-1] = 0.6625872066244483, best_loss = 0.7644649202004075, model saved at 5\n",
      "val_losses[-1] = 0.5776323184370995, best_loss = 0.6625872066244483, model saved at 6\n",
      "val_losses[-1] = 0.5604400252923369, best_loss = 0.5776323184370995, model saved at 7\n",
      "val_losses[-1] = 0.5263772479258477, best_loss = 0.5604400252923369, model saved at 8\n",
      "val_losses[-1] = 0.4888208005577326, best_loss = 0.5263772479258477, model saved at 9\n",
      "val_losses[-1] = 0.4761270056478679, best_loss = 0.4888208005577326, model saved at 11\n",
      "val_losses[-1] = 0.45907400427386164, best_loss = 0.4761270056478679, model saved at 12\n",
      "val_losses[-1] = 0.43779598036780953, best_loss = 0.45907400427386164, model saved at 16\n",
      "(1, 0.7)\n",
      "iter 0\n",
      "val_losses[-1] = 1.2907054722309113, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8554642293602228, best_loss = 1.2907054722309113, model saved at 1\n",
      "val_losses[-1] = 0.7284914225339889, best_loss = 0.8554642293602228, model saved at 2\n",
      "val_losses[-1] = 0.6651306927204133, best_loss = 0.7284914225339889, model saved at 3\n",
      "val_losses[-1] = 0.6003310285508633, best_loss = 0.6651306927204133, model saved at 4\n",
      "val_losses[-1] = 0.5754546580836177, best_loss = 0.6003310285508633, model saved at 5\n",
      "val_losses[-1] = 0.5444762545637787, best_loss = 0.5754546580836177, model saved at 9\n",
      "val_losses[-1] = 0.4989858090877533, best_loss = 0.5444762545637787, model saved at 10\n",
      "val_losses[-1] = 0.49001417299732564, best_loss = 0.4989858090877533, model saved at 12\n",
      "val_losses[-1] = 0.45731857949867843, best_loss = 0.49001417299732564, model saved at 14\n",
      "val_losses[-1] = 0.44399119466543197, best_loss = 0.45731857949867843, model saved at 17\n",
      "val_losses[-1] = 0.43173595601692794, best_loss = 0.44399119466543197, model saved at 20\n",
      "val_losses[-1] = 0.4276348521001637, best_loss = 0.43173595601692794, model saved at 27\n",
      "iter 1\n",
      "val_losses[-1] = 1.1863127160817384, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.794898620992899, best_loss = 1.1863127160817384, model saved at 1\n",
      "val_losses[-1] = 0.7756557680666447, best_loss = 0.794898620992899, model saved at 2\n",
      "val_losses[-1] = 0.7154479704797267, best_loss = 0.7756557680666447, model saved at 3\n",
      "val_losses[-1] = 0.5927832534536719, best_loss = 0.7154479704797267, model saved at 4\n",
      "val_losses[-1] = 0.5446446004323662, best_loss = 0.5927832534536719, model saved at 7\n",
      "val_losses[-1] = 0.47523350091651084, best_loss = 0.5446446004323662, model saved at 8\n",
      "val_losses[-1] = 0.46388953030109403, best_loss = 0.47523350091651084, model saved at 13\n",
      "val_losses[-1] = 0.4578611541539431, best_loss = 0.46388953030109403, model saved at 14\n",
      "val_losses[-1] = 0.4480658731423318, best_loss = 0.4578611541539431, model saved at 17\n",
      "val_losses[-1] = 0.4427266623824835, best_loss = 0.4480658731423318, model saved at 18\n",
      "val_losses[-1] = 0.43514302335679533, best_loss = 0.4427266623824835, model saved at 20\n",
      "val_losses[-1] = 0.43434267938137056, best_loss = 0.43514302335679533, model saved at 22\n",
      "val_losses[-1] = 0.43343582963570954, best_loss = 0.43434267938137056, model saved at 24\n",
      "iter 2\n",
      "val_losses[-1] = 1.5943815685808658, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.0544136449694634, best_loss = 1.5943815685808658, model saved at 1\n",
      "val_losses[-1] = 0.8437908861786128, best_loss = 1.0544136449694634, model saved at 2\n",
      "val_losses[-1] = 0.7967570934444665, best_loss = 0.8437908861786128, model saved at 3\n",
      "val_losses[-1] = 0.7209209052845835, best_loss = 0.7967570934444665, model saved at 5\n",
      "val_losses[-1] = 0.7145916385576129, best_loss = 0.7209209052845835, model saved at 6\n",
      "val_losses[-1] = 0.6432431381195783, best_loss = 0.7145916385576129, model saved at 7\n",
      "val_losses[-1] = 0.5631861589848995, best_loss = 0.6432431381195783, model saved at 8\n",
      "val_losses[-1] = 0.5427997763268649, best_loss = 0.5631861589848995, model saved at 9\n",
      "val_losses[-1] = 0.5398919427767396, best_loss = 0.5427997763268649, model saved at 10\n",
      "val_losses[-1] = 0.509759517852217, best_loss = 0.5398919427767396, model saved at 11\n",
      "val_losses[-1] = 0.4975472575984895, best_loss = 0.509759517852217, model saved at 12\n",
      "val_losses[-1] = 0.45069860769435766, best_loss = 0.4975472575984895, model saved at 16\n",
      "val_losses[-1] = 0.4418502999469638, best_loss = 0.45069860769435766, model saved at 18\n",
      "val_losses[-1] = 0.43889031643047927, best_loss = 0.4418502999469638, model saved at 21\n",
      "val_losses[-1] = 0.42119640335440633, best_loss = 0.43889031643047927, model saved at 27\n",
      "iter 3\n",
      "val_losses[-1] = 1.6033273339271545, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.1884796783328055, best_loss = 1.6033273339271545, model saved at 1\n",
      "val_losses[-1] = 0.7594507083296775, best_loss = 1.1884796783328055, model saved at 2\n",
      "val_losses[-1] = 0.6569696245715022, best_loss = 0.7594507083296775, model saved at 4\n",
      "val_losses[-1] = 0.6435513058677316, best_loss = 0.6569696245715022, model saved at 5\n",
      "val_losses[-1] = 0.6399854118004441, best_loss = 0.6435513058677316, model saved at 6\n",
      "val_losses[-1] = 0.49116609590128063, best_loss = 0.6399854118004441, model saved at 8\n",
      "val_losses[-1] = 0.45249823229387404, best_loss = 0.49116609590128063, model saved at 11\n",
      "val_losses[-1] = 0.4517596159130335, best_loss = 0.45249823229387404, model saved at 12\n",
      "val_losses[-1] = 0.45150233563035724, best_loss = 0.4517596159130335, model saved at 18\n",
      "val_losses[-1] = 0.43870200403034687, best_loss = 0.45150233563035724, model saved at 19\n",
      "val_losses[-1] = 0.43434544978663325, best_loss = 0.43870200403034687, model saved at 21\n",
      "iter 4\n",
      "val_losses[-1] = 1.5428030021488666, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.0516868371516466, best_loss = 1.5428030021488666, model saved at 1\n",
      "val_losses[-1] = 0.8001990247517824, best_loss = 1.0516868371516466, model saved at 2\n",
      "val_losses[-1] = 0.7268178196623921, best_loss = 0.8001990247517824, model saved at 4\n",
      "val_losses[-1] = 0.6669844221323729, best_loss = 0.7268178196623921, model saved at 5\n",
      "val_losses[-1] = 0.6102093484252691, best_loss = 0.6669844221323729, model saved at 6\n",
      "val_losses[-1] = 0.6062527537345886, best_loss = 0.6102093484252691, model saved at 7\n",
      "val_losses[-1] = 0.5832010012120008, best_loss = 0.6062527537345886, model saved at 9\n",
      "val_losses[-1] = 0.5212496461346745, best_loss = 0.5832010012120008, model saved at 10\n",
      "val_losses[-1] = 0.4865068966522813, best_loss = 0.5212496461346745, model saved at 11\n",
      "val_losses[-1] = 0.4773798009380698, best_loss = 0.4865068966522813, model saved at 12\n",
      "val_losses[-1] = 0.4425034403800964, best_loss = 0.4773798009380698, model saved at 16\n",
      "val_losses[-1] = 0.4373517161235213, best_loss = 0.4425034403800964, model saved at 22\n",
      "(1, 0.6)\n",
      "iter 0\n",
      "val_losses[-1] = 1.4768140114843846, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8695493668317795, best_loss = 1.4768140114843846, model saved at 1\n",
      "val_losses[-1] = 0.7282904602587223, best_loss = 0.8695493668317795, model saved at 2\n",
      "val_losses[-1] = 0.6633706774562598, best_loss = 0.7282904602587223, model saved at 3\n",
      "val_losses[-1] = 0.5993785599246622, best_loss = 0.6633706774562598, model saved at 4\n",
      "val_losses[-1] = 0.5817475112155079, best_loss = 0.5993785599246622, model saved at 5\n",
      "val_losses[-1] = 0.5291757997125387, best_loss = 0.5817475112155079, model saved at 8\n",
      "val_losses[-1] = 0.5241466399282217, best_loss = 0.5291757997125387, model saved at 12\n",
      "val_losses[-1] = 0.49720113053917886, best_loss = 0.5241466399282217, model saved at 14\n",
      "val_losses[-1] = 0.4784591030329466, best_loss = 0.49720113053917886, model saved at 15\n",
      "val_losses[-1] = 0.4363953540101647, best_loss = 0.4784591030329466, model saved at 17\n",
      "val_losses[-1] = 0.4272456864826381, best_loss = 0.4363953540101647, model saved at 20\n",
      "iter 1\n",
      "val_losses[-1] = 1.2438910715281963, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8042093008756638, best_loss = 1.2438910715281963, model saved at 1\n",
      "val_losses[-1] = 0.7840180069208145, best_loss = 0.8042093008756638, model saved at 2\n",
      "val_losses[-1] = 0.7555942127481103, best_loss = 0.7840180069208145, model saved at 3\n",
      "val_losses[-1] = 0.6021492317318916, best_loss = 0.7555942127481103, model saved at 4\n",
      "val_losses[-1] = 0.5735416941344738, best_loss = 0.6021492317318916, model saved at 5\n",
      "val_losses[-1] = 0.5465623514726758, best_loss = 0.5735416941344738, model saved at 6\n",
      "val_losses[-1] = 0.47201331350952386, best_loss = 0.5465623514726758, model saved at 8\n",
      "val_losses[-1] = 0.45489881029352547, best_loss = 0.47201331350952386, model saved at 13\n",
      "val_losses[-1] = 0.44654743587598206, best_loss = 0.45489881029352547, model saved at 20\n",
      "val_losses[-1] = 0.436522579099983, best_loss = 0.44654743587598206, model saved at 22\n",
      "iter 2\n",
      "val_losses[-1] = 1.588253904134035, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.005722115561366, best_loss = 1.588253904134035, model saved at 1\n",
      "val_losses[-1] = 0.7984239842742682, best_loss = 1.005722115561366, model saved at 2\n",
      "val_losses[-1] = 0.7377461230382323, best_loss = 0.7984239842742682, model saved at 3\n",
      "val_losses[-1] = 0.638784715719521, best_loss = 0.7377461230382323, model saved at 5\n",
      "val_losses[-1] = 0.5758112464100122, best_loss = 0.638784715719521, model saved at 7\n",
      "val_losses[-1] = 0.5512853933498263, best_loss = 0.5758112464100122, model saved at 8\n",
      "val_losses[-1] = 0.4812866666354239, best_loss = 0.5512853933498263, model saved at 11\n",
      "val_losses[-1] = 0.46597179118543863, best_loss = 0.4812866666354239, model saved at 12\n",
      "val_losses[-1] = 0.4533499895595014, best_loss = 0.46597179118543863, model saved at 16\n",
      "val_losses[-1] = 0.44357240600511433, best_loss = 0.4533499895595014, model saved at 17\n",
      "val_losses[-1] = 0.4397764509543777, best_loss = 0.44357240600511433, model saved at 22\n",
      "val_losses[-1] = 0.4379371582530439, best_loss = 0.4397764509543777, model saved at 27\n",
      "val_losses[-1] = 0.4328438618220389, best_loss = 0.4379371582530439, model saved at 28\n",
      "iter 3\n",
      "val_losses[-1] = 1.5986555568873881, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 1.116657091677189, best_loss = 1.5986555568873881, model saved at 1\n",
      "val_losses[-1] = 0.8025508906692267, best_loss = 1.116657091677189, model saved at 2\n",
      "val_losses[-1] = 0.7159629138186574, best_loss = 0.8025508906692267, model saved at 3\n",
      "val_losses[-1] = 0.6881960498169064, best_loss = 0.7159629138186574, model saved at 4\n",
      "val_losses[-1] = 0.6505621211603284, best_loss = 0.6881960498169064, model saved at 5\n",
      "val_losses[-1] = 0.5906196920201182, best_loss = 0.6505621211603284, model saved at 8\n",
      "val_losses[-1] = 0.5348909288644791, best_loss = 0.5906196920201182, model saved at 9\n",
      "val_losses[-1] = 0.5228432768955826, best_loss = 0.5348909288644791, model saved at 10\n",
      "val_losses[-1] = 0.48723552096635103, best_loss = 0.5228432768955826, model saved at 11\n",
      "val_losses[-1] = 0.4622837288305163, best_loss = 0.48723552096635103, model saved at 15\n",
      "val_losses[-1] = 0.4589750592596829, best_loss = 0.4622837288305163, model saved at 17\n",
      "val_losses[-1] = 0.4557490233331919, best_loss = 0.4589750592596829, model saved at 18\n",
      "val_losses[-1] = 0.4372366017661989, best_loss = 0.4557490233331919, model saved at 19\n",
      "val_losses[-1] = 0.43547902405261996, best_loss = 0.4372366017661989, model saved at 24\n",
      "val_losses[-1] = 0.4324327633716166, best_loss = 0.43547902405261996, model saved at 28\n",
      "iter 4\n",
      "val_losses[-1] = 1.4980449378490448, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.9486049048602581, best_loss = 1.4980449378490448, model saved at 1\n",
      "val_losses[-1] = 0.7693939227610826, best_loss = 0.9486049048602581, model saved at 2\n",
      "val_losses[-1] = 0.7563053078949451, best_loss = 0.7693939227610826, model saved at 3\n",
      "val_losses[-1] = 0.6510076811537147, best_loss = 0.7563053078949451, model saved at 5\n",
      "val_losses[-1] = 0.5462837068364024, best_loss = 0.6510076811537147, model saved at 6\n",
      "val_losses[-1] = 0.5216960681602358, best_loss = 0.5462837068364024, model saved at 7\n",
      "val_losses[-1] = 0.5054853540845216, best_loss = 0.5216960681602358, model saved at 8\n",
      "val_losses[-1] = 0.46697071576491, best_loss = 0.5054853540845216, model saved at 11\n",
      "val_losses[-1] = 0.437948577478528, best_loss = 0.46697071576491, model saved at 16\n",
      "val_losses[-1] = 0.43072819206863644, best_loss = 0.437948577478528, model saved at 22\n",
      "(1, 0.5)\n",
      "iter 0\n",
      "val_losses[-1] = 1.1999758400022984, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8604850646108388, best_loss = 1.1999758400022984, model saved at 1\n",
      "val_losses[-1] = 0.7394623707979917, best_loss = 0.8604850646108388, model saved at 2\n",
      "val_losses[-1] = 0.7197407508268953, best_loss = 0.7394623707979917, model saved at 3\n",
      "val_losses[-1] = 0.6420361930504441, best_loss = 0.7197407508268953, model saved at 4\n",
      "val_losses[-1] = 0.5808433344587683, best_loss = 0.6420361930504441, model saved at 5\n",
      "val_losses[-1] = 0.5715053433552384, best_loss = 0.5808433344587683, model saved at 6\n",
      "val_losses[-1] = 0.5419884972274304, best_loss = 0.5715053433552384, model saved at 8\n",
      "val_losses[-1] = 0.5383196251466871, best_loss = 0.5419884972274304, model saved at 10\n",
      "val_losses[-1] = 0.5296639047563076, best_loss = 0.5383196251466871, model saved at 12\n",
      "val_losses[-1] = 0.4929968249984086, best_loss = 0.5296639047563076, model saved at 13\n",
      "val_losses[-1] = 0.4675685680471361, best_loss = 0.4929968249984086, model saved at 14\n",
      "val_losses[-1] = 0.4334148283582181, best_loss = 0.4675685680471361, model saved at 17\n",
      "val_losses[-1] = 0.4333939134143293, best_loss = 0.4334148283582181, model saved at 20\n",
      "iter 1\n",
      "val_losses[-1] = 1.1715235650539397, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7640367384999991, best_loss = 1.1715235650539397, model saved at 1\n",
      "val_losses[-1] = 0.6903813101351262, best_loss = 0.7640367384999991, model saved at 2\n",
      "val_losses[-1] = 0.5881766783073544, best_loss = 0.6903813101351262, model saved at 3\n",
      "val_losses[-1] = 0.5529162865132093, best_loss = 0.5881766783073544, model saved at 5\n",
      "val_losses[-1] = 0.4976512002758682, best_loss = 0.5529162865132093, model saved at 6\n",
      "val_losses[-1] = 0.47143634157255293, best_loss = 0.4976512002758682, model saved at 8\n",
      "val_losses[-1] = 0.4702199251390994, best_loss = 0.47143634157255293, model saved at 11\n",
      "val_losses[-1] = 0.4501906828954816, best_loss = 0.4702199251390994, model saved at 13\n",
      "val_losses[-1] = 0.43990449300035833, best_loss = 0.4501906828954816, model saved at 18\n",
      "val_losses[-1] = 0.4300642741844058, best_loss = 0.43990449300035833, model saved at 20\n",
      "val_losses[-1] = 0.42990520875900984, best_loss = 0.4300642741844058, model saved at 22\n",
      "iter 2\n",
      "val_losses[-1] = 1.573471763730049, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.9008479963988065, best_loss = 1.573471763730049, model saved at 1\n",
      "val_losses[-1] = 0.7487388983368873, best_loss = 0.9008479963988065, model saved at 2\n",
      "val_losses[-1] = 0.7175025790929794, best_loss = 0.7487388983368873, model saved at 3\n",
      "val_losses[-1] = 0.6915601003915072, best_loss = 0.7175025790929794, model saved at 5\n",
      "val_losses[-1] = 0.6335286276414991, best_loss = 0.6915601003915072, model saved at 6\n",
      "val_losses[-1] = 0.6183409815654158, best_loss = 0.6335286276414991, model saved at 8\n",
      "val_losses[-1] = 0.6053137823939323, best_loss = 0.6183409815654158, model saved at 9\n",
      "val_losses[-1] = 0.5420135647058487, best_loss = 0.6053137823939323, model saved at 10\n",
      "val_losses[-1] = 0.5174089422449469, best_loss = 0.5420135647058487, model saved at 12\n",
      "val_losses[-1] = 0.4877439050003886, best_loss = 0.5174089422449469, model saved at 13\n",
      "val_losses[-1] = 0.45173775386065246, best_loss = 0.4877439050003886, model saved at 16\n",
      "val_losses[-1] = 0.4399210757575929, best_loss = 0.45173775386065246, model saved at 18\n",
      "val_losses[-1] = 0.43636632785201074, best_loss = 0.4399210757575929, model saved at 26\n",
      "iter 3\n",
      "val_losses[-1] = 1.6003626592457294, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8986427567899227, best_loss = 1.6003626592457294, model saved at 1\n",
      "val_losses[-1] = 0.7137599118053913, best_loss = 0.8986427567899227, model saved at 2\n",
      "val_losses[-1] = 0.6795535204932094, best_loss = 0.7137599118053913, model saved at 3\n",
      "val_losses[-1] = 0.6330074349418282, best_loss = 0.6795535204932094, model saved at 5\n",
      "val_losses[-1] = 0.6160289432853461, best_loss = 0.6330074349418282, model saved at 8\n",
      "val_losses[-1] = 0.5361721839755773, best_loss = 0.6160289432853461, model saved at 9\n",
      "val_losses[-1] = 0.5220496795140207, best_loss = 0.5361721839755773, model saved at 10\n",
      "val_losses[-1] = 0.5054246472194791, best_loss = 0.5220496795140207, model saved at 11\n",
      "val_losses[-1] = 0.4701610899530351, best_loss = 0.5054246472194791, model saved at 14\n",
      "val_losses[-1] = 0.46092149131000043, best_loss = 0.4701610899530351, model saved at 15\n",
      "val_losses[-1] = 0.445628859475255, best_loss = 0.46092149131000043, model saved at 18\n",
      "val_losses[-1] = 0.44362457701936364, best_loss = 0.445628859475255, model saved at 19\n",
      "val_losses[-1] = 0.43200999069958923, best_loss = 0.44362457701936364, model saved at 20\n",
      "val_losses[-1] = 0.42814120147377255, best_loss = 0.43200999069958923, model saved at 24\n",
      "iter 4\n",
      "val_losses[-1] = 1.5130249731242658, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.868880956619978, best_loss = 1.5130249731242658, model saved at 1\n",
      "val_losses[-1] = 0.8578091651201248, best_loss = 0.868880956619978, model saved at 2\n",
      "val_losses[-1] = 0.7303278243169189, best_loss = 0.8578091651201248, model saved at 3\n",
      "val_losses[-1] = 0.6831633413210512, best_loss = 0.7303278243169189, model saved at 4\n",
      "val_losses[-1] = 0.6726312348619103, best_loss = 0.6831633413210512, model saved at 6\n",
      "val_losses[-1] = 0.5917709955945611, best_loss = 0.6726312348619103, model saved at 7\n",
      "val_losses[-1] = 0.5514232005923987, best_loss = 0.5917709955945611, model saved at 8\n",
      "val_losses[-1] = 0.4938367505557835, best_loss = 0.5514232005923987, model saved at 10\n",
      "val_losses[-1] = 0.47720830179750917, best_loss = 0.4938367505557835, model saved at 15\n",
      "val_losses[-1] = 0.4589005048386753, best_loss = 0.47720830179750917, model saved at 16\n",
      "val_losses[-1] = 0.4489583007059991, best_loss = 0.4589005048386753, model saved at 21\n",
      "val_losses[-1] = 0.43125605611130596, best_loss = 0.4489583007059991, model saved at 24\n",
      "(1, 0.4)\n",
      "iter 0\n",
      "val_losses[-1] = 1.4316595003008843, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8564289659261703, best_loss = 1.4316595003008843, model saved at 1\n",
      "val_losses[-1] = 0.7065546410158277, best_loss = 0.8564289659261703, model saved at 2\n",
      "val_losses[-1] = 0.6553077146410942, best_loss = 0.7065546410158277, model saved at 3\n",
      "val_losses[-1] = 0.6062411023303866, best_loss = 0.6553077146410942, model saved at 4\n",
      "val_losses[-1] = 0.5526043245568871, best_loss = 0.6062411023303866, model saved at 6\n",
      "val_losses[-1] = 0.534866739064455, best_loss = 0.5526043245568871, model saved at 7\n",
      "val_losses[-1] = 0.4918419120833278, best_loss = 0.534866739064455, model saved at 8\n",
      "val_losses[-1] = 0.4917201424017549, best_loss = 0.4918419120833278, model saved at 9\n",
      "val_losses[-1] = 0.46923230215907097, best_loss = 0.4917201424017549, model saved at 10\n",
      "val_losses[-1] = 0.45124903954565526, best_loss = 0.46923230215907097, model saved at 12\n",
      "val_losses[-1] = 0.4440667930059135, best_loss = 0.45124903954565526, model saved at 15\n",
      "val_losses[-1] = 0.43472765320912005, best_loss = 0.4440667930059135, model saved at 17\n",
      "val_losses[-1] = 0.43231221614405513, best_loss = 0.43472765320912005, model saved at 20\n",
      "iter 1\n",
      "val_losses[-1] = 1.1024845223873854, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7340316975489258, best_loss = 1.1024845223873854, model saved at 1\n",
      "val_losses[-1] = 0.6465463377535343, best_loss = 0.7340316975489258, model saved at 2\n",
      "val_losses[-1] = 0.5900852346792818, best_loss = 0.6465463377535343, model saved at 3\n",
      "val_losses[-1] = 0.5661014759913087, best_loss = 0.5900852346792818, model saved at 4\n",
      "val_losses[-1] = 0.5465752905234694, best_loss = 0.5661014759913087, model saved at 5\n",
      "val_losses[-1] = 0.5045953663997352, best_loss = 0.5465752905234694, model saved at 6\n",
      "val_losses[-1] = 0.4667869320139289, best_loss = 0.5045953663997352, model saved at 8\n",
      "val_losses[-1] = 0.46627130433917047, best_loss = 0.4667869320139289, model saved at 11\n",
      "val_losses[-1] = 0.4384445299394429, best_loss = 0.46627130433917047, model saved at 13\n",
      "val_losses[-1] = 0.4337527511641383, best_loss = 0.4384445299394429, model saved at 18\n",
      "val_losses[-1] = 0.4288146557286382, best_loss = 0.4337527511641383, model saved at 20\n",
      "iter 2\n",
      "val_losses[-1] = 1.5537490755319596, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.9007306519895792, best_loss = 1.5537490755319596, model saved at 1\n",
      "val_losses[-1] = 0.7292093308642507, best_loss = 0.9007306519895792, model saved at 2\n",
      "val_losses[-1] = 0.6876844929531216, best_loss = 0.7292093308642507, model saved at 3\n",
      "val_losses[-1] = 0.6349776804447174, best_loss = 0.6876844929531216, model saved at 6\n",
      "val_losses[-1] = 0.6304047098383307, best_loss = 0.6349776804447174, model saved at 7\n",
      "val_losses[-1] = 0.617265654169023, best_loss = 0.6304047098383307, model saved at 8\n",
      "val_losses[-1] = 0.5638893416151405, best_loss = 0.617265654169023, model saved at 10\n",
      "val_losses[-1] = 0.5398552162572742, best_loss = 0.5638893416151405, model saved at 11\n",
      "val_losses[-1] = 0.4912574216723442, best_loss = 0.5398552162572742, model saved at 12\n",
      "val_losses[-1] = 0.48511957079172136, best_loss = 0.4912574216723442, model saved at 14\n",
      "val_losses[-1] = 0.4640684735029936, best_loss = 0.48511957079172136, model saved at 17\n",
      "val_losses[-1] = 0.44198607336729767, best_loss = 0.4640684735029936, model saved at 18\n",
      "val_losses[-1] = 0.4374499723315239, best_loss = 0.44198607336729767, model saved at 19\n",
      "val_losses[-1] = 0.42518293792381884, best_loss = 0.4374499723315239, model saved at 22\n",
      "val_losses[-1] = 0.42512360513210296, best_loss = 0.42518293792381884, model saved at 25\n",
      "iter 3\n",
      "val_losses[-1] = 1.593394249677658, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8616172082722187, best_loss = 1.593394249677658, model saved at 1\n",
      "val_losses[-1] = 0.7051631970331073, best_loss = 0.8616172082722187, model saved at 2\n",
      "val_losses[-1] = 0.6572657706215977, best_loss = 0.7051631970331073, model saved at 3\n",
      "val_losses[-1] = 0.6259596835821867, best_loss = 0.6572657706215977, model saved at 5\n",
      "val_losses[-1] = 0.5230926391668618, best_loss = 0.6259596835821867, model saved at 8\n",
      "val_losses[-1] = 0.478959733247757, best_loss = 0.5230926391668618, model saved at 11\n",
      "val_losses[-1] = 0.45123033225536346, best_loss = 0.478959733247757, model saved at 12\n",
      "val_losses[-1] = 0.43962531005963684, best_loss = 0.45123033225536346, model saved at 14\n",
      "val_losses[-1] = 0.43196608321741226, best_loss = 0.43962531005963684, model saved at 18\n",
      "val_losses[-1] = 0.4268761033192277, best_loss = 0.43196608321741226, model saved at 20\n",
      "iter 4\n",
      "val_losses[-1] = 1.4759423598647117, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8431803401559591, best_loss = 1.4759423598647117, model saved at 1\n",
      "val_losses[-1] = 0.8293193999677897, best_loss = 0.8431803401559591, model saved at 2\n",
      "val_losses[-1] = 0.7084689565002918, best_loss = 0.8293193999677897, model saved at 3\n",
      "val_losses[-1] = 0.6734102223068476, best_loss = 0.7084689565002918, model saved at 4\n",
      "val_losses[-1] = 0.5837686978280544, best_loss = 0.6734102223068476, model saved at 6\n",
      "val_losses[-1] = 0.5254750125110149, best_loss = 0.5837686978280544, model saved at 8\n",
      "val_losses[-1] = 0.49951738622039554, best_loss = 0.5254750125110149, model saved at 10\n",
      "val_losses[-1] = 0.49243616349995134, best_loss = 0.49951738622039554, model saved at 11\n",
      "val_losses[-1] = 0.4846643225289881, best_loss = 0.49243616349995134, model saved at 14\n",
      "val_losses[-1] = 0.4600740996189415, best_loss = 0.4846643225289881, model saved at 16\n",
      "val_losses[-1] = 0.4534001985564828, best_loss = 0.4600740996189415, model saved at 17\n",
      "val_losses[-1] = 0.4469737684354186, best_loss = 0.4534001985564828, model saved at 20\n",
      "val_losses[-1] = 0.44379724534228443, best_loss = 0.4469737684354186, model saved at 21\n",
      "val_losses[-1] = 0.4322081750258803, best_loss = 0.44379724534228443, model saved at 24\n",
      "(1, 0.3)\n",
      "iter 0\n",
      "val_losses[-1] = 1.2550515152513981, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7861737467348575, best_loss = 1.2550515152513981, model saved at 1\n",
      "val_losses[-1] = 0.7036243714392185, best_loss = 0.7861737467348575, model saved at 2\n",
      "val_losses[-1] = 0.66279037296772, best_loss = 0.7036243714392185, model saved at 4\n",
      "val_losses[-1] = 0.6327415781095624, best_loss = 0.66279037296772, model saved at 5\n",
      "val_losses[-1] = 0.5774560578167438, best_loss = 0.6327415781095624, model saved at 7\n",
      "val_losses[-1] = 0.5500221038237214, best_loss = 0.5774560578167438, model saved at 8\n",
      "val_losses[-1] = 0.5403210861608386, best_loss = 0.5500221038237214, model saved at 9\n",
      "val_losses[-1] = 0.47961323950439694, best_loss = 0.5403210861608386, model saved at 12\n",
      "val_losses[-1] = 0.45731317438185215, best_loss = 0.47961323950439694, model saved at 13\n",
      "val_losses[-1] = 0.4477591373026371, best_loss = 0.45731317438185215, model saved at 15\n",
      "val_losses[-1] = 0.4292188096791506, best_loss = 0.4477591373026371, model saved at 17\n",
      "val_losses[-1] = 0.4261560533195734, best_loss = 0.4292188096791506, model saved at 20\n",
      "val_losses[-1] = 0.4255925739184022, best_loss = 0.4261560533195734, model saved at 21\n",
      "iter 1\n",
      "val_losses[-1] = 0.9544778499752283, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7598591627553105, best_loss = 0.9544778499752283, model saved at 1\n",
      "val_losses[-1] = 0.6733132261782885, best_loss = 0.7598591627553105, model saved at 2\n",
      "val_losses[-1] = 0.6571056403219699, best_loss = 0.6733132261782885, model saved at 3\n",
      "val_losses[-1] = 0.5853967629373074, best_loss = 0.6571056403219699, model saved at 6\n",
      "val_losses[-1] = 0.5706194280646741, best_loss = 0.5853967629373074, model saved at 7\n",
      "val_losses[-1] = 0.535170341655612, best_loss = 0.5706194280646741, model saved at 8\n",
      "val_losses[-1] = 0.5196262658573687, best_loss = 0.535170341655612, model saved at 9\n",
      "val_losses[-1] = 0.5009631056338548, best_loss = 0.5196262658573687, model saved at 11\n",
      "val_losses[-1] = 0.4712334033101797, best_loss = 0.5009631056338548, model saved at 12\n",
      "val_losses[-1] = 0.4454436399973929, best_loss = 0.4712334033101797, model saved at 13\n",
      "val_losses[-1] = 0.43556001912802456, best_loss = 0.4454436399973929, model saved at 15\n",
      "val_losses[-1] = 0.4256265826523304, best_loss = 0.43556001912802456, model saved at 16\n",
      "val_losses[-1] = 0.41923418249934913, best_loss = 0.4256265826523304, model saved at 20\n",
      "iter 2\n",
      "val_losses[-1] = 1.4936201333999635, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8107225771993398, best_loss = 1.4936201333999635, model saved at 1\n",
      "val_losses[-1] = 0.6952481029555202, best_loss = 0.8107225771993398, model saved at 2\n",
      "val_losses[-1] = 0.6605757512152195, best_loss = 0.6952481029555202, model saved at 4\n",
      "val_losses[-1] = 0.6299790786579251, best_loss = 0.6605757512152195, model saved at 6\n",
      "val_losses[-1] = 0.5738604268059134, best_loss = 0.6299790786579251, model saved at 7\n",
      "val_losses[-1] = 0.5364387161098421, best_loss = 0.5738604268059134, model saved at 8\n",
      "val_losses[-1] = 0.4988890695385635, best_loss = 0.5364387161098421, model saved at 10\n",
      "val_losses[-1] = 0.4815130107104778, best_loss = 0.4988890695385635, model saved at 12\n",
      "val_losses[-1] = 0.47898276820778846, best_loss = 0.4815130107104778, model saved at 13\n",
      "val_losses[-1] = 0.45938065871596334, best_loss = 0.47898276820778846, model saved at 17\n",
      "val_losses[-1] = 0.4438792520202696, best_loss = 0.45938065871596334, model saved at 18\n",
      "val_losses[-1] = 0.4314508226700127, best_loss = 0.4438792520202696, model saved at 20\n",
      "iter 3\n",
      "val_losses[-1] = 1.5558393061161042, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8029631916433573, best_loss = 1.5558393061161042, model saved at 1\n",
      "val_losses[-1] = 0.7921391369774937, best_loss = 0.8029631916433573, model saved at 2\n",
      "val_losses[-1] = 0.6177983485162258, best_loss = 0.7921391369774937, model saved at 3\n",
      "val_losses[-1] = 0.5920447945594788, best_loss = 0.6177983485162258, model saved at 5\n",
      "val_losses[-1] = 0.5801229840144515, best_loss = 0.5920447945594788, model saved at 6\n",
      "val_losses[-1] = 0.5556128270924091, best_loss = 0.5801229840144515, model saved at 7\n",
      "val_losses[-1] = 0.48654518704861405, best_loss = 0.5556128270924091, model saved at 8\n",
      "val_losses[-1] = 0.476732474565506, best_loss = 0.48654518704861405, model saved at 10\n",
      "val_losses[-1] = 0.4548662981018424, best_loss = 0.476732474565506, model saved at 11\n",
      "val_losses[-1] = 0.4495101112872362, best_loss = 0.4548662981018424, model saved at 12\n",
      "val_losses[-1] = 0.44769482063129545, best_loss = 0.4495101112872362, model saved at 17\n",
      "val_losses[-1] = 0.44611465353518726, best_loss = 0.44769482063129545, model saved at 19\n",
      "val_losses[-1] = 0.4400518083013594, best_loss = 0.44611465353518726, model saved at 22\n",
      "iter 4\n",
      "val_losses[-1] = 1.3024132043123244, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8173848755657673, best_loss = 1.3024132043123244, model saved at 1\n",
      "val_losses[-1] = 0.7117285031825304, best_loss = 0.8173848755657673, model saved at 3\n",
      "val_losses[-1] = 0.663430542871356, best_loss = 0.7117285031825304, model saved at 4\n",
      "val_losses[-1] = 0.5620602613314987, best_loss = 0.663430542871356, model saved at 7\n",
      "val_losses[-1] = 0.5487268142402172, best_loss = 0.5620602613314987, model saved at 8\n",
      "val_losses[-1] = 0.5090046186000109, best_loss = 0.5487268142402172, model saved at 11\n",
      "val_losses[-1] = 0.5018395565450191, best_loss = 0.5090046186000109, model saved at 13\n",
      "val_losses[-1] = 0.49097130419686436, best_loss = 0.5018395565450191, model saved at 14\n",
      "val_losses[-1] = 0.4821671137586236, best_loss = 0.49097130419686436, model saved at 15\n",
      "val_losses[-1] = 0.4698475764133036, best_loss = 0.4821671137586236, model saved at 16\n",
      "val_losses[-1] = 0.46349929375573995, best_loss = 0.4698475764133036, model saved at 17\n",
      "val_losses[-1] = 0.4606118707917631, best_loss = 0.46349929375573995, model saved at 20\n",
      "val_losses[-1] = 0.45649118833243846, best_loss = 0.4606118707917631, model saved at 21\n",
      "val_losses[-1] = 0.45237328894436357, best_loss = 0.45649118833243846, model saved at 22\n",
      "(1, 0.2)\n",
      "iter 0\n",
      "val_losses[-1] = 1.5098180256783962, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8246096648275852, best_loss = 1.5098180256783962, model saved at 1\n",
      "val_losses[-1] = 0.657747071608901, best_loss = 0.8246096648275852, model saved at 2\n",
      "val_losses[-1] = 0.6250922141596675, best_loss = 0.657747071608901, model saved at 3\n",
      "val_losses[-1] = 0.5651839535683394, best_loss = 0.6250922141596675, model saved at 4\n",
      "val_losses[-1] = 0.5264289146289229, best_loss = 0.5651839535683394, model saved at 5\n",
      "val_losses[-1] = 0.5220318282023072, best_loss = 0.5264289146289229, model saved at 7\n",
      "val_losses[-1] = 0.5058717619627714, best_loss = 0.5220318282023072, model saved at 8\n",
      "val_losses[-1] = 0.4753257575444877, best_loss = 0.5058717619627714, model saved at 9\n",
      "val_losses[-1] = 0.45844377456232904, best_loss = 0.4753257575444877, model saved at 10\n",
      "val_losses[-1] = 0.4379448024556041, best_loss = 0.45844377456232904, model saved at 12\n",
      "val_losses[-1] = 0.43485300252214076, best_loss = 0.4379448024556041, model saved at 14\n",
      "val_losses[-1] = 0.42384688509628177, best_loss = 0.43485300252214076, model saved at 15\n",
      "val_losses[-1] = 0.4219062357209623, best_loss = 0.42384688509628177, model saved at 20\n",
      "iter 1\n",
      "val_losses[-1] = 0.9077404279261827, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8234680410474539, best_loss = 0.9077404279261827, model saved at 1\n",
      "val_losses[-1] = 0.6378079313784838, best_loss = 0.8234680410474539, model saved at 2\n",
      "val_losses[-1] = 0.6185653364285827, best_loss = 0.6378079313784838, model saved at 3\n",
      "val_losses[-1] = 0.5247618824243545, best_loss = 0.6185653364285827, model saved at 6\n",
      "val_losses[-1] = 0.4855195766314864, best_loss = 0.5247618824243545, model saved at 9\n",
      "val_losses[-1] = 0.466311283223331, best_loss = 0.4855195766314864, model saved at 13\n",
      "val_losses[-1] = 0.4624979356303811, best_loss = 0.466311283223331, model saved at 14\n",
      "val_losses[-1] = 0.4379571573808789, best_loss = 0.4624979356303811, model saved at 15\n",
      "val_losses[-1] = 0.42877402873709797, best_loss = 0.4379571573808789, model saved at 16\n",
      "val_losses[-1] = 0.42767805103212597, best_loss = 0.42877402873709797, model saved at 20\n",
      "iter 2\n",
      "val_losses[-1] = 1.1683843746781348, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7276855625212193, best_loss = 1.1683843746781348, model saved at 1\n",
      "val_losses[-1] = 0.6521827334538102, best_loss = 0.7276855625212193, model saved at 2\n",
      "val_losses[-1] = 0.6515025030821562, best_loss = 0.6521827334538102, model saved at 3\n",
      "val_losses[-1] = 0.5862034499645233, best_loss = 0.6515025030821562, model saved at 7\n",
      "val_losses[-1] = 0.5313726782798767, best_loss = 0.5862034499645233, model saved at 9\n",
      "val_losses[-1] = 0.527664958871901, best_loss = 0.5313726782798767, model saved at 11\n",
      "val_losses[-1] = 0.4570469303056598, best_loss = 0.527664958871901, model saved at 12\n",
      "val_losses[-1] = 0.4447295186109841, best_loss = 0.4570469303056598, model saved at 13\n",
      "val_losses[-1] = 0.43499060650356114, best_loss = 0.4447295186109841, model saved at 14\n",
      "val_losses[-1] = 0.4264367653056979, best_loss = 0.43499060650356114, model saved at 18\n",
      "iter 3\n",
      "val_losses[-1] = 1.1065995041280985, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7262962494045496, best_loss = 1.1065995041280985, model saved at 1\n",
      "val_losses[-1] = 0.6112205633893609, best_loss = 0.7262962494045496, model saved at 3\n",
      "val_losses[-1] = 0.5531234597787261, best_loss = 0.6112205633893609, model saved at 5\n",
      "val_losses[-1] = 0.5309214504435659, best_loss = 0.5531234597787261, model saved at 6\n",
      "val_losses[-1] = 0.5211415102705359, best_loss = 0.5309214504435659, model saved at 7\n",
      "val_losses[-1] = 0.501161727681756, best_loss = 0.5211415102705359, model saved at 8\n",
      "val_losses[-1] = 0.44275190867483616, best_loss = 0.501161727681756, model saved at 11\n",
      "val_losses[-1] = 0.43555290773510935, best_loss = 0.44275190867483616, model saved at 12\n",
      "val_losses[-1] = 0.4344357387162745, best_loss = 0.43555290773510935, model saved at 18\n",
      "iter 4\n",
      "val_losses[-1] = 1.1142489906400441, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.751651206240058, best_loss = 1.1142489906400441, model saved at 1\n",
      "val_losses[-1] = 0.6676935585215688, best_loss = 0.751651206240058, model saved at 3\n",
      "val_losses[-1] = 0.5951355449855328, best_loss = 0.6676935585215688, model saved at 4\n",
      "val_losses[-1] = 0.5918369924649596, best_loss = 0.5951355449855328, model saved at 6\n",
      "val_losses[-1] = 0.5310123501345515, best_loss = 0.5918369924649596, model saved at 7\n",
      "val_losses[-1] = 0.5280129205435514, best_loss = 0.5310123501345515, model saved at 8\n",
      "val_losses[-1] = 0.5143752971664071, best_loss = 0.5280129205435514, model saved at 10\n",
      "val_losses[-1] = 0.5037457251921296, best_loss = 0.5143752971664071, model saved at 13\n",
      "val_losses[-1] = 0.4717073844745755, best_loss = 0.5037457251921296, model saved at 15\n",
      "val_losses[-1] = 0.4367164551280439, best_loss = 0.4717073844745755, model saved at 16\n",
      "val_losses[-1] = 0.4281574328429997, best_loss = 0.4367164551280439, model saved at 20\n",
      "val_losses[-1] = 0.4250943576917052, best_loss = 0.4281574328429997, model saved at 23\n",
      "(1, 0.1)\n",
      "iter 0\n",
      "val_losses[-1] = 0.8722225870937109, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7322237897664309, best_loss = 0.8722225870937109, model saved at 1\n",
      "val_losses[-1] = 0.6254505241289735, best_loss = 0.7322237897664309, model saved at 2\n",
      "val_losses[-1] = 0.5777869462966919, best_loss = 0.6254505241289735, model saved at 3\n",
      "val_losses[-1] = 0.5673693416640162, best_loss = 0.5777869462966919, model saved at 4\n",
      "val_losses[-1] = 0.4813052279874682, best_loss = 0.5673693416640162, model saved at 5\n",
      "val_losses[-1] = 0.4736628090962768, best_loss = 0.4813052279874682, model saved at 8\n",
      "val_losses[-1] = 0.442474537435919, best_loss = 0.4736628090962768, model saved at 9\n",
      "val_losses[-1] = 0.4253745533525944, best_loss = 0.442474537435919, model saved at 12\n",
      "val_losses[-1] = 0.41925059352070093, best_loss = 0.4253745533525944, model saved at 15\n",
      "iter 1\n",
      "val_losses[-1] = 0.836071702465415, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7243393452838063, best_loss = 0.836071702465415, model saved at 1\n",
      "val_losses[-1] = 0.5626094313338399, best_loss = 0.7243393452838063, model saved at 2\n",
      "val_losses[-1] = 0.5541031841188669, best_loss = 0.5626094313338399, model saved at 3\n",
      "val_losses[-1] = 0.5531722731888294, best_loss = 0.5541031841188669, model saved at 4\n",
      "val_losses[-1] = 0.5172038923949003, best_loss = 0.5531722731888294, model saved at 5\n",
      "val_losses[-1] = 0.5088467126712203, best_loss = 0.5172038923949003, model saved at 6\n",
      "val_losses[-1] = 0.4596604355610907, best_loss = 0.5088467126712203, model saved at 8\n",
      "val_losses[-1] = 0.4547427867539227, best_loss = 0.4596604355610907, model saved at 10\n",
      "val_losses[-1] = 0.44551531653851273, best_loss = 0.4547427867539227, model saved at 11\n",
      "val_losses[-1] = 0.4318152753636241, best_loss = 0.44551531653851273, model saved at 13\n",
      "val_losses[-1] = 0.4285311132669449, best_loss = 0.4318152753636241, model saved at 16\n",
      "val_losses[-1] = 0.42833178099244834, best_loss = 0.4285311132669449, model saved at 18\n",
      "iter 2\n",
      "val_losses[-1] = 1.044763894751668, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.726567855104804, best_loss = 1.044763894751668, model saved at 1\n",
      "val_losses[-1] = 0.624158531986177, best_loss = 0.726567855104804, model saved at 2\n",
      "val_losses[-1] = 0.5932236554101109, best_loss = 0.624158531986177, model saved at 3\n",
      "val_losses[-1] = 0.49169578300788996, best_loss = 0.5932236554101109, model saved at 7\n",
      "val_losses[-1] = 0.45123776206746696, best_loss = 0.49169578300788996, model saved at 10\n",
      "val_losses[-1] = 0.4485892021097243, best_loss = 0.45123776206746696, model saved at 11\n",
      "val_losses[-1] = 0.4302759850397706, best_loss = 0.4485892021097243, model saved at 12\n",
      "val_losses[-1] = 0.41970400330610574, best_loss = 0.4302759850397706, model saved at 14\n",
      "val_losses[-1] = 0.41817008759826424, best_loss = 0.41970400330610574, model saved at 17\n",
      "iter 3\n",
      "val_losses[-1] = 0.9866696011275053, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.6524211639538408, best_loss = 0.9866696011275053, model saved at 1\n",
      "val_losses[-1] = 0.6369204960763455, best_loss = 0.6524211639538408, model saved at 3\n",
      "val_losses[-1] = 0.5099290504120291, best_loss = 0.6369204960763455, model saved at 4\n",
      "val_losses[-1] = 0.5000296326354146, best_loss = 0.5099290504120291, model saved at 5\n",
      "val_losses[-1] = 0.49649519119411706, best_loss = 0.5000296326354146, model saved at 6\n",
      "val_losses[-1] = 0.46177500654011966, best_loss = 0.49649519119411706, model saved at 7\n",
      "val_losses[-1] = 0.45284937517717483, best_loss = 0.46177500654011966, model saved at 8\n",
      "val_losses[-1] = 0.4435133713297546, best_loss = 0.45284937517717483, model saved at 9\n",
      "val_losses[-1] = 0.4268165735527873, best_loss = 0.4435133713297546, model saved at 11\n",
      "iter 4\n",
      "val_losses[-1] = 1.0650304209440946, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7711244560778141, best_loss = 1.0650304209440946, model saved at 1\n",
      "val_losses[-1] = 0.7710850559175014, best_loss = 0.7711244560778141, model saved at 2\n",
      "val_losses[-1] = 0.6029807221144438, best_loss = 0.7710850559175014, model saved at 3\n",
      "val_losses[-1] = 0.5543652914464474, best_loss = 0.6029807221144438, model saved at 5\n",
      "val_losses[-1] = 0.5062132770195603, best_loss = 0.5543652914464474, model saved at 6\n",
      "val_losses[-1] = 0.48654646389186385, best_loss = 0.5062132770195603, model saved at 7\n",
      "val_losses[-1] = 0.4455286206677556, best_loss = 0.48654646389186385, model saved at 8\n",
      "val_losses[-1] = 0.4227793101221323, best_loss = 0.4455286206677556, model saved at 11\n",
      "val_losses[-1] = 0.4175859985873103, best_loss = 0.4227793101221323, model saved at 17\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "num_iter = 5\n",
    "\n",
    "loss_fns = (nn.CrossEntropyLoss(), nn.MSELoss())\n",
    "\n",
    "for loss_ratios in all_loss_ratios:\n",
    "    print(loss_ratios)\n",
    "    \n",
    "    models = []\n",
    "    for j in range(num_iter):\n",
    "        print(f\"iter {j}\")\n",
    "        dataset = torch.load(f\"data/amc_data_512_case_1.pt\")\n",
    "        train_loader = dataset['train_loader']\n",
    "        val_loader = dataset['val_loader']\n",
    "        \n",
    "        torch.manual_seed(j)\n",
    "        model_mtl = amc_model_mtl(case=1)\n",
    "        model_mtl.cuda()\n",
    "\n",
    "        optimizer = torch.optim.Adam(model_mtl.parameters(), lr=0.0005, weight_decay=0.0001)\n",
    "\n",
    "        model, losses, losses_mod, losses_snr, val_losses, val_losses_snr = train_mtl(model_mtl, optimizer, train_loader, \n",
    "                                                                                      val_loader, loss_fns, \n",
    "                                                                                      num_epochs=num_epochs, verbose=False, \n",
    "                                                                                      loss_ratios=loss_ratios)\n",
    "        \n",
    "        model_config = {\"weights\": model_mtl.state_dict(),\n",
    "                        \"losses\": losses,\n",
    "                        \"val_losses\": val_losses,\n",
    "                        \"losses_mod\": losses_mod,\n",
    "                        \"losses_snr\": losses_snr,\n",
    "                        \"val_losses_snr\": val_losses_snr}\n",
    "        \n",
    "        models.append(model_config)\n",
    "    torch.save(models, f'models/case_1/amc_{loss_ratios[0]}_{loss_ratios[1]}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caf851a2-887c-47c6-9941-bff31f1a3810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.9)\n",
      "(1, 0.8)\n",
      "(1, 0.7)\n",
      "(1, 0.6)\n",
      "(1, 0.5)\n",
      "(1, 0.4)\n",
      "(1, 0.3)\n",
      "(1, 0.2)\n",
      "(1, 0.1)\n"
     ]
    }
   ],
   "source": [
    "snr_range = np.arange(-15,16,2)\n",
    "\n",
    "# for models in sorted(os.listdir('models')):\n",
    "for loss_ratios in all_loss_ratios:\n",
    "    print(loss_ratios)\n",
    "    results = []\n",
    "    for model in torch.load(f'models/case_1/amc_{loss_ratios[0]}_{loss_ratios[1]}.pt'):\n",
    "        model_mtl = amc_model_mtl(case=1)\n",
    "        model_mtl.load_state_dict(model['weights'])\n",
    "        accs_mod = test_model_mtl(model_mtl, snr_range, num_frames=128)\n",
    "        \n",
    "        result = {\"accs_mod\": accs_mod,\n",
    "                   \"snr_range\": snr_range,\n",
    "                   \"model\": model}\n",
    "        results.append(result)\n",
    "    torch.save(results, f'results/case_1/amc_{loss_ratios[0]}_{loss_ratios[1]}.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed4843ef-bfc7-40b3-89fb-c985dd0394de",
   "metadata": {},
   "source": [
    "## Add MTL, case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa91110c-46ce-4673-8331-06564bd72b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_snr = np.arange(-15,16,2)\n",
    "\n",
    "train_loader = gen_loader(num_frames=512, snr=train_snr, batch_size=32, case=2)\n",
    "val_loader = gen_loader(num_frames=64, snr=train_snr, batch_size=32, case=2)\n",
    "\n",
    "dataset = {'train_loader': train_loader,\n",
    "           'val_loader': val_loader}\n",
    "\n",
    "torch.save(dataset, f\"data/amc_data_512_case_2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "976ad751-287e-4a52-860e-b3d4c802d4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.9)\n",
      "iter 0\n",
      "val_losses[-1] = 1.0015151225030423, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.811079940572381, best_loss = 1.0015151225030423, model saved at 1\n",
      "val_losses[-1] = 0.6611665023490787, best_loss = 0.811079940572381, model saved at 2\n",
      "val_losses[-1] = 0.5986242212355137, best_loss = 0.6611665023490787, model saved at 3\n",
      "val_losses[-1] = 0.5393058797344565, best_loss = 0.5986242212355137, model saved at 4\n",
      "val_losses[-1] = 0.5179628105834126, best_loss = 0.5393058797344565, model saved at 5\n",
      "val_losses[-1] = 0.5138407708145678, best_loss = 0.5179628105834126, model saved at 6\n",
      "val_losses[-1] = 0.49173193480819466, best_loss = 0.5138407708145678, model saved at 7\n",
      "val_losses[-1] = 0.47604854963719845, best_loss = 0.49173193480819466, model saved at 9\n",
      "val_losses[-1] = 0.465094197448343, best_loss = 0.47604854963719845, model saved at 11\n",
      "val_losses[-1] = 0.4457358210347593, best_loss = 0.465094197448343, model saved at 12\n",
      "val_losses[-1] = 0.4426851633936167, best_loss = 0.4457358210347593, model saved at 13\n",
      "val_losses[-1] = 0.43217147802934053, best_loss = 0.4426851633936167, model saved at 14\n",
      "val_losses[-1] = 0.4305131183937192, best_loss = 0.43217147802934053, model saved at 20\n",
      "iter 1\n",
      "val_losses[-1] = 1.0379096824675798, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.904950513318181, best_loss = 1.0379096824675798, model saved at 1\n",
      "val_losses[-1] = 0.6256540285423398, best_loss = 0.904950513318181, model saved at 2\n",
      "val_losses[-1] = 0.5864451816305518, best_loss = 0.6256540285423398, model saved at 3\n",
      "val_losses[-1] = 0.5377299321815372, best_loss = 0.5864451816305518, model saved at 4\n",
      "val_losses[-1] = 0.49076636815443636, best_loss = 0.5377299321815372, model saved at 6\n",
      "val_losses[-1] = 0.4807636925019324, best_loss = 0.49076636815443636, model saved at 7\n",
      "val_losses[-1] = 0.4685513813048601, best_loss = 0.4807636925019324, model saved at 10\n",
      "val_losses[-1] = 0.46549666291102765, best_loss = 0.4685513813048601, model saved at 12\n",
      "val_losses[-1] = 0.4437729173339903, best_loss = 0.46549666291102765, model saved at 13\n",
      "val_losses[-1] = 0.43609134312719106, best_loss = 0.4437729173339903, model saved at 18\n",
      "val_losses[-1] = 0.42888028649613263, best_loss = 0.43609134312719106, model saved at 27\n",
      "iter 2\n",
      "val_losses[-1] = 1.0643432039767504, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8830436747521162, best_loss = 1.0643432039767504, model saved at 1\n",
      "val_losses[-1] = 0.7290787473320961, best_loss = 0.8830436747521162, model saved at 2\n",
      "val_losses[-1] = 0.6607498247176409, best_loss = 0.7290787473320961, model saved at 3\n",
      "val_losses[-1] = 0.6310772048309445, best_loss = 0.6607498247176409, model saved at 4\n",
      "val_losses[-1] = 0.5273866727948189, best_loss = 0.6310772048309445, model saved at 5\n",
      "val_losses[-1] = 0.49052608301863077, best_loss = 0.5273866727948189, model saved at 7\n",
      "val_losses[-1] = 0.46565643036738036, best_loss = 0.49052608301863077, model saved at 12\n",
      "val_losses[-1] = 0.459729774389416, best_loss = 0.46565643036738036, model saved at 15\n",
      "val_losses[-1] = 0.4454863560386002, best_loss = 0.459729774389416, model saved at 16\n",
      "val_losses[-1] = 0.43407008284702897, best_loss = 0.4454863560386002, model saved at 19\n",
      "val_losses[-1] = 0.4332552248612046, best_loss = 0.43407008284702897, model saved at 23\n",
      "val_losses[-1] = 0.42975471494719386, best_loss = 0.4332552248612046, model saved at 26\n",
      "iter 3\n",
      "val_losses[-1] = 0.9978930730372667, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.9837628126144409, best_loss = 0.9978930730372667, model saved at 1\n",
      "val_losses[-1] = 0.852485840767622, best_loss = 0.9837628126144409, model saved at 2\n",
      "val_losses[-1] = 0.6194604733958841, best_loss = 0.852485840767622, model saved at 3\n",
      "val_losses[-1] = 0.5670187011361122, best_loss = 0.6194604733958841, model saved at 4\n",
      "val_losses[-1] = 0.559209593385458, best_loss = 0.5670187011361122, model saved at 5\n",
      "val_losses[-1] = 0.49761911304667594, best_loss = 0.559209593385458, model saved at 7\n",
      "val_losses[-1] = 0.49721382595598695, best_loss = 0.49761911304667594, model saved at 10\n",
      "val_losses[-1] = 0.48608601503074167, best_loss = 0.49721382595598695, model saved at 11\n",
      "val_losses[-1] = 0.4593519037589431, best_loss = 0.48608601503074167, model saved at 12\n",
      "val_losses[-1] = 0.4462007631547749, best_loss = 0.4593519037589431, model saved at 17\n",
      "val_losses[-1] = 0.4435173384845257, best_loss = 0.4462007631547749, model saved at 18\n",
      "val_losses[-1] = 0.43426914932206273, best_loss = 0.4435173384845257, model saved at 19\n",
      "iter 4\n",
      "val_losses[-1] = 1.0206447578966618, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.9258669033646584, best_loss = 1.0206447578966618, model saved at 1\n",
      "val_losses[-1] = 0.6886273505166173, best_loss = 0.9258669033646584, model saved at 2\n",
      "val_losses[-1] = 0.6162386637181043, best_loss = 0.6886273505166173, model saved at 3\n",
      "val_losses[-1] = 0.6102897007018327, best_loss = 0.6162386637181043, model saved at 4\n",
      "val_losses[-1] = 0.5926786422729492, best_loss = 0.6102897007018327, model saved at 5\n",
      "val_losses[-1] = 0.5204282950609922, best_loss = 0.5926786422729492, model saved at 6\n",
      "val_losses[-1] = 0.49655320700258015, best_loss = 0.5204282950609922, model saved at 7\n",
      "val_losses[-1] = 0.4957863723859191, best_loss = 0.49655320700258015, model saved at 10\n",
      "val_losses[-1] = 0.46792423631995916, best_loss = 0.4957863723859191, model saved at 14\n",
      "val_losses[-1] = 0.45591711457818745, best_loss = 0.46792423631995916, model saved at 15\n",
      "val_losses[-1] = 0.44557528393343093, best_loss = 0.45591711457818745, model saved at 18\n",
      "val_losses[-1] = 0.4361227057874203, best_loss = 0.44557528393343093, model saved at 20\n",
      "val_losses[-1] = 0.4323207008652389, best_loss = 0.4361227057874203, model saved at 25\n",
      "(1, 0.8)\n",
      "iter 0\n",
      "val_losses[-1] = 1.0031853385269642, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.6858878327533603, best_loss = 1.0031853385269642, model saved at 1\n",
      "val_losses[-1] = 0.6075827179476618, best_loss = 0.6858878327533603, model saved at 2\n",
      "val_losses[-1] = 0.5652193760499358, best_loss = 0.6075827179476618, model saved at 3\n",
      "val_losses[-1] = 0.5507061235606671, best_loss = 0.5652193760499358, model saved at 4\n",
      "val_losses[-1] = 0.49828218715265393, best_loss = 0.5507061235606671, model saved at 5\n",
      "val_losses[-1] = 0.4811838342808187, best_loss = 0.49828218715265393, model saved at 7\n",
      "val_losses[-1] = 0.46731970058754085, best_loss = 0.4811838342808187, model saved at 8\n",
      "val_losses[-1] = 0.45935318861156704, best_loss = 0.46731970058754085, model saved at 9\n",
      "val_losses[-1] = 0.4577503501437604, best_loss = 0.45935318861156704, model saved at 10\n",
      "val_losses[-1] = 0.4530590086244047, best_loss = 0.4577503501437604, model saved at 13\n",
      "val_losses[-1] = 0.4452699082903564, best_loss = 0.4530590086244047, model saved at 14\n",
      "val_losses[-1] = 0.436701700091362, best_loss = 0.4452699082903564, model saved at 15\n",
      "val_losses[-1] = 0.4260879478417337, best_loss = 0.436701700091362, model saved at 20\n",
      "iter 1\n",
      "val_losses[-1] = 1.0306668922305107, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8978384077548981, best_loss = 1.0306668922305107, model saved at 1\n",
      "val_losses[-1] = 0.6380529027432204, best_loss = 0.8978384077548981, model saved at 2\n",
      "val_losses[-1] = 0.5636195095255971, best_loss = 0.6380529027432204, model saved at 4\n",
      "val_losses[-1] = 0.5201264807954431, best_loss = 0.5636195095255971, model saved at 6\n",
      "val_losses[-1] = 0.49344378523528576, best_loss = 0.5201264807954431, model saved at 7\n",
      "val_losses[-1] = 0.48419631374999883, best_loss = 0.49344378523528576, model saved at 10\n",
      "val_losses[-1] = 0.46612866343930365, best_loss = 0.48419631374999883, model saved at 12\n",
      "val_losses[-1] = 0.46201446279883385, best_loss = 0.46612866343930365, model saved at 15\n",
      "val_losses[-1] = 0.4559826192446053, best_loss = 0.46201446279883385, model saved at 17\n",
      "val_losses[-1] = 0.4484389521181583, best_loss = 0.4559826192446053, model saved at 18\n",
      "val_losses[-1] = 0.4483329742215574, best_loss = 0.4484389521181583, model saved at 24\n",
      "val_losses[-1] = 0.44171319296583533, best_loss = 0.4483329742215574, model saved at 27\n",
      "iter 2\n",
      "val_losses[-1] = 1.0422220140695573, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.9650164425373078, best_loss = 1.0422220140695573, model saved at 1\n",
      "val_losses[-1] = 0.6935426980257035, best_loss = 0.9650164425373078, model saved at 2\n",
      "val_losses[-1] = 0.6516435423865914, best_loss = 0.6935426980257035, model saved at 3\n",
      "val_losses[-1] = 0.586225695721805, best_loss = 0.6516435423865914, model saved at 4\n",
      "val_losses[-1] = 0.5392907032743096, best_loss = 0.586225695721805, model saved at 5\n",
      "val_losses[-1] = 0.5295090297237038, best_loss = 0.5392907032743096, model saved at 6\n",
      "val_losses[-1] = 0.5057563431560993, best_loss = 0.5295090297237038, model saved at 7\n",
      "val_losses[-1] = 0.49609322343021633, best_loss = 0.5057563431560993, model saved at 11\n",
      "val_losses[-1] = 0.48466620203107597, best_loss = 0.49609322343021633, model saved at 12\n",
      "val_losses[-1] = 0.4687495117075741, best_loss = 0.48466620203107597, model saved at 14\n",
      "val_losses[-1] = 0.4524925664998591, best_loss = 0.4687495117075741, model saved at 16\n",
      "val_losses[-1] = 0.4473980965092778, best_loss = 0.4524925664998591, model saved at 20\n",
      "val_losses[-1] = 0.43845057133585214, best_loss = 0.4473980965092778, model saved at 21\n",
      "val_losses[-1] = 0.43275176556780937, best_loss = 0.43845057133585214, model saved at 24\n",
      "iter 3\n",
      "val_losses[-1] = 1.0000932816416026, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.9859174344688654, best_loss = 1.0000932816416026, model saved at 1\n",
      "val_losses[-1] = 0.8530106123536825, best_loss = 0.9859174344688654, model saved at 2\n",
      "val_losses[-1] = 0.754028745740652, best_loss = 0.8530106123536825, model saved at 3\n",
      "val_losses[-1] = 0.5943230329081416, best_loss = 0.754028745740652, model saved at 4\n",
      "val_losses[-1] = 0.590431860089302, best_loss = 0.5943230329081416, model saved at 5\n",
      "val_losses[-1] = 0.5560305677354336, best_loss = 0.590431860089302, model saved at 6\n",
      "val_losses[-1] = 0.49879165142774584, best_loss = 0.5560305677354336, model saved at 7\n",
      "val_losses[-1] = 0.47532063433900473, best_loss = 0.49879165142774584, model saved at 10\n",
      "val_losses[-1] = 0.4558803976513445, best_loss = 0.47532063433900473, model saved at 12\n",
      "val_losses[-1] = 0.4458890907466412, best_loss = 0.4558803976513445, model saved at 14\n",
      "val_losses[-1] = 0.43900524349883197, best_loss = 0.4458890907466412, model saved at 17\n",
      "val_losses[-1] = 0.4302634520456195, best_loss = 0.43900524349883197, model saved at 22\n",
      "iter 4\n",
      "val_losses[-1] = 0.9948287196457386, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8312718905508518, best_loss = 0.9948287196457386, model saved at 1\n",
      "val_losses[-1] = 0.5993751826696098, best_loss = 0.8312718905508518, model saved at 2\n",
      "val_losses[-1] = 0.5177676327526569, best_loss = 0.5993751826696098, model saved at 4\n",
      "val_losses[-1] = 0.4987902401946485, best_loss = 0.5177676327526569, model saved at 7\n",
      "val_losses[-1] = 0.49586004968732594, best_loss = 0.4987902401946485, model saved at 8\n",
      "val_losses[-1] = 0.47633247412741186, best_loss = 0.49586004968732594, model saved at 10\n",
      "val_losses[-1] = 0.44202471943572164, best_loss = 0.47633247412741186, model saved at 15\n",
      "val_losses[-1] = 0.4333046774379909, best_loss = 0.44202471943572164, model saved at 18\n",
      "val_losses[-1] = 0.42687602723017337, best_loss = 0.4333046774379909, model saved at 25\n",
      "(1, 0.7)\n",
      "iter 0\n",
      "val_losses[-1] = 0.9949928242713213, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7659328706562519, best_loss = 0.9949928242713213, model saved at 1\n",
      "val_losses[-1] = 0.640381726063788, best_loss = 0.7659328706562519, model saved at 2\n",
      "val_losses[-1] = 0.567121846973896, best_loss = 0.640381726063788, model saved at 3\n",
      "val_losses[-1] = 0.50705794878304, best_loss = 0.567121846973896, model saved at 4\n",
      "val_losses[-1] = 0.4997312449850142, best_loss = 0.50705794878304, model saved at 5\n",
      "val_losses[-1] = 0.47536970106884835, best_loss = 0.4997312449850142, model saved at 7\n",
      "val_losses[-1] = 0.46917686313390733, best_loss = 0.47536970106884835, model saved at 8\n",
      "val_losses[-1] = 0.45373041527345775, best_loss = 0.46917686313390733, model saved at 9\n",
      "val_losses[-1] = 0.45144724948331716, best_loss = 0.45373041527345775, model saved at 13\n",
      "val_losses[-1] = 0.44059839528054, best_loss = 0.45144724948331716, model saved at 15\n",
      "val_losses[-1] = 0.44057049266994, best_loss = 0.44059839528054, model saved at 16\n",
      "val_losses[-1] = 0.44024014566093683, best_loss = 0.44057049266994, model saved at 18\n",
      "val_losses[-1] = 0.4292564237490296, best_loss = 0.44024014566093683, model saved at 20\n",
      "iter 1\n",
      "val_losses[-1] = 1.018730791285634, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.901996024698019, best_loss = 1.018730791285634, model saved at 1\n",
      "val_losses[-1] = 0.6744869222864509, best_loss = 0.901996024698019, model saved at 2\n",
      "val_losses[-1] = 0.6347103366628289, best_loss = 0.6744869222864509, model saved at 3\n",
      "val_losses[-1] = 0.5400250365957617, best_loss = 0.6347103366628289, model saved at 4\n",
      "val_losses[-1] = 0.4940574369393289, best_loss = 0.5400250365957617, model saved at 6\n",
      "val_losses[-1] = 0.473107897490263, best_loss = 0.4940574369393289, model saved at 10\n",
      "val_losses[-1] = 0.4551404149271548, best_loss = 0.473107897490263, model saved at 17\n",
      "val_losses[-1] = 0.4418927991762757, best_loss = 0.4551404149271548, model saved at 18\n",
      "val_losses[-1] = 0.43625439880415795, best_loss = 0.4418927991762757, model saved at 24\n",
      "iter 2\n",
      "val_losses[-1] = 1.0052058406174182, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.9863715641200542, best_loss = 1.0052058406174182, model saved at 1\n",
      "val_losses[-1] = 0.6823223013430834, best_loss = 0.9863715641200542, model saved at 2\n",
      "val_losses[-1] = 0.6385556494817137, best_loss = 0.6823223013430834, model saved at 3\n",
      "val_losses[-1] = 0.5604955883696675, best_loss = 0.6385556494817137, model saved at 4\n",
      "val_losses[-1] = 0.5471997000277042, best_loss = 0.5604955883696675, model saved at 5\n",
      "val_losses[-1] = 0.5148365344852209, best_loss = 0.5471997000277042, model saved at 6\n",
      "val_losses[-1] = 0.508092388510704, best_loss = 0.5148365344852209, model saved at 8\n",
      "val_losses[-1] = 0.48180392226204277, best_loss = 0.508092388510704, model saved at 9\n",
      "val_losses[-1] = 0.4752412336878479, best_loss = 0.48180392226204277, model saved at 11\n",
      "val_losses[-1] = 0.4569658299908042, best_loss = 0.4752412336878479, model saved at 14\n",
      "val_losses[-1] = 0.4417315434664488, best_loss = 0.4569658299908042, model saved at 17\n",
      "val_losses[-1] = 0.43621806241571903, best_loss = 0.4417315434664488, model saved at 20\n",
      "val_losses[-1] = 0.42845880417153237, best_loss = 0.43621806241571903, model saved at 21\n",
      "iter 3\n",
      "val_losses[-1] = 1.0034446019679308, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.9760127365589142, best_loss = 1.0034446019679308, model saved at 1\n",
      "val_losses[-1] = 0.6917118931189179, best_loss = 0.9760127365589142, model saved at 2\n",
      "val_losses[-1] = 0.5764470007270575, best_loss = 0.6917118931189179, model saved at 3\n",
      "val_losses[-1] = 0.5224708697758615, best_loss = 0.5764470007270575, model saved at 6\n",
      "val_losses[-1] = 0.4672716801986098, best_loss = 0.5224708697758615, model saved at 7\n",
      "val_losses[-1] = 0.46577372755855323, best_loss = 0.4672716801986098, model saved at 9\n",
      "val_losses[-1] = 0.4593997864983976, best_loss = 0.46577372755855323, model saved at 11\n",
      "val_losses[-1] = 0.45541885159909723, best_loss = 0.4593997864983976, model saved at 12\n",
      "val_losses[-1] = 0.43744776025414467, best_loss = 0.45541885159909723, model saved at 13\n",
      "val_losses[-1] = 0.43463897574692967, best_loss = 0.43744776025414467, model saved at 22\n",
      "val_losses[-1] = 0.4319229026325047, best_loss = 0.43463897574692967, model saved at 23\n",
      "iter 4\n",
      "val_losses[-1] = 0.9951414868235589, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8383913990110159, best_loss = 0.9951414868235589, model saved at 1\n",
      "val_losses[-1] = 0.7147636128589511, best_loss = 0.8383913990110159, model saved at 2\n",
      "val_losses[-1] = 0.6131275800988079, best_loss = 0.7147636128589511, model saved at 3\n",
      "val_losses[-1] = 0.5370818443596364, best_loss = 0.6131275800988079, model saved at 4\n",
      "val_losses[-1] = 0.52293102145195, best_loss = 0.5370818443596364, model saved at 6\n",
      "val_losses[-1] = 0.5066880943253637, best_loss = 0.52293102145195, model saved at 7\n",
      "val_losses[-1] = 0.4759481785818934, best_loss = 0.5066880943253637, model saved at 8\n",
      "val_losses[-1] = 0.4757293378934264, best_loss = 0.4759481785818934, model saved at 10\n",
      "val_losses[-1] = 0.44612180199474094, best_loss = 0.4757293378934264, model saved at 15\n",
      "val_losses[-1] = 0.4338040415197611, best_loss = 0.44612180199474094, model saved at 18\n",
      "(1, 0.6)\n",
      "iter 0\n",
      "val_losses[-1] = 0.9999421369284391, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7586379572749138, best_loss = 0.9999421369284391, model saved at 1\n",
      "val_losses[-1] = 0.711085525713861, best_loss = 0.7586379572749138, model saved at 2\n",
      "val_losses[-1] = 0.5449653547257185, best_loss = 0.711085525713861, model saved at 3\n",
      "val_losses[-1] = 0.5320183612406254, best_loss = 0.5449653547257185, model saved at 4\n",
      "val_losses[-1] = 0.4964141996577382, best_loss = 0.5320183612406254, model saved at 5\n",
      "val_losses[-1] = 0.48791853403672575, best_loss = 0.4964141996577382, model saved at 7\n",
      "val_losses[-1] = 0.48607500195503234, best_loss = 0.48791853403672575, model saved at 8\n",
      "val_losses[-1] = 0.46954589802771807, best_loss = 0.48607500195503234, model saved at 9\n",
      "val_losses[-1] = 0.4482660569250584, best_loss = 0.46954589802771807, model saved at 10\n",
      "val_losses[-1] = 0.4430320647545159, best_loss = 0.4482660569250584, model saved at 13\n",
      "val_losses[-1] = 0.4322832123376429, best_loss = 0.4430320647545159, model saved at 16\n",
      "val_losses[-1] = 0.42715318584814665, best_loss = 0.4322832123376429, model saved at 20\n",
      "iter 1\n",
      "val_losses[-1] = 1.0126411877572536, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7437058717012406, best_loss = 1.0126411877572536, model saved at 1\n",
      "val_losses[-1] = 0.5862276691943407, best_loss = 0.7437058717012406, model saved at 2\n",
      "val_losses[-1] = 0.4995027519762516, best_loss = 0.5862276691943407, model saved at 4\n",
      "val_losses[-1] = 0.4927458534017205, best_loss = 0.4995027519762516, model saved at 6\n",
      "val_losses[-1] = 0.48848008215427396, best_loss = 0.4927458534017205, model saved at 7\n",
      "val_losses[-1] = 0.47674884777516124, best_loss = 0.48848008215427396, model saved at 8\n",
      "val_losses[-1] = 0.4499371529556811, best_loss = 0.47674884777516124, model saved at 10\n",
      "val_losses[-1] = 0.43186737298965455, best_loss = 0.4499371529556811, model saved at 17\n",
      "iter 2\n",
      "val_losses[-1] = 1.0284458123147489, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8515675570815802, best_loss = 1.0284458123147489, model saved at 1\n",
      "val_losses[-1] = 0.6037647230550647, best_loss = 0.8515675570815802, model saved at 2\n",
      "val_losses[-1] = 0.5591682584956288, best_loss = 0.6037647230550647, model saved at 3\n",
      "val_losses[-1] = 0.5147058619186282, best_loss = 0.5591682584956288, model saved at 4\n",
      "val_losses[-1] = 0.49782486278563737, best_loss = 0.5147058619186282, model saved at 5\n",
      "val_losses[-1] = 0.4944428185001016, best_loss = 0.49782486278563737, model saved at 6\n",
      "val_losses[-1] = 0.47314217071980236, best_loss = 0.4944428185001016, model saved at 9\n",
      "val_losses[-1] = 0.4662074063904583, best_loss = 0.47314217071980236, model saved at 11\n",
      "val_losses[-1] = 0.4381509837694466, best_loss = 0.4662074063904583, model saved at 14\n",
      "val_losses[-1] = 0.4331874806899577, best_loss = 0.4381509837694466, model saved at 16\n",
      "val_losses[-1] = 0.4316769514232874, best_loss = 0.4331874806899577, model saved at 17\n",
      "iter 3\n",
      "val_losses[-1] = 0.9953809048980474, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8880606926977634, best_loss = 0.9953809048980474, model saved at 1\n",
      "val_losses[-1] = 0.6592913581058383, best_loss = 0.8880606926977634, model saved at 2\n",
      "val_losses[-1] = 0.5559342790395021, best_loss = 0.6592913581058383, model saved at 3\n",
      "val_losses[-1] = 0.5272928042337298, best_loss = 0.5559342790395021, model saved at 4\n",
      "val_losses[-1] = 0.5048057059757411, best_loss = 0.5272928042337298, model saved at 6\n",
      "val_losses[-1] = 0.48257101979106665, best_loss = 0.5048057059757411, model saved at 7\n",
      "val_losses[-1] = 0.4820665896870196, best_loss = 0.48257101979106665, model saved at 11\n",
      "val_losses[-1] = 0.45507705099880696, best_loss = 0.4820665896870196, model saved at 13\n",
      "val_losses[-1] = 0.4460683261975646, best_loss = 0.45507705099880696, model saved at 14\n",
      "val_losses[-1] = 0.4302402399480343, best_loss = 0.4460683261975646, model saved at 18\n",
      "iter 4\n",
      "val_losses[-1] = 0.8954116251319647, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.6847445664927363, best_loss = 0.8954116251319647, model saved at 1\n",
      "val_losses[-1] = 0.5604288842529058, best_loss = 0.6847445664927363, model saved at 2\n",
      "val_losses[-1] = 0.5331534825265407, best_loss = 0.5604288842529058, model saved at 3\n",
      "val_losses[-1] = 0.4944844926707447, best_loss = 0.5331534825265407, model saved at 4\n",
      "val_losses[-1] = 0.47559662330895663, best_loss = 0.4944844926707447, model saved at 7\n",
      "val_losses[-1] = 0.4679472676478326, best_loss = 0.47559662330895663, model saved at 8\n",
      "val_losses[-1] = 0.4643103441223502, best_loss = 0.4679472676478326, model saved at 10\n",
      "val_losses[-1] = 0.4617341392673552, best_loss = 0.4643103441223502, model saved at 11\n",
      "val_losses[-1] = 0.43969644941389563, best_loss = 0.4617341392673552, model saved at 18\n",
      "val_losses[-1] = 0.4294984009116888, best_loss = 0.43969644941389563, model saved at 20\n",
      "val_losses[-1] = 0.42657942036166785, best_loss = 0.4294984009116888, model saved at 28\n",
      "(1, 0.5)\n",
      "iter 0\n",
      "val_losses[-1] = 0.9926689188927412, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.6012774296104908, best_loss = 0.9926689188927412, model saved at 1\n",
      "val_losses[-1] = 0.5535941235721111, best_loss = 0.6012774296104908, model saved at 2\n",
      "val_losses[-1] = 0.5118525406345725, best_loss = 0.5535941235721111, model saved at 3\n",
      "val_losses[-1] = 0.5014664059504866, best_loss = 0.5118525406345725, model saved at 4\n",
      "val_losses[-1] = 0.44872881639748813, best_loss = 0.5014664059504866, model saved at 7\n",
      "val_losses[-1] = 0.4481773448176682, best_loss = 0.44872881639748813, model saved at 8\n",
      "val_losses[-1] = 0.44220904894173146, best_loss = 0.4481773448176682, model saved at 9\n",
      "val_losses[-1] = 0.44218805376440284, best_loss = 0.44220904894173146, model saved at 12\n",
      "val_losses[-1] = 0.4264571962878108, best_loss = 0.44218805376440284, model saved at 15\n",
      "val_losses[-1] = 0.4262392809614539, best_loss = 0.4264571962878108, model saved at 20\n",
      "iter 1\n",
      "val_losses[-1] = 1.0199479285627604, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8627983495593071, best_loss = 1.0199479285627604, model saved at 1\n",
      "val_losses[-1] = 0.5825682356953621, best_loss = 0.8627983495593071, model saved at 2\n",
      "val_losses[-1] = 0.5430413631722331, best_loss = 0.5825682356953621, model saved at 3\n",
      "val_losses[-1] = 0.5017389267683029, best_loss = 0.5430413631722331, model saved at 4\n",
      "val_losses[-1] = 0.4725684148259461, best_loss = 0.5017389267683029, model saved at 7\n",
      "val_losses[-1] = 0.4556045450270176, best_loss = 0.4725684148259461, model saved at 10\n",
      "val_losses[-1] = 0.4506909463554621, best_loss = 0.4556045450270176, model saved at 17\n",
      "val_losses[-1] = 0.430991315189749, best_loss = 0.4506909463554621, model saved at 18\n",
      "iter 2\n",
      "val_losses[-1] = 1.0133640520274638, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7995658650994301, best_loss = 1.0133640520274638, model saved at 1\n",
      "val_losses[-1] = 0.6207520283758641, best_loss = 0.7995658650994301, model saved at 2\n",
      "val_losses[-1] = 0.5892249066382647, best_loss = 0.6207520283758641, model saved at 3\n",
      "val_losses[-1] = 0.5172074700705707, best_loss = 0.5892249066382647, model saved at 4\n",
      "val_losses[-1] = 0.5005646066740155, best_loss = 0.5172074700705707, model saved at 5\n",
      "val_losses[-1] = 0.4916367942467332, best_loss = 0.5005646066740155, model saved at 8\n",
      "val_losses[-1] = 0.46653790334239603, best_loss = 0.4916367942467332, model saved at 9\n",
      "val_losses[-1] = 0.4594075673259795, best_loss = 0.46653790334239603, model saved at 12\n",
      "val_losses[-1] = 0.45050982548855245, best_loss = 0.4594075673259795, model saved at 14\n",
      "val_losses[-1] = 0.4323995146434754, best_loss = 0.45050982548855245, model saved at 16\n",
      "val_losses[-1] = 0.4319802281446755, best_loss = 0.4323995146434754, model saved at 21\n",
      "iter 3\n",
      "val_losses[-1] = 0.9918678618967534, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.8510844495147467, best_loss = 0.9918678618967534, model saved at 1\n",
      "val_losses[-1] = 0.6295766182243824, best_loss = 0.8510844495147467, model saved at 2\n",
      "val_losses[-1] = 0.5816822273656725, best_loss = 0.6295766182243824, model saved at 3\n",
      "val_losses[-1] = 0.530840375367552, best_loss = 0.5816822273656725, model saved at 4\n",
      "val_losses[-1] = 0.5158980356529355, best_loss = 0.530840375367552, model saved at 5\n",
      "val_losses[-1] = 0.5061593492515385, best_loss = 0.5158980356529355, model saved at 6\n",
      "val_losses[-1] = 0.4769588798284531, best_loss = 0.5061593492515385, model saved at 7\n",
      "val_losses[-1] = 0.4691300648264587, best_loss = 0.4769588798284531, model saved at 10\n",
      "val_losses[-1] = 0.46795523250475524, best_loss = 0.4691300648264587, model saved at 12\n",
      "val_losses[-1] = 0.4482444618828595, best_loss = 0.46795523250475524, model saved at 13\n",
      "val_losses[-1] = 0.44499674504622816, best_loss = 0.4482444618828595, model saved at 15\n",
      "val_losses[-1] = 0.43850062107667326, best_loss = 0.44499674504622816, model saved at 20\n",
      "val_losses[-1] = 0.4281707129441202, best_loss = 0.43850062107667326, model saved at 22\n",
      "iter 4\n",
      "val_losses[-1] = 1.0095272157341242, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7790786761790514, best_loss = 1.0095272157341242, model saved at 1\n",
      "val_losses[-1] = 0.6052716318517923, best_loss = 0.7790786761790514, model saved at 2\n",
      "val_losses[-1] = 0.5331600144505501, best_loss = 0.6052716318517923, model saved at 4\n",
      "val_losses[-1] = 0.5269567197188735, best_loss = 0.5331600144505501, model saved at 6\n",
      "val_losses[-1] = 0.48391417115926744, best_loss = 0.5269567197188735, model saved at 7\n",
      "val_losses[-1] = 0.4799094564281404, best_loss = 0.48391417115926744, model saved at 8\n",
      "val_losses[-1] = 0.4787367507815361, best_loss = 0.4799094564281404, model saved at 10\n",
      "val_losses[-1] = 0.47210399676114323, best_loss = 0.4787367507815361, model saved at 11\n",
      "val_losses[-1] = 0.46782171651721, best_loss = 0.47210399676114323, model saved at 12\n",
      "val_losses[-1] = 0.445518156979233, best_loss = 0.46782171651721, model saved at 14\n",
      "val_losses[-1] = 0.4396150015294552, best_loss = 0.445518156979233, model saved at 15\n",
      "val_losses[-1] = 0.43714469112455845, best_loss = 0.4396150015294552, model saved at 18\n",
      "val_losses[-1] = 0.42436802266165613, best_loss = 0.43714469112455845, model saved at 20\n",
      "(1, 0.4)\n",
      "iter 0\n",
      "val_losses[-1] = 0.9825082007795573, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.695926908031106, best_loss = 0.9825082007795573, model saved at 1\n",
      "val_losses[-1] = 0.5605081919580698, best_loss = 0.695926908031106, model saved at 2\n",
      "val_losses[-1] = 0.5119019752368331, best_loss = 0.5605081919580698, model saved at 3\n",
      "val_losses[-1] = 0.455223991908133, best_loss = 0.5119019752368331, model saved at 7\n",
      "val_losses[-1] = 0.4459017083980143, best_loss = 0.455223991908133, model saved at 9\n",
      "val_losses[-1] = 0.4439073711633682, best_loss = 0.4459017083980143, model saved at 10\n",
      "val_losses[-1] = 0.43337507648393514, best_loss = 0.4439073711633682, model saved at 13\n",
      "val_losses[-1] = 0.43242815881967545, best_loss = 0.43337507648393514, model saved at 15\n",
      "val_losses[-1] = 0.42705163415521386, best_loss = 0.43242815881967545, model saved at 18\n",
      "iter 1\n",
      "val_losses[-1] = 1.0055025205016137, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.6581411227583885, best_loss = 1.0055025205016137, model saved at 1\n",
      "val_losses[-1] = 0.5589557940140366, best_loss = 0.6581411227583885, model saved at 2\n",
      "val_losses[-1] = 0.5093861913308502, best_loss = 0.5589557940140366, model saved at 4\n",
      "val_losses[-1] = 0.4834126309491694, best_loss = 0.5093861913308502, model saved at 5\n",
      "val_losses[-1] = 0.4829234270378947, best_loss = 0.4834126309491694, model saved at 7\n",
      "val_losses[-1] = 0.4709947590716183, best_loss = 0.4829234270378947, model saved at 9\n",
      "val_losses[-1] = 0.46219308087602257, best_loss = 0.4709947590716183, model saved at 10\n",
      "val_losses[-1] = 0.4616912627592683, best_loss = 0.46219308087602257, model saved at 12\n",
      "val_losses[-1] = 0.4513117576949298, best_loss = 0.4616912627592683, model saved at 13\n",
      "val_losses[-1] = 0.43832782916724683, best_loss = 0.4513117576949298, model saved at 15\n",
      "iter 2\n",
      "val_losses[-1] = 1.0621049497276545, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.741503118723631, best_loss = 1.0621049497276545, model saved at 1\n",
      "val_losses[-1] = 0.5818014046177268, best_loss = 0.741503118723631, model saved at 2\n",
      "val_losses[-1] = 0.5507381148636341, best_loss = 0.5818014046177268, model saved at 3\n",
      "val_losses[-1] = 0.5001968506723642, best_loss = 0.5507381148636341, model saved at 4\n",
      "val_losses[-1] = 0.47637638337910176, best_loss = 0.5001968506723642, model saved at 5\n",
      "val_losses[-1] = 0.46933406721800563, best_loss = 0.47637638337910176, model saved at 7\n",
      "val_losses[-1] = 0.45127634359523655, best_loss = 0.46933406721800563, model saved at 10\n",
      "val_losses[-1] = 0.4512311778962612, best_loss = 0.45127634359523655, model saved at 12\n",
      "val_losses[-1] = 0.42699264977127316, best_loss = 0.4512311778962612, model saved at 14\n",
      "iter 3\n",
      "val_losses[-1] = 0.990305607393384, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.7095352988690138, best_loss = 0.990305607393384, model saved at 1\n",
      "val_losses[-1] = 0.6079110080376268, best_loss = 0.7095352988690138, model saved at 2\n",
      "val_losses[-1] = 0.5651496279984712, best_loss = 0.6079110080376268, model saved at 3\n",
      "val_losses[-1] = 0.5192136140540242, best_loss = 0.5651496279984712, model saved at 4\n",
      "val_losses[-1] = 0.5093119172379375, best_loss = 0.5192136140540242, model saved at 5\n",
      "val_losses[-1] = 0.4777505214326084, best_loss = 0.5093119172379375, model saved at 7\n",
      "val_losses[-1] = 0.4560969345271587, best_loss = 0.4777505214326084, model saved at 9\n",
      "val_losses[-1] = 0.4351922403089702, best_loss = 0.4560969345271587, model saved at 13\n",
      "val_losses[-1] = 0.43363024964928626, best_loss = 0.4351922403089702, model saved at 14\n",
      "val_losses[-1] = 0.432949660345912, best_loss = 0.43363024964928626, model saved at 18\n",
      "iter 4\n",
      "val_losses[-1] = 0.910605913773179, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.6191936610266566, best_loss = 0.910605913773179, model saved at 1\n",
      "val_losses[-1] = 0.5494868231005967, best_loss = 0.6191936610266566, model saved at 2\n",
      "val_losses[-1] = 0.5146007925271988, best_loss = 0.5494868231005967, model saved at 4\n",
      "val_losses[-1] = 0.48211480062454937, best_loss = 0.5146007925271988, model saved at 7\n",
      "val_losses[-1] = 0.4539167100563645, best_loss = 0.48211480062454937, model saved at 8\n",
      "val_losses[-1] = 0.4483903945423663, best_loss = 0.4539167100563645, model saved at 11\n",
      "val_losses[-1] = 0.4454265839420259, best_loss = 0.4483903945423663, model saved at 13\n",
      "val_losses[-1] = 0.44105643769726155, best_loss = 0.4454265839420259, model saved at 14\n",
      "val_losses[-1] = 0.43008126337081193, best_loss = 0.44105643769726155, model saved at 15\n",
      "val_losses[-1] = 0.42162552047520874, best_loss = 0.43008126337081193, model saved at 20\n",
      "(1, 0.3)\n",
      "iter 0\n",
      "val_losses[-1] = 0.8057912062853575, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.6391269179061055, best_loss = 0.8057912062853575, model saved at 1\n",
      "val_losses[-1] = 0.5482409063726663, best_loss = 0.6391269179061055, model saved at 2\n",
      "val_losses[-1] = 0.49710310585796835, best_loss = 0.5482409063726663, model saved at 3\n",
      "val_losses[-1] = 0.48061276841908696, best_loss = 0.49710310585796835, model saved at 4\n",
      "val_losses[-1] = 0.46769217737019064, best_loss = 0.48061276841908696, model saved at 5\n",
      "val_losses[-1] = 0.44376742420718074, best_loss = 0.46769217737019064, model saved at 7\n",
      "val_losses[-1] = 0.4379441598430276, best_loss = 0.44376742420718074, model saved at 9\n",
      "val_losses[-1] = 0.43347065784037114, best_loss = 0.4379441598430276, model saved at 16\n",
      "val_losses[-1] = 0.4256633071228862, best_loss = 0.43347065784037114, model saved at 18\n",
      "iter 1\n",
      "val_losses[-1] = 0.9990867156535387, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.9327968414872885, best_loss = 0.9990867156535387, model saved at 1\n",
      "val_losses[-1] = 0.5522134078666567, best_loss = 0.9327968414872885, model saved at 2\n",
      "val_losses[-1] = 0.5457765348255634, best_loss = 0.5522134078666567, model saved at 3\n",
      "val_losses[-1] = 0.48379742009565235, best_loss = 0.5457765348255634, model saved at 4\n",
      "val_losses[-1] = 0.47078052079305055, best_loss = 0.48379742009565235, model saved at 5\n",
      "val_losses[-1] = 0.44846184775233267, best_loss = 0.47078052079305055, model saved at 8\n",
      "val_losses[-1] = 0.4373390944674611, best_loss = 0.44846184775233267, model saved at 9\n",
      "val_losses[-1] = 0.4339767556171864, best_loss = 0.4373390944674611, model saved at 15\n",
      "val_losses[-1] = 0.4323432410135865, best_loss = 0.4339767556171864, model saved at 17\n",
      "iter 2\n",
      "val_losses[-1] = 0.9091170191764831, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.6578982518985868, best_loss = 0.9091170191764831, model saved at 1\n",
      "val_losses[-1] = 0.5509609723463654, best_loss = 0.6578982518985868, model saved at 2\n",
      "val_losses[-1] = 0.494684353005141, best_loss = 0.5509609723463654, model saved at 4\n",
      "val_losses[-1] = 0.48453770065680146, best_loss = 0.494684353005141, model saved at 5\n",
      "val_losses[-1] = 0.4752022860571742, best_loss = 0.48453770065680146, model saved at 6\n",
      "val_losses[-1] = 0.4592311906628311, best_loss = 0.4752022860571742, model saved at 7\n",
      "val_losses[-1] = 0.4454384732991457, best_loss = 0.4592311906628311, model saved at 9\n",
      "val_losses[-1] = 0.4286028824746609, best_loss = 0.4454384732991457, model saved at 14\n",
      "iter 3\n",
      "val_losses[-1] = 0.7907027497887611, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5737683121114969, best_loss = 0.7907027497887611, model saved at 1\n",
      "val_losses[-1] = 0.541448247525841, best_loss = 0.5737683121114969, model saved at 3\n",
      "val_losses[-1] = 0.4821090348064899, best_loss = 0.541448247525841, model saved at 5\n",
      "val_losses[-1] = 0.45320050390437244, best_loss = 0.4821090348064899, model saved at 7\n",
      "val_losses[-1] = 0.45232780892401936, best_loss = 0.45320050390437244, model saved at 12\n",
      "val_losses[-1] = 0.43333143116906286, best_loss = 0.45232780892401936, model saved at 13\n",
      "val_losses[-1] = 0.431919508241117, best_loss = 0.43333143116906286, model saved at 16\n",
      "val_losses[-1] = 0.4258898883126676, best_loss = 0.431919508241117, model saved at 18\n",
      "iter 4\n",
      "val_losses[-1] = 0.8131927412003279, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5967554037459195, best_loss = 0.8131927412003279, model saved at 1\n",
      "val_losses[-1] = 0.5359382044523955, best_loss = 0.5967554037459195, model saved at 2\n",
      "val_losses[-1] = 0.4759470638819039, best_loss = 0.5359382044523955, model saved at 4\n",
      "val_losses[-1] = 0.4573175299912691, best_loss = 0.4759470638819039, model saved at 8\n",
      "val_losses[-1] = 0.45551821645349266, best_loss = 0.4573175299912691, model saved at 12\n",
      "val_losses[-1] = 0.45013253558427097, best_loss = 0.45551821645349266, model saved at 14\n",
      "val_losses[-1] = 0.42930459799245, best_loss = 0.45013253558427097, model saved at 15\n",
      "val_losses[-1] = 0.42671195026487113, best_loss = 0.42930459799245, model saved at 18\n",
      "(1, 0.2)\n",
      "iter 0\n",
      "val_losses[-1] = 0.7239080384373665, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5742317374795676, best_loss = 0.7239080384373665, model saved at 1\n",
      "val_losses[-1] = 0.5305246230214834, best_loss = 0.5742317374795676, model saved at 2\n",
      "val_losses[-1] = 0.4966600310057402, best_loss = 0.5305246230214834, model saved at 3\n",
      "val_losses[-1] = 0.48387824948877095, best_loss = 0.4966600310057402, model saved at 5\n",
      "val_losses[-1] = 0.47281043995171784, best_loss = 0.48387824948877095, model saved at 7\n",
      "val_losses[-1] = 0.435705927759409, best_loss = 0.47281043995171784, model saved at 8\n",
      "val_losses[-1] = 0.4255750616081059, best_loss = 0.435705927759409, model saved at 13\n",
      "iter 1\n",
      "val_losses[-1] = 0.8364124841988086, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5616735272109509, best_loss = 0.8364124841988086, model saved at 1\n",
      "val_losses[-1] = 0.524117368645966, best_loss = 0.5616735272109509, model saved at 2\n",
      "val_losses[-1] = 0.5131068270653486, best_loss = 0.524117368645966, model saved at 3\n",
      "val_losses[-1] = 0.48729617409408094, best_loss = 0.5131068270653486, model saved at 4\n",
      "val_losses[-1] = 0.461888138577342, best_loss = 0.48729617409408094, model saved at 5\n",
      "val_losses[-1] = 0.445507528539747, best_loss = 0.461888138577342, model saved at 8\n",
      "val_losses[-1] = 0.435267127212137, best_loss = 0.445507528539747, model saved at 11\n",
      "val_losses[-1] = 0.43435833202674984, best_loss = 0.435267127212137, model saved at 12\n",
      "val_losses[-1] = 0.426878316141665, best_loss = 0.43435833202674984, model saved at 13\n",
      "iter 2\n",
      "val_losses[-1] = 0.917498328909278, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5869204236194492, best_loss = 0.917498328909278, model saved at 1\n",
      "val_losses[-1] = 0.5146658455953002, best_loss = 0.5869204236194492, model saved at 2\n",
      "val_losses[-1] = 0.5133256881497801, best_loss = 0.5146658455953002, model saved at 4\n",
      "val_losses[-1] = 0.4927233605645597, best_loss = 0.5133256881497801, model saved at 5\n",
      "val_losses[-1] = 0.4617372704669833, best_loss = 0.4927233605645597, model saved at 6\n",
      "val_losses[-1] = 0.4551738264039159, best_loss = 0.4617372704669833, model saved at 8\n",
      "val_losses[-1] = 0.4536720708012581, best_loss = 0.4551738264039159, model saved at 9\n",
      "val_losses[-1] = 0.43997920653782785, best_loss = 0.4536720708012581, model saved at 10\n",
      "val_losses[-1] = 0.4274399540387094, best_loss = 0.43997920653782785, model saved at 14\n",
      "iter 3\n",
      "val_losses[-1] = 0.7974414970725775, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5793415738269687, best_loss = 0.7974414970725775, model saved at 1\n",
      "val_losses[-1] = 0.5216076850891114, best_loss = 0.5793415738269687, model saved at 2\n",
      "val_losses[-1] = 0.4907045751810074, best_loss = 0.5216076850891114, model saved at 5\n",
      "val_losses[-1] = 0.48413918698206543, best_loss = 0.4907045751810074, model saved at 6\n",
      "val_losses[-1] = 0.4556906968355179, best_loss = 0.48413918698206543, model saved at 7\n",
      "val_losses[-1] = 0.44014839101582764, best_loss = 0.4556906968355179, model saved at 10\n",
      "val_losses[-1] = 0.43454576851800086, best_loss = 0.44014839101582764, model saved at 13\n",
      "val_losses[-1] = 0.42869726549834014, best_loss = 0.43454576851800086, model saved at 14\n",
      "iter 4\n",
      "val_losses[-1] = 0.9326250713318587, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5598766570910811, best_loss = 0.9326250713318587, model saved at 1\n",
      "val_losses[-1] = 0.5251151047646999, best_loss = 0.5598766570910811, model saved at 2\n",
      "val_losses[-1] = 0.4788589529693127, best_loss = 0.5251151047646999, model saved at 4\n",
      "val_losses[-1] = 0.46289161033928394, best_loss = 0.4788589529693127, model saved at 6\n",
      "val_losses[-1] = 0.45873150397092105, best_loss = 0.46289161033928394, model saved at 7\n",
      "val_losses[-1] = 0.4525600723922253, best_loss = 0.45873150397092105, model saved at 8\n",
      "val_losses[-1] = 0.4473629671148956, best_loss = 0.4525600723922253, model saved at 11\n",
      "val_losses[-1] = 0.4376908648759127, best_loss = 0.4473629671148956, model saved at 15\n",
      "(1, 0.1)\n",
      "iter 0\n",
      "val_losses[-1] = 0.6903558764606714, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5031814344227314, best_loss = 0.6903558764606714, model saved at 1\n",
      "val_losses[-1] = 0.48689186898991466, best_loss = 0.5031814344227314, model saved at 3\n",
      "val_losses[-1] = 0.47775352345779537, best_loss = 0.48689186898991466, model saved at 4\n",
      "val_losses[-1] = 0.4776718565262854, best_loss = 0.47775352345779537, model saved at 5\n",
      "val_losses[-1] = 0.443462329916656, best_loss = 0.4776718565262854, model saved at 7\n",
      "val_losses[-1] = 0.4371579776518047, best_loss = 0.443462329916656, model saved at 8\n",
      "val_losses[-1] = 0.42635180661454797, best_loss = 0.4371579776518047, model saved at 9\n",
      "iter 1\n",
      "val_losses[-1] = 0.831503090262413, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.540063445456326, best_loss = 0.831503090262413, model saved at 1\n",
      "val_losses[-1] = 0.49534109476953747, best_loss = 0.540063445456326, model saved at 2\n",
      "val_losses[-1] = 0.46737970523536204, best_loss = 0.49534109476953747, model saved at 4\n",
      "val_losses[-1] = 0.46607717787846925, best_loss = 0.46737970523536204, model saved at 5\n",
      "val_losses[-1] = 0.4402416697703302, best_loss = 0.46607717787846925, model saved at 7\n",
      "val_losses[-1] = 0.4343208880163729, best_loss = 0.4402416697703302, model saved at 8\n",
      "val_losses[-1] = 0.43041061013937, best_loss = 0.4343208880163729, model saved at 17\n",
      "iter 2\n",
      "val_losses[-1] = 0.8494739782065153, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.6122001335024834, best_loss = 0.8494739782065153, model saved at 1\n",
      "val_losses[-1] = 0.5020592276006937, best_loss = 0.6122001335024834, model saved at 2\n",
      "val_losses[-1] = 0.48524347906932236, best_loss = 0.5020592276006937, model saved at 5\n",
      "val_losses[-1] = 0.4241284569725394, best_loss = 0.48524347906932236, model saved at 8\n",
      "iter 3\n",
      "val_losses[-1] = 0.7798367317765951, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5457992199808359, best_loss = 0.7798367317765951, model saved at 1\n",
      "val_losses[-1] = 0.5358130855485796, best_loss = 0.5457992199808359, model saved at 2\n",
      "val_losses[-1] = 0.49672027472406627, best_loss = 0.5358130855485796, model saved at 3\n",
      "val_losses[-1] = 0.4881035923026502, best_loss = 0.49672027472406627, model saved at 4\n",
      "val_losses[-1] = 0.45243903091177345, best_loss = 0.4881035923026502, model saved at 5\n",
      "val_losses[-1] = 0.44967788066715003, best_loss = 0.45243903091177345, model saved at 6\n",
      "val_losses[-1] = 0.43857534509152174, best_loss = 0.44967788066715003, model saved at 9\n",
      "val_losses[-1] = 0.4350011674221605, best_loss = 0.43857534509152174, model saved at 10\n",
      "val_losses[-1] = 0.4272839281708002, best_loss = 0.4350011674221605, model saved at 14\n",
      "iter 4\n",
      "val_losses[-1] = 0.6964698756113649, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.5295440805144608, best_loss = 0.6964698756113649, model saved at 1\n",
      "val_losses[-1] = 0.5287038337439298, best_loss = 0.5295440805144608, model saved at 2\n",
      "val_losses[-1] = 0.526158255059272, best_loss = 0.5287038337439298, model saved at 3\n",
      "val_losses[-1] = 0.46853611171245574, best_loss = 0.526158255059272, model saved at 4\n",
      "val_losses[-1] = 0.45866435999050736, best_loss = 0.46853611171245574, model saved at 6\n",
      "val_losses[-1] = 0.4440821622498333, best_loss = 0.45866435999050736, model saved at 7\n",
      "val_losses[-1] = 0.4267634339630604, best_loss = 0.4440821622498333, model saved at 10\n",
      "val_losses[-1] = 0.4168817989528179, best_loss = 0.4267634339630604, model saved at 12\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "num_iter = 5\n",
    "\n",
    "loss_fns = (nn.CrossEntropyLoss(), nn.CrossEntropyLoss())\n",
    "\n",
    "for loss_ratios in all_loss_ratios:\n",
    "    print(loss_ratios)\n",
    "    \n",
    "    models = []\n",
    "    for j in range(num_iter):\n",
    "        print(f\"iter {j}\")\n",
    "        dataset = torch.load(f\"data/amc_data_512_case_2.pt\")\n",
    "        train_loader = dataset['train_loader']\n",
    "        val_loader = dataset['val_loader']\n",
    "        \n",
    "        torch.manual_seed(j)\n",
    "        model_mtl = amc_model_mtl(case=2)\n",
    "        model_mtl.cuda()\n",
    "\n",
    "        optimizer = torch.optim.Adam(model_mtl.parameters(), lr=0.0005, weight_decay=0.0001)\n",
    "\n",
    "        model, losses, losses_mod, losses_snr, val_losses, val_losses_snr = train_mtl(model_mtl, optimizer, train_loader, \n",
    "                                                                                      val_loader, loss_fns, \n",
    "                                                                                      num_epochs=num_epochs, verbose=False, \n",
    "                                                                                      loss_ratios=loss_ratios)\n",
    "        \n",
    "        model_config = {\"weights\": model_mtl.state_dict(),\n",
    "                        \"losses\": losses,\n",
    "                        \"val_losses\": val_losses,\n",
    "                        \"losses_mod\": losses_mod,\n",
    "                        \"losses_snr\": losses_snr,\n",
    "                        \"val_losses_snr\": val_losses_snr}\n",
    "        \n",
    "        models.append(model_config)\n",
    "    torch.save(models, f'models/case_2/amc_{loss_ratios[0]}_{loss_ratios[1]}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d31bc7e-498f-4037-9082-253b0e3e3255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.9)\n",
      "(1, 0.8)\n",
      "(1, 0.7)\n",
      "(1, 0.6)\n",
      "(1, 0.5)\n",
      "(1, 0.4)\n",
      "(1, 0.3)\n",
      "(1, 0.2)\n",
      "(1, 0.1)\n"
     ]
    }
   ],
   "source": [
    "snr_range = np.arange(-15,16,2)\n",
    "\n",
    "# for models in sorted(os.listdir('models')):\n",
    "for loss_ratios in all_loss_ratios:\n",
    "    print(loss_ratios)\n",
    "    results = []\n",
    "    for model in torch.load(f'models/case_2/amc_{loss_ratios[0]}_{loss_ratios[1]}.pt'):\n",
    "        model_mtl = amc_model_mtl(case=2)\n",
    "        model_mtl.load_state_dict(model['weights'])\n",
    "        accs_mod = test_model_mtl(model_mtl, snr_range, num_frames=128)\n",
    "        \n",
    "        result = {\"accs_mod\": accs_mod,\n",
    "                   \"snr_range\": snr_range,\n",
    "                   \"model\": model}\n",
    "        results.append(result)\n",
    "    torch.save(results, f'results/case_2/amc_{loss_ratios[0]}_{loss_ratios[1]}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4b75a9-27cc-447a-99c9-32807931d0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
