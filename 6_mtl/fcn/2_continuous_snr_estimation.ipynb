{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Continuous FS and SNR estimation with MTL\n",
    "\n",
    "In this notebook we train a double-headed FCN model that does frame sync and SNR estimation. The whole architecture is fully convolutional and can be applied to arbitrary length inputs. To make life easier for myself, I did all the result plotting in the next notebook -- 3_plotting_results.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from comms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(signal.max_len_seq(7)[0][:64])\n",
    "max_seq = signal.max_len_seq(7)[0][:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make one frame of data with preamble attached with random time offset\n",
    "def create_frame(preamble_seq, payload=128, signal_length=200, offset=40):\n",
    "    waveform = np.random.randint(0,2,signal_length)\n",
    "    waveform[offset:offset+len(preamble_seq)] = preamble_seq\n",
    "    waveform = np.where(waveform < 1, -1+0j, 1+0j)\n",
    "    \n",
    "    return waveform\n",
    "\n",
    "# Function returns the DER of a binary sequence preamble_seq by using the standard\n",
    "# correlation under selected impairments.\n",
    "def calculate_baseline(preamble_seq, snr_range=None, num_iter=1500, payload=128,\n",
    "                       signal_length=200, add_phase_offset=True, carrier_offset=None,\n",
    "                       sample_rate=1e6, add_channel=False):\n",
    "    \n",
    "    if snr_range is None:\n",
    "        snr_range = np.arange(-15,10)\n",
    "    \n",
    "    preamble = np.where(preamble_seq < 1, -1+0j, 1+0j)\n",
    "\n",
    "    corr_ers = np.zeros(len(snr_range),)\n",
    "    \n",
    "    if carrier_offset:\n",
    "        offset_sine = np.exp(1j*2*np.pi*(carrier_offset/sample_rate)*np.arange(signal_length))\n",
    "\n",
    "    for idx, snr in enumerate(snr_range):\n",
    "        corr_err = float(0)\n",
    "        for i in range(num_iter):\n",
    "\n",
    "            # Create new frame with a random tau\n",
    "            tau = np.random.randint(0,signal_length-payload-len(preamble_seq))\n",
    "            my_frame = create_frame(preamble_seq, payload=payload, signal_length=signal_length, offset=tau)\n",
    "            \n",
    "            if add_phase_offset:\n",
    "                ph = np.random.randint(-180,high=181)\n",
    "                my_frame = phase_offset(my_frame, offset=ph)\n",
    "                \n",
    "            if carrier_offset is not None:\n",
    "                my_frame = my_frame*offset_sine\n",
    "                \n",
    "            if add_channel:\n",
    "                gains = 1/np.sqrt(2)*(np.random.normal(0)+1j*np.random.normal(0))\n",
    "                my_frame = gains*my_frame\n",
    "                \n",
    "            # Add noise\n",
    "            my_frame = awgn(my_frame, snr)\n",
    "            \n",
    "            # Find peaks using correlation\n",
    "            correlation = np.abs(np.correlate(my_frame, preamble, mode='valid'))\n",
    "            y_corr = np.argmax(correlation)\n",
    "\n",
    "            # Calculate if error\n",
    "            corr_err = corr_err + (y_corr != tau)\n",
    "\n",
    "        corr_ers[idx] = corr_err\n",
    "  \n",
    "    corr_ders = corr_ers/num_iter\n",
    "        \n",
    "    return corr_ders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function returns the DER of a binary sequence preamble_seq by using the standard\n",
    "# correlation under selected impairments.\n",
    "def calculate_baseline(preamble_seq, snr_range=None, num_iter=1500, payload=128,\n",
    "                       signal_length=400, add_phase_offset=True, carrier_offset=None,\n",
    "                       sample_rate=1e6, add_channel=False):\n",
    "    \n",
    "    if snr_range is None:\n",
    "        snr_range = np.arange(-15,10)\n",
    "    \n",
    "    preamble = np.where(preamble_seq < 1, -1+0j, 1+0j)\n",
    "\n",
    "    corr_ers = np.zeros(len(snr_range),)\n",
    "    \n",
    "    if carrier_offset:\n",
    "        offset_sine = np.exp(1j*2*np.pi*(carrier_offset/sample_rate)*np.arange(signal_length))\n",
    "\n",
    "    for idx, snr in enumerate(snr_range):\n",
    "        corr_err = float(0)\n",
    "        for i in range(num_iter):\n",
    "\n",
    "            # Create new frame with a random tau\n",
    "            tau = np.random.randint(0,signal_length-payload-len(preamble_seq))\n",
    "            my_frame = create_frame(preamble_seq, payload=payload, signal_length=signal_length, offset=tau)\n",
    "            \n",
    "            if add_phase_offset:\n",
    "                ph = np.random.randint(-180,high=181)\n",
    "                my_frame = phase_offset(my_frame, offset=ph)\n",
    "                \n",
    "            if carrier_offset is not None:\n",
    "                my_frame = my_frame*offset_sine\n",
    "                \n",
    "            if add_channel:\n",
    "                gains = 1/np.sqrt(2)*(np.random.normal(0)+1j*np.random.normal(0))\n",
    "                my_frame = gains*my_frame\n",
    "                \n",
    "            # Add noise\n",
    "            my_frame = awgn(my_frame, snr)\n",
    "            \n",
    "            # Find peaks using correlation\n",
    "            correlation = np.abs(np.correlate(my_frame, preamble, mode='valid'))\n",
    "            y_corr = np.argmax(correlation)\n",
    "\n",
    "            # Calculate if error\n",
    "            corr_err = corr_err + (y_corr != tau)\n",
    "\n",
    "        corr_ers[idx] = corr_err\n",
    "  \n",
    "    corr_ders = corr_ers/num_iter\n",
    "        \n",
    "    return corr_ders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_range = np.arange(-15,11)\n",
    "seq_lengths = [16, 32, 64]\n",
    "num_examples = 8192\n",
    "num_models = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = {}\n",
    "for seq_length in seq_lengths:\n",
    "    baseline = 1-calculate_baseline(max_seq[:seq_length], snr_range=snr_range, num_iter=200, carrier_offset=1)\n",
    "    baselines[seq_length] = baseline\n",
    "\n",
    "torch.save({'baselines': baselines,\n",
    "            'snr_range': snr_range},\n",
    "            'baseline/mtl_fs_snr_baselines.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "baselines = torch.load('baseline/mtl_fs_snr_baselines.pt')['baselines']\n",
    "\n",
    "for seq_length in seq_lengths:\n",
    "    plt.plot(snr_range, baselines[seq_length])\n",
    "plt.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(data, labels, labels_snr, labels_cfo, to_onehot=True, abs_phase=False, gpu=True):\n",
    "    \n",
    "    # Convert labels to pytorch tensors\n",
    "    if to_onehot:\n",
    "        labels_oh = np.zeros(data.shape)\n",
    "        for idx, label in enumerate(labels):\n",
    "            labels_oh[idx,label] = 1\n",
    "        labels = torch.FloatTensor(labels_oh)\n",
    "    else:\n",
    "        labels = torch.LongTensor(labels)\n",
    "        \n",
    "    labels_snr_extended = torch.FloatTensor(labels_snr.reshape(labels_snr.shape[0], 1).repeat(data.shape[1], axis=1))\n",
    "    labels_cfo_extended = torch.FloatTensor(labels_cfo.reshape(labels_cfo.shape[0], 1).repeat(data.shape[1], axis=1))\n",
    "\n",
    "    # Split into real and imaginary channels\n",
    "    train_data = torch.FloatTensor(np.expand_dims(np.stack((data.real, data.imag),axis=1),axis=1))\n",
    "\n",
    "    # Prep dataset for cuda if gpu true\n",
    "    if gpu:\n",
    "        train_data = train_data.cuda()\n",
    "        labels = labels.cuda()\n",
    "        labels_snr_extended = labels_snr_extended.cuda()\n",
    "        labels_cfo_extended = labels_cfo_extended.cuda()\n",
    "        \n",
    "    return train_data, labels, labels_snr_extended, labels_cfo_extended\n",
    "\n",
    "def gen_training_data(preamble_seq, num_examples = 1024, signal_length = 200, payload=128, max_snr = 10, normalize=False, add_phase_offset=False, add_channel=False, \n",
    "                      clean_outputs=False, sample_rate=1e6, add_carrier_offset=False, max_freq_offset=10e3):\n",
    "\n",
    "    waveforms = np.random.randint(0,2,(num_examples, signal_length))\n",
    "    waveforms = np.where(waveforms < 1, -1+0j, 1+0j)\n",
    "    \n",
    "    preamble = np.where(preamble_seq < 1, -1+0j, 1+0j)\n",
    "    \n",
    "    # Pre-define array to contain complex-valued waveforms\n",
    "#     waveforms = np.zeros((num_examples,signal_length),dtype=np.complex128)\n",
    "\n",
    "    # Predefine labels array\n",
    "    labels = np.zeros((num_examples,),dtype=int)\n",
    "    \n",
    "    labels_snr = np.zeros((num_examples,), dtype=float)\n",
    "    labels_cfo = np.zeros((num_examples,), dtype=float)\n",
    "\n",
    "    # Insert into random offset and save offset as label\n",
    "    for idx, waveform in enumerate(waveforms):\n",
    "        \n",
    "        # Get random time offset\n",
    "        tau = np.random.randint(0,signal_length-len(preamble_seq))\n",
    "        \n",
    "        # Insert packet at offset tau\n",
    "        waveform[tau:tau+len(preamble_seq)] = preamble\n",
    "        \n",
    "        # Our label is the same time offset\n",
    "        labels[idx] = tau\n",
    "        \n",
    "        # Add random phase offset\n",
    "        if add_phase_offset:\n",
    "            waveforms[idx] = phase_offset(waveform,offset=np.random.randint(-180,high=181))\n",
    "        else:\n",
    "            waveforms[idx] = waveform\n",
    "\n",
    "        # Add flat fading channel\n",
    "        if add_channel:\n",
    "            gains = 1/np.sqrt(2)*(np.random.randn()+1j*np.random.randn())\n",
    "            waveforms[idx] = gains*waveforms[idx]\n",
    "            \n",
    "        # Add frequency offset\n",
    "        if add_carrier_offset:\n",
    "            carrier_offset = np.random.randint(0, max_freq_offset)\n",
    "            offset_sine = np.exp(1j*2*np.pi*(carrier_offset/sample_rate)*np.arange(signal_length))\n",
    "            waveforms[idx] = offset_sine*waveforms[idx]\n",
    "    \n",
    "        # Add noise\n",
    "        snr = np.random.randint(-max_snr, max_snr) \n",
    "        waveforms[idx] = awgn(waveforms[idx], snr)\n",
    "\n",
    "        labels_snr[idx] = float(snr)/max_snr\n",
    "        labels_cfo[idx] = float(carrier_offset)/max_freq_offset\n",
    "    \n",
    "    # normalize\n",
    "#     if normalize:\n",
    "#         waveforms = (waveforms/np.max(np.abs(waveforms),axis=1)[:,None])\n",
    "\n",
    "    return waveforms, labels, labels_snr, labels_cfo\n",
    "\n",
    "class preamble_detector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(preamble_detector, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, (2,55), 1, padding=(0,27))\n",
    "        self.conv2 = nn.Conv2d(32, 32, (1,55), 1, padding=(0,27))\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32,1,1,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # First conv layer, correlation\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        # 2nd conv layer, non-linearities and cleanup\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        # Final linear / combining layer\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        # Output only 1 dimension\n",
    "        x = x.squeeze()\n",
    "\n",
    "        return x\n",
    "\n",
    "class preamble_detector_mtl(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(preamble_detector_mtl, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, (2,55), 1, padding=(0,27))\n",
    "        self.conv2 = nn.Conv2d(32, 32, (1,55), 1, padding=(0,27))\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32,1,1,1)\n",
    "        \n",
    "        self.snr_estimator = nn.Conv2d(32,1,1,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # First conv layer, correlation\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        # 2nd conv layer, non-linearities and cleanup\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        # SNR estimation head\n",
    "        snr = self.snr_estimator(x)\n",
    "        snr = snr.squeeze()\n",
    "        \n",
    "        # Final linear / combining layer\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        # Output only 1 dimension\n",
    "        x = x.squeeze()\n",
    "\n",
    "        return x, snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2023)\n",
    "for seq_length in seq_lengths:\n",
    "    # training data\n",
    "    train_data, labels, labels_snr, labels_cfo = gen_training_data(max_seq[:seq_length], num_examples=num_examples, max_snr=10, \n",
    "                                                                   signal_length=400, add_carrier_offset=True, max_freq_offset=1)\n",
    "    train_data, labels, labels_snr, labels_cfo = preprocess(train_data, labels, labels_snr, labels_cfo, to_onehot=True)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_data, labels, labels_snr, labels_cfo)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # validation data\n",
    "    val_data, val_labels, val_labels_snr, val_labels_cfo = gen_training_data(max_seq[:seq_length], num_examples=128, max_snr=10, \n",
    "                                                                             signal_length=400, add_carrier_offset=True, max_freq_offset=1)\n",
    "    val_data, val_labels, val_labels_snr, val_labels_cfo = preprocess(val_data, val_labels, val_labels_snr, val_labels_cfo, to_onehot=True)\n",
    "\n",
    "    val_dataset = torch.utils.data.TensorDataset(val_data, val_labels, val_labels_snr, val_labels_cfo)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    dataset = {'train_loader': train_loader,\n",
    "               'val_loader': val_loader}\n",
    "\n",
    "    torch.save(dataset, f\"data/mtl_fs_snr_{num_examples}_{seq_length}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(detector, optimizer, train_loader, val_loader, loss_fn, num_epochs=5):\n",
    "\n",
    "    losses, snr_losses, fs_losses = [], [], []\n",
    "    val_losses = []\n",
    "\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss, running_fs_loss, running_snr_loss = 0, 0, 0\n",
    "        running_val_loss = 0\n",
    "\n",
    "        for x_train, y_train, z_train, w_train in train_loader:\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = detector(x_train)\n",
    "\n",
    "            loss = loss_fn(outputs, y_train)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss = running_loss + loss.item()\n",
    "\n",
    "        losses.append(running_loss/len(train_loader))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # evaluate validation loss\n",
    "            for x_val, y_val, z_val, w_val in val_loader:\n",
    "                val_outputs = detector(x_val)\n",
    "                val_loss = loss_fn(val_outputs, y_val)\n",
    "                running_val_loss = val_loss.item()\n",
    "        \n",
    "        val_losses.append(running_val_loss/len(val_loader))\n",
    "\n",
    "        if val_losses[-1] < best_loss:\n",
    "            print(f'val_losses[-1] = {val_losses[-1]}, best_loss = {best_loss}, model saved at {epoch}')\n",
    "            saved_model = detector.state_dict()\n",
    "            best_loss = val_losses[-1]\n",
    "\n",
    "    detector.load_state_dict(saved_model)\n",
    "    \n",
    "    return detector, losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006412063376046717, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005955626838840544, best_loss = 0.0006412063376046717, model saved at 1\n",
      "val_losses[-1] = 0.0005198577418923378, best_loss = 0.0005955626838840544, model saved at 2\n",
      "val_losses[-1] = 0.0004429582040756941, best_loss = 0.0005198577418923378, model saved at 3\n",
      "val_losses[-1] = 0.00040260120294988155, best_loss = 0.0004429582040756941, model saved at 4\n",
      "val_losses[-1] = 0.00039690471021458507, best_loss = 0.00040260120294988155, model saved at 5\n",
      "val_losses[-1] = 0.00039008972817100585, best_loss = 0.00039690471021458507, model saved at 6\n",
      "val_losses[-1] = 0.00037995463935658336, best_loss = 0.00039008972817100585, model saved at 7\n",
      "val_losses[-1] = 0.0003764138964470476, best_loss = 0.00037995463935658336, model saved at 14\n",
      "val_losses[-1] = 0.0003721752727869898, best_loss = 0.0003764138964470476, model saved at 20\n",
      "val_losses[-1] = 0.0003704047412611544, best_loss = 0.0003721752727869898, model saved at 29\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0005831076996400952, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0004321388842072338, best_loss = 0.0005831076996400952, model saved at 1\n",
      "val_losses[-1] = 0.00041627470636740327, best_loss = 0.0004321388842072338, model saved at 2\n",
      "val_losses[-1] = 0.0004074976604897529, best_loss = 0.00041627470636740327, model saved at 4\n",
      "val_losses[-1] = 0.0004057775076944381, best_loss = 0.0004074976604897529, model saved at 5\n",
      "val_losses[-1] = 0.0003912254760507494, best_loss = 0.0004057775076944381, model saved at 6\n",
      "val_losses[-1] = 0.00038944618427194655, best_loss = 0.0003912254760507494, model saved at 7\n",
      "val_losses[-1] = 0.00038780629984103143, best_loss = 0.00038944618427194655, model saved at 8\n",
      "val_losses[-1] = 0.0003788632166106254, best_loss = 0.00038780629984103143, model saved at 9\n",
      "val_losses[-1] = 0.0003762662236113101, best_loss = 0.0003788632166106254, model saved at 10\n",
      "val_losses[-1] = 0.0003756552468985319, best_loss = 0.0003762662236113101, model saved at 13\n",
      "val_losses[-1] = 0.0003730075841303915, best_loss = 0.0003756552468985319, model saved at 15\n",
      "val_losses[-1] = 0.0003721887478604913, best_loss = 0.0003730075841303915, model saved at 21\n",
      "val_losses[-1] = 0.00036326562985777855, best_loss = 0.0003721887478604913, model saved at 23\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0006283749244175851, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006071110838092864, best_loss = 0.0006283749244175851, model saved at 1\n",
      "val_losses[-1] = 0.0005967388860881329, best_loss = 0.0006071110838092864, model saved at 2\n",
      "val_losses[-1] = 0.0005167508497834206, best_loss = 0.0005967388860881329, model saved at 3\n",
      "val_losses[-1] = 0.000442919263150543, best_loss = 0.0005167508497834206, model saved at 4\n",
      "val_losses[-1] = 0.00040863838512450457, best_loss = 0.000442919263150543, model saved at 5\n",
      "val_losses[-1] = 0.0003962321497965604, best_loss = 0.00040863838512450457, model saved at 6\n",
      "val_losses[-1] = 0.0003765938454307616, best_loss = 0.0003962321497965604, model saved at 7\n",
      "val_losses[-1] = 0.0003757199156098068, best_loss = 0.0003765938454307616, model saved at 10\n",
      "val_losses[-1] = 0.0003744620771612972, best_loss = 0.0003757199156098068, model saved at 12\n",
      "val_losses[-1] = 0.0003701128007378429, best_loss = 0.0003744620771612972, model saved at 13\n",
      "val_losses[-1] = 0.0003697611391544342, best_loss = 0.0003701128007378429, model saved at 26\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0004822468035854399, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0004410995461512357, best_loss = 0.0004822468035854399, model saved at 1\n",
      "val_losses[-1] = 0.00042262946953997016, best_loss = 0.0004410995461512357, model saved at 2\n",
      "val_losses[-1] = 0.00039830393507145345, best_loss = 0.00042262946953997016, model saved at 3\n",
      "val_losses[-1] = 0.00038944691186770797, best_loss = 0.00039830393507145345, model saved at 5\n",
      "val_losses[-1] = 0.0003761803964152932, best_loss = 0.00038944691186770797, model saved at 6\n",
      "val_losses[-1] = 0.000370152440154925, best_loss = 0.0003761803964152932, model saved at 8\n",
      "val_losses[-1] = 0.000367882865248248, best_loss = 0.000370152440154925, model saved at 29\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006034417892806232, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005904141580685973, best_loss = 0.0006034417892806232, model saved at 1\n",
      "val_losses[-1] = 0.00044447509571909904, best_loss = 0.0005904141580685973, model saved at 2\n",
      "val_losses[-1] = 0.00039259876939468086, best_loss = 0.00044447509571909904, model saved at 3\n",
      "val_losses[-1] = 0.00037604302633553743, best_loss = 0.00039259876939468086, model saved at 4\n",
      "val_losses[-1] = 0.0003667496202979237, best_loss = 0.00037604302633553743, model saved at 5\n",
      "val_losses[-1] = 0.00035832173307426274, best_loss = 0.0003667496202979237, model saved at 21\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.000627908855676651, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000591438205447048, best_loss = 0.000627908855676651, model saved at 1\n",
      "val_losses[-1] = 0.00015500612789765, best_loss = 0.000591438205447048, model saved at 2\n",
      "val_losses[-1] = 0.00013777872663922608, best_loss = 0.00015500612789765, model saved at 3\n",
      "val_losses[-1] = 0.00012954835256095976, best_loss = 0.00013777872663922608, model saved at 5\n",
      "val_losses[-1] = 0.00012026316835545003, best_loss = 0.00012954835256095976, model saved at 6\n",
      "iter 1...\n",
      "val_losses[-1] = 0.00021664205996785313, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00015460829308722168, best_loss = 0.00021664205996785313, model saved at 1\n",
      "val_losses[-1] = 0.0001401013578288257, best_loss = 0.00015460829308722168, model saved at 2\n",
      "val_losses[-1] = 0.00012662811786867678, best_loss = 0.0001401013578288257, model saved at 3\n",
      "val_losses[-1] = 0.00012133569543948397, best_loss = 0.00012662811786867678, model saved at 8\n",
      "val_losses[-1] = 0.00011767242540372536, best_loss = 0.00012133569543948397, model saved at 11\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0006005495088174939, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005032889894209802, best_loss = 0.0006005495088174939, model saved at 1\n",
      "val_losses[-1] = 0.00017886213026940823, best_loss = 0.0005032889894209802, model saved at 2\n",
      "val_losses[-1] = 0.00014890798775013536, best_loss = 0.00017886213026940823, model saved at 3\n",
      "val_losses[-1] = 0.00014418525097426027, best_loss = 0.00014890798775013536, model saved at 4\n",
      "val_losses[-1] = 0.00013528323324862868, best_loss = 0.00014418525097426027, model saved at 5\n",
      "val_losses[-1] = 0.00013180129462853074, best_loss = 0.00013528323324862868, model saved at 6\n",
      "val_losses[-1] = 0.0001303833705605939, best_loss = 0.00013180129462853074, model saved at 11\n",
      "val_losses[-1] = 0.0001298702700296417, best_loss = 0.0001303833705605939, model saved at 15\n",
      "val_losses[-1] = 0.0001248433254659176, best_loss = 0.0001298702700296417, model saved at 20\n",
      "iter 3...\n",
      "val_losses[-1] = 0.00016367141506634653, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00013372481043916196, best_loss = 0.00016367141506634653, model saved at 1\n",
      "val_losses[-1] = 0.0001305690675508231, best_loss = 0.00013372481043916196, model saved at 4\n",
      "val_losses[-1] = 0.00012583020725287497, best_loss = 0.0001305690675508231, model saved at 6\n",
      "val_losses[-1] = 0.0001233557122759521, best_loss = 0.00012583020725287497, model saved at 10\n",
      "val_losses[-1] = 0.0001226696331286803, best_loss = 0.0001233557122759521, model saved at 18\n",
      "iter 4...\n",
      "val_losses[-1] = 0.00016302989388350397, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00015032736700959504, best_loss = 0.00016302989388350397, model saved at 1\n",
      "val_losses[-1] = 0.0001276016846532002, best_loss = 0.00015032736700959504, model saved at 2\n",
      "val_losses[-1] = 0.00012691505253314972, best_loss = 0.0001276016846532002, model saved at 3\n",
      "val_losses[-1] = 0.00012556473666336387, best_loss = 0.00012691505253314972, model saved at 10\n",
      "val_losses[-1] = 0.0001239137927768752, best_loss = 0.00012556473666336387, model saved at 11\n",
      "val_losses[-1] = 0.00012324257113505155, best_loss = 0.0001239137927768752, model saved at 28\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006146089290268719, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006036864942871034, best_loss = 0.0006146089290268719, model saved at 1\n",
      "val_losses[-1] = 9.935751586453989e-05, best_loss = 0.0006036864942871034, model saved at 2\n",
      "val_losses[-1] = 8.813798194751143e-05, best_loss = 9.935751586453989e-05, model saved at 3\n",
      "val_losses[-1] = 8.1182639405597e-05, best_loss = 8.813798194751143e-05, model saved at 4\n",
      "val_losses[-1] = 7.954554166644812e-05, best_loss = 8.1182639405597e-05, model saved at 5\n",
      "val_losses[-1] = 7.358867151197046e-05, best_loss = 7.954554166644812e-05, model saved at 6\n",
      "val_losses[-1] = 7.183684647316113e-05, best_loss = 7.358867151197046e-05, model saved at 7\n",
      "val_losses[-1] = 7.178728992585093e-05, best_loss = 7.183684647316113e-05, model saved at 9\n",
      "iter 1...\n",
      "val_losses[-1] = 0.00011798078776337206, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 8.930110197979957e-05, best_loss = 0.00011798078776337206, model saved at 1\n",
      "val_losses[-1] = 8.620582957519218e-05, best_loss = 8.930110197979957e-05, model saved at 3\n",
      "val_losses[-1] = 8.472451736452058e-05, best_loss = 8.620582957519218e-05, model saved at 4\n",
      "val_losses[-1] = 7.933580491226166e-05, best_loss = 8.472451736452058e-05, model saved at 5\n",
      "val_losses[-1] = 7.581002864753827e-05, best_loss = 7.933580491226166e-05, model saved at 6\n",
      "val_losses[-1] = 7.559457299066707e-05, best_loss = 7.581002864753827e-05, model saved at 7\n",
      "val_losses[-1] = 7.489170820917934e-05, best_loss = 7.559457299066707e-05, model saved at 11\n",
      "val_losses[-1] = 7.466490933438763e-05, best_loss = 7.489170820917934e-05, model saved at 18\n",
      "val_losses[-1] = 7.439715409418568e-05, best_loss = 7.466490933438763e-05, model saved at 26\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0006250523147173226, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000167234888067469, best_loss = 0.0006250523147173226, model saved at 1\n",
      "val_losses[-1] = 0.00010164690320380032, best_loss = 0.000167234888067469, model saved at 2\n",
      "val_losses[-1] = 9.317764488514513e-05, best_loss = 0.00010164690320380032, model saved at 3\n",
      "val_losses[-1] = 9.118337038671598e-05, best_loss = 9.317764488514513e-05, model saved at 4\n",
      "val_losses[-1] = 7.90029953350313e-05, best_loss = 9.118337038671598e-05, model saved at 5\n",
      "val_losses[-1] = 7.372221443802118e-05, best_loss = 7.90029953350313e-05, model saved at 10\n",
      "iter 3...\n",
      "val_losses[-1] = 9.687991405371577e-05, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 8.106703899102286e-05, best_loss = 9.687991405371577e-05, model saved at 1\n",
      "val_losses[-1] = 7.925562385935336e-05, best_loss = 8.106703899102286e-05, model saved at 2\n",
      "val_losses[-1] = 7.803599874023348e-05, best_loss = 7.925562385935336e-05, model saved at 3\n",
      "val_losses[-1] = 7.671333878533915e-05, best_loss = 7.803599874023348e-05, model saved at 5\n",
      "val_losses[-1] = 7.6235257438384e-05, best_loss = 7.671333878533915e-05, model saved at 9\n",
      "val_losses[-1] = 7.437198655679822e-05, best_loss = 7.6235257438384e-05, model saved at 15\n",
      "val_losses[-1] = 7.432685379171744e-05, best_loss = 7.437198655679822e-05, model saved at 19\n",
      "val_losses[-1] = 7.400765753118321e-05, best_loss = 7.432685379171744e-05, model saved at 21\n",
      "val_losses[-1] = 7.078871567500755e-05, best_loss = 7.400765753118321e-05, model saved at 29\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0005456137587316334, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00040669075679033995, best_loss = 0.0005456137587316334, model saved at 1\n",
      "val_losses[-1] = 9.673382010078058e-05, best_loss = 0.00040669075679033995, model saved at 2\n",
      "val_losses[-1] = 7.958940113894641e-05, best_loss = 9.673382010078058e-05, model saved at 3\n",
      "val_losses[-1] = 7.65402292017825e-05, best_loss = 7.958940113894641e-05, model saved at 4\n",
      "val_losses[-1] = 7.595963688800111e-05, best_loss = 7.65402292017825e-05, model saved at 13\n",
      "val_losses[-1] = 7.35362118575722e-05, best_loss = 7.595963688800111e-05, model saved at 19\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "for seq_length in seq_lengths:\n",
    "    print(seq_length)\n",
    "    models = []\n",
    "    for i in range(num_models):\n",
    "        print(f\"iter {i}...\")\n",
    "        torch.manual_seed(i)\n",
    "        \n",
    "        dataset = torch.load(f\"data/mtl_fs_snr_{num_examples}_{seq_length}.pt\")\n",
    "        train_loader = dataset['train_loader']\n",
    "        val_loader = dataset['val_loader']\n",
    "\n",
    "        detector = preamble_detector()\n",
    "        detector.cuda()\n",
    "\n",
    "        loss_fn = nn.MSELoss()\n",
    "        optimizer = optim.Adam(detector.parameters(), lr=0.001, weight_decay=0.001)\n",
    "\n",
    "        detector, losses, val_losses = train(detector, optimizer, train_loader, val_loader, \n",
    "                                                                    loss_fn, num_epochs=num_epochs)\n",
    "\n",
    "        model_config = {\"weights\": detector.state_dict(),\n",
    "                        \"losses\": losses,\n",
    "                        \"val_losses\": val_losses}\n",
    "\n",
    "        models.append(model_config)\n",
    "\n",
    "    torch.save(models, f'models/continuous/fs_{num_examples}_{seq_length}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, seq_length in enumerate(seq_lengths):\n",
    "    for model in torch.load(f'models/continuous/fs_{num_examples}_{seq_length}.pt'):\n",
    "#         plt.plot(model['losses'], f'C{i}')\n",
    "        plt.plot(model['losses'], f'C{i}')\n",
    "        plt.plot(model['val_losses'], f'C{i}--')\n",
    "# plt.ylim([0.002, 0.003])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(detector, preamble_seq, snr_range, num_runs=200, payload=128, signal_length=400):\n",
    "    \n",
    "    accs = []\n",
    "    for snr in snr_range:\n",
    "        corrects = 0\n",
    "        for i in range(num_runs):\n",
    "            \n",
    "            tau = np.random.randint(0,signal_length-payload-len(preamble_seq))\n",
    "\n",
    "            my_frame = create_frame(preamble_seq, payload=payload, signal_length=signal_length, offset=tau)\n",
    "            my_frame = awgn(my_frame, snr)\n",
    "\n",
    "            new_frame = np.expand_dims(np.vstack((my_frame.real, my_frame.imag)),axis=(0,1))\n",
    "            new_frame = torch.tensor(new_frame).float()\n",
    "            nn_output = detector(new_frame)\n",
    "\n",
    "            if nn_output.argmax() == tau:\n",
    "                corrects += 1\n",
    "\n",
    "        acc = corrects/num_runs\n",
    "        accs.append(acc)\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "32\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "for seq_length in seq_lengths:\n",
    "    print(seq_length)\n",
    "    results = []\n",
    "    for model in torch.load(f'models/continuous/fs_{num_examples}_{seq_length}.pt'):\n",
    "        detector = preamble_detector()\n",
    "        detector.load_state_dict(model['weights'])\n",
    "\n",
    "        accs = test(detector, max_seq[:seq_length], snr_range=snr_range, num_runs=500)\n",
    "        \n",
    "        result = {\"accs\": accs,\n",
    "                   \"snr_range\": snr_range,\n",
    "                   \"model\": detector}\n",
    "        \n",
    "        results.append(result)\n",
    "    torch.save(results, f'results/continuous/fs_{num_examples}_{seq_length}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, seq_length in enumerate(seq_lengths):\n",
    "    for result in torch.load(f'results/continuous/fs_{num_examples}_{seq_length}.pt'):\n",
    "        plt.plot(result['snr_range'], result['accs'], f'C{i}')\n",
    "        plt.plot(snr_range, baselines[seq_length], f'C{i}--')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add MTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mtl(detector, optimizer, train_loader, val_loader, loss_fn_fs, loss_fn_snr, num_epochs=5, loss_ratios=(1,0.5)):\n",
    "\n",
    "    losses, snr_losses, fs_losses = [], [], []\n",
    "    val_losses = []\n",
    "\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss, running_fs_loss, running_snr_loss = 0, 0, 0\n",
    "\n",
    "        for x_train, y_train, z_train, w_train in train_loader:\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs, snr_outputs = detector(x_train)\n",
    "\n",
    "            loss_fs = loss_fn_fs(outputs, y_train)\n",
    "            loss_snr = loss_fn_snr(snr_outputs, z_train)\n",
    "\n",
    "            loss = loss_ratios[0]*loss_fs + loss_ratios[1]*loss_snr\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss = running_loss + loss.item()\n",
    "            running_fs_loss = running_fs_loss + loss_fs.item()\n",
    "            running_snr_loss = running_snr_loss + loss_snr.item()\n",
    "\n",
    "        losses.append(running_loss/len(train_loader))\n",
    "        snr_losses.append(running_snr_loss/len(train_loader))\n",
    "        fs_losses.append(running_fs_loss/len(train_loader))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # evaluate validation loss\n",
    "            for x_val, y_val, z_val, w_val in val_loader:\n",
    "                val_outputs, _ = detector(x_val)\n",
    "                val_loss = loss_fn(val_outputs, y_val)\n",
    "                running_val_loss = val_loss.item()\n",
    "        \n",
    "        val_losses.append(running_val_loss/len(val_loader))\n",
    "\n",
    "        if val_losses[-1] < best_loss:\n",
    "            print(f'val_losses[-1] = {val_losses[-1]}, best_loss = {best_loss}, model saved at {epoch}')\n",
    "            saved_model = detector.state_dict()\n",
    "            best_loss = val_losses[-1]\n",
    "\n",
    "    detector.load_state_dict(saved_model)\n",
    "    \n",
    "    return detector, losses, val_losses, snr_losses, fs_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.9),\n",
       " (1, 0.8),\n",
       " (1, 0.7),\n",
       " (1, 0.6),\n",
       " (1, 0.5),\n",
       " (1, 0.4),\n",
       " (1, 0.3),\n",
       " (1, 0.2),\n",
       " (1, 0.1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_loss_ratios = []\n",
    "for i in range(1,10):\n",
    "    models = []\n",
    "\n",
    "    fs_weight = 1\n",
    "    snr_weight = round(1 - i*0.1, 1)\n",
    "    \n",
    "    loss_ratios = (fs_weight, snr_weight)\n",
    "    \n",
    "    all_loss_ratios.append(loss_ratios)\n",
    "all_loss_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.9)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006399503909051418, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006293138721957803, best_loss = 0.0006399503909051418, model saved at 1\n",
      "val_losses[-1] = 0.0006278412765823305, best_loss = 0.0006293138721957803, model saved at 2\n",
      "val_losses[-1] = 0.0006261595990508795, best_loss = 0.0006278412765823305, model saved at 3\n",
      "val_losses[-1] = 0.0006242023082450032, best_loss = 0.0006261595990508795, model saved at 4\n",
      "val_losses[-1] = 0.0006239560316316783, best_loss = 0.0006242023082450032, model saved at 9\n",
      "val_losses[-1] = 0.0006230090511962771, best_loss = 0.0006239560316316783, model saved at 10\n",
      "val_losses[-1] = 0.0006197315524332225, best_loss = 0.0006230090511962771, model saved at 11\n",
      "val_losses[-1] = 0.0006155123701319098, best_loss = 0.0006197315524332225, model saved at 12\n",
      "val_losses[-1] = 0.0006141015910543501, best_loss = 0.0006155123701319098, model saved at 13\n",
      "val_losses[-1] = 0.0006060206796973944, best_loss = 0.0006141015910543501, model saved at 14\n",
      "val_losses[-1] = 0.0006030116346664727, best_loss = 0.0006060206796973944, model saved at 15\n",
      "val_losses[-1] = 0.00060205755289644, best_loss = 0.0006030116346664727, model saved at 16\n",
      "val_losses[-1] = 0.0005989389610476792, best_loss = 0.00060205755289644, model saved at 17\n",
      "val_losses[-1] = 0.0005924601573497057, best_loss = 0.0005989389610476792, model saved at 18\n",
      "val_losses[-1] = 0.0005280592595227063, best_loss = 0.0005924601573497057, model saved at 19\n",
      "val_losses[-1] = 0.00048517435789108276, best_loss = 0.0005280592595227063, model saved at 20\n",
      "val_losses[-1] = 0.00044114317279309034, best_loss = 0.00048517435789108276, model saved at 21\n",
      "val_losses[-1] = 0.00041433170554228127, best_loss = 0.00044114317279309034, model saved at 22\n",
      "val_losses[-1] = 0.0004067120607942343, best_loss = 0.00041433170554228127, model saved at 23\n",
      "val_losses[-1] = 0.0003930371021851897, best_loss = 0.0004067120607942343, model saved at 24\n",
      "val_losses[-1] = 0.00038177092210389674, best_loss = 0.0003930371021851897, model saved at 25\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006506507634185255, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006086429348215461, best_loss = 0.0006506507634185255, model saved at 1\n",
      "val_losses[-1] = 0.0004811039543710649, best_loss = 0.0006086429348215461, model saved at 2\n",
      "val_losses[-1] = 0.00042728407424874604, best_loss = 0.0004811039543710649, model saved at 3\n",
      "val_losses[-1] = 0.0004267623880878091, best_loss = 0.00042728407424874604, model saved at 5\n",
      "val_losses[-1] = 0.0004182571719866246, best_loss = 0.0004267623880878091, model saved at 6\n",
      "val_losses[-1] = 0.0003931577375624329, best_loss = 0.0004182571719866246, model saved at 7\n",
      "val_losses[-1] = 0.00038387937820516527, best_loss = 0.0003931577375624329, model saved at 9\n",
      "val_losses[-1] = 0.00037252894253470004, best_loss = 0.00038387937820516527, model saved at 13\n",
      "val_losses[-1] = 0.00037169194547459483, best_loss = 0.00037252894253470004, model saved at 15\n",
      "val_losses[-1] = 0.00036996169365011156, best_loss = 0.00037169194547459483, model saved at 17\n",
      "val_losses[-1] = 0.0003618257469497621, best_loss = 0.00036996169365011156, model saved at 19\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007795406854711473, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006365635199472308, best_loss = 0.0007795406854711473, model saved at 2\n",
      "val_losses[-1] = 0.0006159316399134696, best_loss = 0.0006365635199472308, model saved at 3\n",
      "val_losses[-1] = 0.0006111107068136334, best_loss = 0.0006159316399134696, model saved at 4\n",
      "val_losses[-1] = 0.0006073173717595637, best_loss = 0.0006111107068136334, model saved at 5\n",
      "val_losses[-1] = 0.0006045695045031607, best_loss = 0.0006073173717595637, model saved at 6\n",
      "val_losses[-1] = 0.0006012261146679521, best_loss = 0.0006045695045031607, model saved at 7\n",
      "val_losses[-1] = 0.0005993301747366786, best_loss = 0.0006012261146679521, model saved at 8\n",
      "val_losses[-1] = 0.0005968111800029874, best_loss = 0.0005993301747366786, model saved at 9\n",
      "val_losses[-1] = 0.0005794964963570237, best_loss = 0.0005968111800029874, model saved at 10\n",
      "val_losses[-1] = 0.00048590853111818433, best_loss = 0.0005794964963570237, model saved at 11\n",
      "val_losses[-1] = 0.00042741172364912927, best_loss = 0.00048590853111818433, model saved at 12\n",
      "val_losses[-1] = 0.00041525004780851305, best_loss = 0.00042741172364912927, model saved at 13\n",
      "val_losses[-1] = 0.00039098827983252704, best_loss = 0.00041525004780851305, model saved at 14\n",
      "val_losses[-1] = 0.0003870964574161917, best_loss = 0.00039098827983252704, model saved at 15\n",
      "val_losses[-1] = 0.00038390239933505654, best_loss = 0.0003870964574161917, model saved at 17\n",
      "val_losses[-1] = 0.0003797265817411244, best_loss = 0.00038390239933505654, model saved at 20\n",
      "val_losses[-1] = 0.0003764004504773766, best_loss = 0.0003797265817411244, model saved at 22\n",
      "val_losses[-1] = 0.0003758226230274886, best_loss = 0.0003764004504773766, model saved at 26\n",
      "val_losses[-1] = 0.00036932717193849385, best_loss = 0.0003758226230274886, model saved at 29\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006719910888932645, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006200004718266428, best_loss = 0.0006719910888932645, model saved at 1\n",
      "val_losses[-1] = 0.0006111538968980312, best_loss = 0.0006200004718266428, model saved at 3\n",
      "val_losses[-1] = 0.0006105945794843137, best_loss = 0.0006111538968980312, model saved at 4\n",
      "val_losses[-1] = 0.0006081152241677046, best_loss = 0.0006105945794843137, model saved at 5\n",
      "val_losses[-1] = 0.0004706755862571299, best_loss = 0.0006081152241677046, model saved at 6\n",
      "val_losses[-1] = 0.00042139660217799246, best_loss = 0.0004706755862571299, model saved at 7\n",
      "val_losses[-1] = 0.0004125643172301352, best_loss = 0.00042139660217799246, model saved at 8\n",
      "val_losses[-1] = 0.00040187558624893427, best_loss = 0.0004125643172301352, model saved at 9\n",
      "val_losses[-1] = 0.00038978244992904365, best_loss = 0.00040187558624893427, model saved at 10\n",
      "val_losses[-1] = 0.00038259357097558677, best_loss = 0.00038978244992904365, model saved at 11\n",
      "val_losses[-1] = 0.000376106530893594, best_loss = 0.00038259357097558677, model saved at 14\n",
      "val_losses[-1] = 0.0003735307545866817, best_loss = 0.000376106530893594, model saved at 15\n",
      "val_losses[-1] = 0.00037101886118762195, best_loss = 0.0003735307545866817, model saved at 21\n",
      "val_losses[-1] = 0.0003694127663038671, best_loss = 0.00037101886118762195, model saved at 26\n",
      "val_losses[-1] = 0.000369119894457981, best_loss = 0.0003694127663038671, model saved at 29\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006294004269875586, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006219439674168825, best_loss = 0.0006294004269875586, model saved at 1\n",
      "val_losses[-1] = 0.0006210366263985634, best_loss = 0.0006219439674168825, model saved at 2\n",
      "val_losses[-1] = 0.0006193533772602677, best_loss = 0.0006210366263985634, model saved at 3\n",
      "val_losses[-1] = 0.0006192214204929769, best_loss = 0.0006193533772602677, model saved at 5\n",
      "val_losses[-1] = 0.0006160548073239625, best_loss = 0.0006192214204929769, model saved at 6\n",
      "val_losses[-1] = 0.0006134145078249276, best_loss = 0.0006160548073239625, model saved at 7\n",
      "val_losses[-1] = 0.0006113169947639108, best_loss = 0.0006134145078249276, model saved at 8\n",
      "val_losses[-1] = 0.0006095011485740542, best_loss = 0.0006113169947639108, model saved at 9\n",
      "val_losses[-1] = 0.0006067232461646199, best_loss = 0.0006095011485740542, model saved at 10\n",
      "val_losses[-1] = 0.0006053780671209097, best_loss = 0.0006067232461646199, model saved at 12\n",
      "val_losses[-1] = 0.0006049292860552669, best_loss = 0.0006053780671209097, model saved at 13\n",
      "val_losses[-1] = 0.0006042820168659091, best_loss = 0.0006049292860552669, model saved at 14\n",
      "val_losses[-1] = 0.00060425722040236, best_loss = 0.0006042820168659091, model saved at 15\n",
      "val_losses[-1] = 0.0006037807906977832, best_loss = 0.00060425722040236, model saved at 17\n",
      "val_losses[-1] = 0.0006032714736647904, best_loss = 0.0006037807906977832, model saved at 18\n",
      "val_losses[-1] = 0.0006023980095051229, best_loss = 0.0006032714736647904, model saved at 20\n",
      "val_losses[-1] = 0.0006017973646521568, best_loss = 0.0006023980095051229, model saved at 25\n",
      "val_losses[-1] = 0.0006014293758198619, best_loss = 0.0006017973646521568, model saved at 26\n",
      "val_losses[-1] = 0.0006005874020047486, best_loss = 0.0006014293758198619, model saved at 29\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006467319908551872, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00063822150696069, best_loss = 0.0006467319908551872, model saved at 1\n",
      "val_losses[-1] = 0.0006321507389657199, best_loss = 0.00063822150696069, model saved at 3\n",
      "val_losses[-1] = 0.0006263831746764481, best_loss = 0.0006321507389657199, model saved at 4\n",
      "val_losses[-1] = 0.0006225625984370708, best_loss = 0.0006263831746764481, model saved at 7\n",
      "val_losses[-1] = 0.0005996722029522061, best_loss = 0.0006225625984370708, model saved at 8\n",
      "val_losses[-1] = 0.0005909354658797383, best_loss = 0.0005996722029522061, model saved at 9\n",
      "val_losses[-1] = 0.0005158054991625249, best_loss = 0.0005909354658797383, model saved at 10\n",
      "val_losses[-1] = 0.0001746543712215498, best_loss = 0.0005158054991625249, model saved at 11\n",
      "val_losses[-1] = 0.00015336115029640496, best_loss = 0.0001746543712215498, model saved at 12\n",
      "val_losses[-1] = 0.0001456104509998113, best_loss = 0.00015336115029640496, model saved at 13\n",
      "val_losses[-1] = 0.00014313576684799045, best_loss = 0.0001456104509998113, model saved at 14\n",
      "val_losses[-1] = 0.00013858801685273647, best_loss = 0.00014313576684799045, model saved at 17\n",
      "val_losses[-1] = 0.00013162662799004465, best_loss = 0.00013858801685273647, model saved at 18\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006254097679629922, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000608704169280827, best_loss = 0.0006254097679629922, model saved at 1\n",
      "val_losses[-1] = 0.0005987350014038384, best_loss = 0.000608704169280827, model saved at 4\n",
      "val_losses[-1] = 0.000586560636293143, best_loss = 0.0005987350014038384, model saved at 5\n",
      "val_losses[-1] = 0.0005806025583297014, best_loss = 0.000586560636293143, model saved at 6\n",
      "val_losses[-1] = 0.0005773833254352212, best_loss = 0.0005806025583297014, model saved at 7\n",
      "val_losses[-1] = 0.0005747965769842267, best_loss = 0.0005773833254352212, model saved at 8\n",
      "val_losses[-1] = 0.0005723761860281229, best_loss = 0.0005747965769842267, model saved at 9\n",
      "val_losses[-1] = 0.0005698788445442915, best_loss = 0.0005723761860281229, model saved at 10\n",
      "val_losses[-1] = 0.0005681872717104852, best_loss = 0.0005698788445442915, model saved at 11\n",
      "val_losses[-1] = 0.0005648082005791366, best_loss = 0.0005681872717104852, model saved at 13\n",
      "val_losses[-1] = 0.0005622546304948628, best_loss = 0.0005648082005791366, model saved at 14\n",
      "val_losses[-1] = 0.0005616985727101564, best_loss = 0.0005622546304948628, model saved at 15\n",
      "val_losses[-1] = 0.0005590929067693651, best_loss = 0.0005616985727101564, model saved at 16\n",
      "val_losses[-1] = 0.0005568508058786392, best_loss = 0.0005590929067693651, model saved at 17\n",
      "val_losses[-1] = 0.0005539000267162919, best_loss = 0.0005568508058786392, model saved at 18\n",
      "val_losses[-1] = 0.0005512633942998946, best_loss = 0.0005539000267162919, model saved at 19\n",
      "val_losses[-1] = 0.0005503068678081036, best_loss = 0.0005512633942998946, model saved at 20\n",
      "val_losses[-1] = 0.0005460673710331321, best_loss = 0.0005503068678081036, model saved at 21\n",
      "val_losses[-1] = 0.0005424258997663856, best_loss = 0.0005460673710331321, model saved at 22\n",
      "val_losses[-1] = 0.00018522431491874158, best_loss = 0.0005424258997663856, model saved at 24\n",
      "val_losses[-1] = 0.00016005571524146944, best_loss = 0.00018522431491874158, model saved at 25\n",
      "val_losses[-1] = 0.00015899953723419458, best_loss = 0.00016005571524146944, model saved at 26\n",
      "val_losses[-1] = 0.00014926044968888164, best_loss = 0.00015899953723419458, model saved at 27\n",
      "val_losses[-1] = 0.00014302294584922493, best_loss = 0.00014926044968888164, model saved at 28\n",
      "val_losses[-1] = 0.00014204288891050965, best_loss = 0.00014302294584922493, model saved at 29\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007916832691989839, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0007842548075132072, best_loss = 0.0007916832691989839, model saved at 2\n",
      "val_losses[-1] = 0.0006000039866194129, best_loss = 0.0007842548075132072, model saved at 3\n",
      "val_losses[-1] = 0.0005912801716476679, best_loss = 0.0006000039866194129, model saved at 4\n",
      "val_losses[-1] = 0.0005845708074048162, best_loss = 0.0005912801716476679, model saved at 5\n",
      "val_losses[-1] = 0.0005798059282824397, best_loss = 0.0005845708074048162, model saved at 6\n",
      "val_losses[-1] = 0.0005744930822402239, best_loss = 0.0005798059282824397, model saved at 7\n",
      "val_losses[-1] = 0.0005700718029402196, best_loss = 0.0005744930822402239, model saved at 8\n",
      "val_losses[-1] = 0.0005566884647123516, best_loss = 0.0005700718029402196, model saved at 9\n",
      "val_losses[-1] = 0.000450226420070976, best_loss = 0.0005566884647123516, model saved at 10\n",
      "val_losses[-1] = 0.00022069967235438526, best_loss = 0.000450226420070976, model saved at 11\n",
      "val_losses[-1] = 0.00017212351667694747, best_loss = 0.00022069967235438526, model saved at 12\n",
      "val_losses[-1] = 0.0001631947816349566, best_loss = 0.00017212351667694747, model saved at 13\n",
      "val_losses[-1] = 0.00014954805374145508, best_loss = 0.0001631947816349566, model saved at 14\n",
      "val_losses[-1] = 0.00014508824096992612, best_loss = 0.00014954805374145508, model saved at 15\n",
      "val_losses[-1] = 0.00014010250743012875, best_loss = 0.00014508824096992612, model saved at 19\n",
      "val_losses[-1] = 0.00013639431563206017, best_loss = 0.00014010250743012875, model saved at 29\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0004016523016616702, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0001811089168768376, best_loss = 0.0004016523016616702, model saved at 1\n",
      "val_losses[-1] = 0.00016916287131607533, best_loss = 0.0001811089168768376, model saved at 2\n",
      "val_losses[-1] = 0.00015350113972090185, best_loss = 0.00016916287131607533, model saved at 4\n",
      "val_losses[-1] = 0.00014450856542680413, best_loss = 0.00015350113972090185, model saved at 5\n",
      "val_losses[-1] = 0.00014220330922398716, best_loss = 0.00014450856542680413, model saved at 8\n",
      "val_losses[-1] = 0.00013684593432117254, best_loss = 0.00014220330922398716, model saved at 10\n",
      "val_losses[-1] = 0.0001353341358480975, best_loss = 0.00013684593432117254, model saved at 15\n",
      "val_losses[-1] = 0.00013384068734012544, best_loss = 0.0001353341358480975, model saved at 17\n",
      "val_losses[-1] = 0.00013241964916232973, best_loss = 0.00013384068734012544, model saved at 21\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006283109541982412, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000614955322816968, best_loss = 0.0006283109541982412, model saved at 1\n",
      "val_losses[-1] = 0.0006113144918344915, best_loss = 0.000614955322816968, model saved at 2\n",
      "val_losses[-1] = 0.0006104204803705215, best_loss = 0.0006113144918344915, model saved at 4\n",
      "val_losses[-1] = 0.0005922394338995218, best_loss = 0.0006104204803705215, model saved at 5\n",
      "val_losses[-1] = 0.0005847734282724559, best_loss = 0.0005922394338995218, model saved at 6\n",
      "val_losses[-1] = 0.0005748652038164437, best_loss = 0.0005847734282724559, model saved at 7\n",
      "val_losses[-1] = 0.0005706591182388365, best_loss = 0.0005748652038164437, model saved at 8\n",
      "val_losses[-1] = 0.0005691051483154297, best_loss = 0.0005706591182388365, model saved at 10\n",
      "val_losses[-1] = 0.0005664086784236133, best_loss = 0.0005691051483154297, model saved at 11\n",
      "val_losses[-1] = 0.0005640065064653754, best_loss = 0.0005664086784236133, model saved at 12\n",
      "val_losses[-1] = 0.00023034235346131027, best_loss = 0.0005640065064653754, model saved at 14\n",
      "val_losses[-1] = 0.00016671247431077063, best_loss = 0.00023034235346131027, model saved at 15\n",
      "val_losses[-1] = 0.00015563011402264237, best_loss = 0.00016671247431077063, model saved at 16\n",
      "val_losses[-1] = 0.00015083829930517823, best_loss = 0.00015563011402264237, model saved at 21\n",
      "val_losses[-1] = 0.0001481920771766454, best_loss = 0.00015083829930517823, model saved at 22\n",
      "val_losses[-1] = 0.00014729534450452775, best_loss = 0.0001481920771766454, model saved at 23\n",
      "val_losses[-1] = 0.0001465065433876589, best_loss = 0.00014729534450452775, model saved at 24\n",
      "val_losses[-1] = 0.00014235208800528198, best_loss = 0.0001465065433876589, model saved at 28\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006320071988739073, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006296947249211371, best_loss = 0.0006320071988739073, model saved at 1\n",
      "val_losses[-1] = 0.0006249882862903178, best_loss = 0.0006296947249211371, model saved at 3\n",
      "val_losses[-1] = 0.0006243044626899064, best_loss = 0.0006249882862903178, model saved at 4\n",
      "val_losses[-1] = 0.0006237197667360306, best_loss = 0.0006243044626899064, model saved at 5\n",
      "val_losses[-1] = 0.0006235367036424577, best_loss = 0.0006237197667360306, model saved at 6\n",
      "val_losses[-1] = 0.0006234772154130042, best_loss = 0.0006235367036424577, model saved at 7\n",
      "val_losses[-1] = 0.000621006649453193, best_loss = 0.0006234772154130042, model saved at 8\n",
      "val_losses[-1] = 0.0006174560985527933, best_loss = 0.000621006649453193, model saved at 9\n",
      "val_losses[-1] = 0.0006159456097520888, best_loss = 0.0006174560985527933, model saved at 10\n",
      "val_losses[-1] = 0.0006075013079680502, best_loss = 0.0006159456097520888, model saved at 11\n",
      "val_losses[-1] = 0.0005363061791285872, best_loss = 0.0006075013079680502, model saved at 12\n",
      "val_losses[-1] = 0.00011106502643087879, best_loss = 0.0005363061791285872, model saved at 13\n",
      "val_losses[-1] = 9.045340266311541e-05, best_loss = 0.00011106502643087879, model saved at 14\n",
      "val_losses[-1] = 9.013733506435528e-05, best_loss = 9.045340266311541e-05, model saved at 15\n",
      "val_losses[-1] = 8.727957174414769e-05, best_loss = 9.013733506435528e-05, model saved at 16\n",
      "val_losses[-1] = 8.45667818794027e-05, best_loss = 8.727957174414769e-05, model saved at 19\n",
      "val_losses[-1] = 8.340876956935972e-05, best_loss = 8.45667818794027e-05, model saved at 20\n",
      "val_losses[-1] = 8.192636596504599e-05, best_loss = 8.340876956935972e-05, model saved at 23\n",
      "iter 1...\n",
      "val_losses[-1] = 0.000624924199655652, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005800368380732834, best_loss = 0.000624924199655652, model saved at 1\n",
      "val_losses[-1] = 0.0005699307657778263, best_loss = 0.0005800368380732834, model saved at 2\n",
      "val_losses[-1] = 0.00016229532775469124, best_loss = 0.0005699307657778263, model saved at 3\n",
      "val_losses[-1] = 8.377586345886812e-05, best_loss = 0.00016229532775469124, model saved at 4\n",
      "val_losses[-1] = 8.357097249245271e-05, best_loss = 8.377586345886812e-05, model saved at 6\n",
      "val_losses[-1] = 8.068393799476326e-05, best_loss = 8.357097249245271e-05, model saved at 8\n",
      "val_losses[-1] = 8.005506242625415e-05, best_loss = 8.068393799476326e-05, model saved at 15\n",
      "val_losses[-1] = 7.85714655648917e-05, best_loss = 8.005506242625415e-05, model saved at 25\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0012033242965117097, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0009042649762704968, best_loss = 0.0012033242965117097, model saved at 1\n",
      "val_losses[-1] = 0.0005392457242123783, best_loss = 0.0009042649762704968, model saved at 2\n",
      "val_losses[-1] = 0.0005164565518498421, best_loss = 0.0005392457242123783, model saved at 3\n",
      "val_losses[-1] = 0.0004943827516399324, best_loss = 0.0005164565518498421, model saved at 4\n",
      "val_losses[-1] = 0.0004804449563380331, best_loss = 0.0004943827516399324, model saved at 5\n",
      "val_losses[-1] = 0.0004787482903338969, best_loss = 0.0004804449563380331, model saved at 6\n",
      "val_losses[-1] = 0.00012581954069901258, best_loss = 0.0004787482903338969, model saved at 7\n",
      "val_losses[-1] = 9.719603258417919e-05, best_loss = 0.00012581954069901258, model saved at 8\n",
      "val_losses[-1] = 9.356824739370495e-05, best_loss = 9.719603258417919e-05, model saved at 9\n",
      "val_losses[-1] = 8.96151686902158e-05, best_loss = 9.356824739370495e-05, model saved at 10\n",
      "val_losses[-1] = 7.919814379420131e-05, best_loss = 8.96151686902158e-05, model saved at 11\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006806340534240007, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005393209285102785, best_loss = 0.0006806340534240007, model saved at 1\n",
      "val_losses[-1] = 0.00013334226969163865, best_loss = 0.0005393209285102785, model saved at 2\n",
      "val_losses[-1] = 8.253374107880518e-05, best_loss = 0.00013334226969163865, model saved at 3\n",
      "val_losses[-1] = 8.053613419178873e-05, best_loss = 8.253374107880518e-05, model saved at 8\n",
      "val_losses[-1] = 8.02555659902282e-05, best_loss = 8.053613419178873e-05, model saved at 12\n",
      "val_losses[-1] = 7.9951154475566e-05, best_loss = 8.02555659902282e-05, model saved at 15\n",
      "val_losses[-1] = 7.94572988525033e-05, best_loss = 7.9951154475566e-05, model saved at 16\n",
      "val_losses[-1] = 7.787224603816867e-05, best_loss = 7.94572988525033e-05, model saved at 18\n",
      "val_losses[-1] = 7.603789708809927e-05, best_loss = 7.787224603816867e-05, model saved at 20\n",
      "iter 4...\n",
      "val_losses[-1] = 0.000622770341578871, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006085628410801291, best_loss = 0.000622770341578871, model saved at 1\n",
      "val_losses[-1] = 0.0005980546702630818, best_loss = 0.0006085628410801291, model saved at 2\n",
      "val_losses[-1] = 0.0005741894710808992, best_loss = 0.0005980546702630818, model saved at 3\n",
      "val_losses[-1] = 0.0005556339165195823, best_loss = 0.0005741894710808992, model saved at 4\n",
      "val_losses[-1] = 0.0005411499878391623, best_loss = 0.0005556339165195823, model saved at 5\n",
      "val_losses[-1] = 0.0005312770954333246, best_loss = 0.0005411499878391623, model saved at 6\n",
      "val_losses[-1] = 0.0005205527413636446, best_loss = 0.0005312770954333246, model saved at 7\n",
      "val_losses[-1] = 0.0005096945096738636, best_loss = 0.0005205527413636446, model saved at 8\n",
      "val_losses[-1] = 0.0004985154955647886, best_loss = 0.0005096945096738636, model saved at 9\n",
      "val_losses[-1] = 0.000482860574265942, best_loss = 0.0004985154955647886, model saved at 10\n",
      "val_losses[-1] = 0.0004689253692049533, best_loss = 0.000482860574265942, model saved at 11\n",
      "val_losses[-1] = 0.00045461824629455805, best_loss = 0.0004689253692049533, model saved at 12\n",
      "val_losses[-1] = 0.00044635863741859794, best_loss = 0.00045461824629455805, model saved at 13\n",
      "val_losses[-1] = 0.00013560896331910044, best_loss = 0.00044635863741859794, model saved at 15\n",
      "val_losses[-1] = 9.792255150387064e-05, best_loss = 0.00013560896331910044, model saved at 16\n",
      "val_losses[-1] = 9.739752567838877e-05, best_loss = 9.792255150387064e-05, model saved at 17\n",
      "val_losses[-1] = 8.063977293204516e-05, best_loss = 9.739752567838877e-05, model saved at 18\n",
      "val_losses[-1] = 7.56301378714852e-05, best_loss = 8.063977293204516e-05, model saved at 21\n",
      "(1, 0.8)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.000625823566224426, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006234380416572094, best_loss = 0.000625823566224426, model saved at 1\n",
      "val_losses[-1] = 0.0006228273850865662, best_loss = 0.0006234380416572094, model saved at 11\n",
      "val_losses[-1] = 0.0006173024303279817, best_loss = 0.0006228273850865662, model saved at 12\n",
      "val_losses[-1] = 0.0005984968738630414, best_loss = 0.0006173024303279817, model saved at 13\n",
      "val_losses[-1] = 0.0005487844464369118, best_loss = 0.0005984968738630414, model saved at 14\n",
      "val_losses[-1] = 0.00047766006900928915, best_loss = 0.0005487844464369118, model saved at 15\n",
      "val_losses[-1] = 0.0004312717937864363, best_loss = 0.00047766006900928915, model saved at 16\n",
      "val_losses[-1] = 0.0004188516759313643, best_loss = 0.0004312717937864363, model saved at 17\n",
      "val_losses[-1] = 0.0004089718859177083, best_loss = 0.0004188516759313643, model saved at 18\n",
      "val_losses[-1] = 0.000403091631596908, best_loss = 0.0004089718859177083, model saved at 19\n",
      "val_losses[-1] = 0.00039582286262884736, best_loss = 0.000403091631596908, model saved at 22\n",
      "val_losses[-1] = 0.0003950998361688107, best_loss = 0.00039582286262884736, model saved at 23\n",
      "val_losses[-1] = 0.000390367116779089, best_loss = 0.0003950998361688107, model saved at 24\n",
      "val_losses[-1] = 0.00038694083923473954, best_loss = 0.000390367116779089, model saved at 25\n",
      "iter 1...\n",
      "val_losses[-1] = 0.000651573296636343, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005964047741144896, best_loss = 0.000651573296636343, model saved at 1\n",
      "val_losses[-1] = 0.0004909468116238713, best_loss = 0.0005964047741144896, model saved at 2\n",
      "val_losses[-1] = 0.0004274422535672784, best_loss = 0.0004909468116238713, model saved at 3\n",
      "val_losses[-1] = 0.000418965209973976, best_loss = 0.0004274422535672784, model saved at 5\n",
      "val_losses[-1] = 0.00040910503594204783, best_loss = 0.000418965209973976, model saved at 6\n",
      "val_losses[-1] = 0.00038608827162534, best_loss = 0.00040910503594204783, model saved at 7\n",
      "val_losses[-1] = 0.0003763089480344206, best_loss = 0.00038608827162534, model saved at 9\n",
      "val_losses[-1] = 0.0003707389405462891, best_loss = 0.0003763089480344206, model saved at 13\n",
      "val_losses[-1] = 0.0003678624634630978, best_loss = 0.0003707389405462891, model saved at 17\n",
      "val_losses[-1] = 0.00036355946213006973, best_loss = 0.0003678624634630978, model saved at 19\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0008735391311347485, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0007100960938259959, best_loss = 0.0008735391311347485, model saved at 1\n",
      "val_losses[-1] = 0.0006483466713689268, best_loss = 0.0007100960938259959, model saved at 2\n",
      "val_losses[-1] = 0.0006393764051608741, best_loss = 0.0006483466713689268, model saved at 3\n",
      "val_losses[-1] = 0.0006208776030689478, best_loss = 0.0006393764051608741, model saved at 4\n",
      "val_losses[-1] = 0.0006142276106402278, best_loss = 0.0006208776030689478, model saved at 5\n",
      "val_losses[-1] = 0.0006116171716712415, best_loss = 0.0006142276106402278, model saved at 6\n",
      "val_losses[-1] = 0.0006042754976078868, best_loss = 0.0006116171716712415, model saved at 7\n",
      "val_losses[-1] = 0.0005587568739429116, best_loss = 0.0006042754976078868, model saved at 8\n",
      "val_losses[-1] = 0.0004810393147636205, best_loss = 0.0005587568739429116, model saved at 9\n",
      "val_losses[-1] = 0.000441734358901158, best_loss = 0.0004810393147636205, model saved at 10\n",
      "val_losses[-1] = 0.00042148400098085403, best_loss = 0.000441734358901158, model saved at 11\n",
      "val_losses[-1] = 0.0004089018329977989, best_loss = 0.00042148400098085403, model saved at 12\n",
      "val_losses[-1] = 0.0004053670563735068, best_loss = 0.0004089018329977989, model saved at 13\n",
      "val_losses[-1] = 0.0003898865543305874, best_loss = 0.0004053670563735068, model saved at 14\n",
      "val_losses[-1] = 0.00038867510738782585, best_loss = 0.0003898865543305874, model saved at 15\n",
      "val_losses[-1] = 0.00038661464350298047, best_loss = 0.00038867510738782585, model saved at 17\n",
      "val_losses[-1] = 0.000379153061658144, best_loss = 0.00038661464350298047, model saved at 20\n",
      "val_losses[-1] = 0.0003736498183570802, best_loss = 0.000379153061658144, model saved at 22\n",
      "val_losses[-1] = 0.0003685620322357863, best_loss = 0.0003736498183570802, model saved at 26\n",
      "val_losses[-1] = 0.000365240266546607, best_loss = 0.0003685620322357863, model saved at 28\n",
      "val_losses[-1] = 0.0003649172140285373, best_loss = 0.000365240266546607, model saved at 29\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006821201532147825, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006182654178701341, best_loss = 0.0006821201532147825, model saved at 1\n",
      "val_losses[-1] = 0.00044729007640853524, best_loss = 0.0006182654178701341, model saved at 2\n",
      "val_losses[-1] = 0.00041984638664871454, best_loss = 0.00044729007640853524, model saved at 3\n",
      "val_losses[-1] = 0.0004037941398564726, best_loss = 0.00041984638664871454, model saved at 4\n",
      "val_losses[-1] = 0.0003940894384868443, best_loss = 0.0004037941398564726, model saved at 7\n",
      "val_losses[-1] = 0.00038798421155661345, best_loss = 0.0003940894384868443, model saved at 9\n",
      "val_losses[-1] = 0.0003836254763882607, best_loss = 0.00038798421155661345, model saved at 10\n",
      "val_losses[-1] = 0.00038312721881084144, best_loss = 0.0003836254763882607, model saved at 14\n",
      "val_losses[-1] = 0.0003783041029237211, best_loss = 0.00038312721881084144, model saved at 15\n",
      "val_losses[-1] = 0.0003768220485653728, best_loss = 0.0003783041029237211, model saved at 21\n",
      "val_losses[-1] = 0.00037664061528630555, best_loss = 0.0003768220485653728, model saved at 23\n",
      "val_losses[-1] = 0.00037365127354860306, best_loss = 0.00037664061528630555, model saved at 29\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006283734692260623, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006210330175235868, best_loss = 0.0006283734692260623, model saved at 1\n",
      "val_losses[-1] = 0.0006205682293511927, best_loss = 0.0006210330175235868, model saved at 3\n",
      "val_losses[-1] = 0.0006190660642459989, best_loss = 0.0006205682293511927, model saved at 4\n",
      "val_losses[-1] = 0.0006180241471156478, best_loss = 0.0006190660642459989, model saved at 5\n",
      "val_losses[-1] = 0.0006140814512036741, best_loss = 0.0006180241471156478, model saved at 6\n",
      "val_losses[-1] = 0.0006092005060054362, best_loss = 0.0006140814512036741, model saved at 7\n",
      "val_losses[-1] = 0.000606671383138746, best_loss = 0.0006092005060054362, model saved at 8\n",
      "val_losses[-1] = 0.0006055542035028338, best_loss = 0.000606671383138746, model saved at 9\n",
      "val_losses[-1] = 0.0006046893540769815, best_loss = 0.0006055542035028338, model saved at 10\n",
      "val_losses[-1] = 0.0006042536115273833, best_loss = 0.0006046893540769815, model saved at 12\n",
      "val_losses[-1] = 0.0006026788614690304, best_loss = 0.0006042536115273833, model saved at 15\n",
      "val_losses[-1] = 0.0006024559261277318, best_loss = 0.0006026788614690304, model saved at 16\n",
      "val_losses[-1] = 0.0006023564492352307, best_loss = 0.0006024559261277318, model saved at 17\n",
      "val_losses[-1] = 0.000601865176577121, best_loss = 0.0006023564492352307, model saved at 20\n",
      "val_losses[-1] = 0.0006013668025843799, best_loss = 0.000601865176577121, model saved at 22\n",
      "val_losses[-1] = 0.0006012245430611074, best_loss = 0.0006013668025843799, model saved at 26\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0007079523638822138, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006517209112644196, best_loss = 0.0007079523638822138, model saved at 1\n",
      "val_losses[-1] = 0.0006388966576196253, best_loss = 0.0006517209112644196, model saved at 2\n",
      "val_losses[-1] = 0.0005835718475282192, best_loss = 0.0006388966576196253, model saved at 3\n",
      "val_losses[-1] = 0.00015292798343580216, best_loss = 0.0005835718475282192, model saved at 4\n",
      "val_losses[-1] = 0.00014850424486212432, best_loss = 0.00015292798343580216, model saved at 5\n",
      "val_losses[-1] = 0.00013361989113036543, best_loss = 0.00014850424486212432, model saved at 6\n",
      "val_losses[-1] = 0.0001316722627962008, best_loss = 0.00013361989113036543, model saved at 16\n",
      "val_losses[-1] = 0.0001272965018870309, best_loss = 0.0001316722627962008, model saved at 17\n",
      "val_losses[-1] = 0.00012644850357901305, best_loss = 0.0001272965018870309, model saved at 18\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006228303536772728, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006124866777099669, best_loss = 0.0006228303536772728, model saved at 1\n",
      "val_losses[-1] = 0.0005981698632240295, best_loss = 0.0006124866777099669, model saved at 4\n",
      "val_losses[-1] = 0.0005879825912415981, best_loss = 0.0005981698632240295, model saved at 5\n",
      "val_losses[-1] = 0.0005797733319923282, best_loss = 0.0005879825912415981, model saved at 6\n",
      "val_losses[-1] = 0.0005757337785325944, best_loss = 0.0005797733319923282, model saved at 7\n",
      "val_losses[-1] = 0.0005720172193832695, best_loss = 0.0005757337785325944, model saved at 8\n",
      "val_losses[-1] = 0.0005680404719896615, best_loss = 0.0005720172193832695, model saved at 9\n",
      "val_losses[-1] = 0.0005653921398334205, best_loss = 0.0005680404719896615, model saved at 10\n",
      "val_losses[-1] = 0.0005627509672194719, best_loss = 0.0005653921398334205, model saved at 11\n",
      "val_losses[-1] = 0.0005608824430964887, best_loss = 0.0005627509672194719, model saved at 12\n",
      "val_losses[-1] = 0.0005546541651710868, best_loss = 0.0005608824430964887, model saved at 14\n",
      "val_losses[-1] = 0.0005539486301131546, best_loss = 0.0005546541651710868, model saved at 15\n",
      "val_losses[-1] = 0.0005520791164599359, best_loss = 0.0005539486301131546, model saved at 16\n",
      "val_losses[-1] = 0.0003335566143505275, best_loss = 0.0005520791164599359, model saved at 17\n",
      "val_losses[-1] = 0.0001583366101840511, best_loss = 0.0003335566143505275, model saved at 18\n",
      "val_losses[-1] = 0.00014216006093192846, best_loss = 0.0001583366101840511, model saved at 20\n",
      "val_losses[-1] = 0.00014197439304552972, best_loss = 0.00014216006093192846, model saved at 23\n",
      "val_losses[-1] = 0.00013748303172178566, best_loss = 0.00014197439304552972, model saved at 24\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0008538573747500777, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0007194039062596858, best_loss = 0.0008538573747500777, model saved at 1\n",
      "val_losses[-1] = 0.0006350058829411864, best_loss = 0.0007194039062596858, model saved at 2\n",
      "val_losses[-1] = 0.0005990450154058635, best_loss = 0.0006350058829411864, model saved at 4\n",
      "val_losses[-1] = 0.0005799385835416615, best_loss = 0.0005990450154058635, model saved at 5\n",
      "val_losses[-1] = 0.0005692337290383875, best_loss = 0.0005799385835416615, model saved at 6\n",
      "val_losses[-1] = 0.0005652577965520322, best_loss = 0.0005692337290383875, model saved at 7\n",
      "val_losses[-1] = 0.0005647282232530415, best_loss = 0.0005652577965520322, model saved at 8\n",
      "val_losses[-1] = 0.000204084615688771, best_loss = 0.0005647282232530415, model saved at 9\n",
      "val_losses[-1] = 0.000157080139615573, best_loss = 0.000204084615688771, model saved at 10\n",
      "val_losses[-1] = 0.00014702207408845425, best_loss = 0.000157080139615573, model saved at 11\n",
      "val_losses[-1] = 0.00014000292867422104, best_loss = 0.00014702207408845425, model saved at 14\n",
      "val_losses[-1] = 0.00013808092626277357, best_loss = 0.00014000292867422104, model saved at 15\n",
      "val_losses[-1] = 0.0001377103035338223, best_loss = 0.00013808092626277357, model saved at 17\n",
      "val_losses[-1] = 0.00013590736489277333, best_loss = 0.0001377103035338223, model saved at 19\n",
      "val_losses[-1] = 0.0001344297779724002, best_loss = 0.00013590736489277333, model saved at 27\n",
      "val_losses[-1] = 0.0001341724127996713, best_loss = 0.0001344297779724002, model saved at 29\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0007313897367566824, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00021569950331468135, best_loss = 0.0007313897367566824, model saved at 1\n",
      "val_losses[-1] = 0.0001577311340952292, best_loss = 0.00021569950331468135, model saved at 2\n",
      "val_losses[-1] = 0.00014630348596256226, best_loss = 0.0001577311340952292, model saved at 4\n",
      "val_losses[-1] = 0.00013800499436911196, best_loss = 0.00014630348596256226, model saved at 5\n",
      "val_losses[-1] = 0.00013721313735004514, best_loss = 0.00013800499436911196, model saved at 10\n",
      "val_losses[-1] = 0.00013323361054062843, best_loss = 0.00013721313735004514, model saved at 15\n",
      "val_losses[-1] = 0.00013206190487835556, best_loss = 0.00013323361054062843, model saved at 18\n",
      "val_losses[-1] = 0.0001312839740421623, best_loss = 0.00013206190487835556, model saved at 21\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006265720585361123, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006138246972113848, best_loss = 0.0006265720585361123, model saved at 1\n",
      "val_losses[-1] = 0.000609044567681849, best_loss = 0.0006138246972113848, model saved at 2\n",
      "val_losses[-1] = 0.0006084589404053986, best_loss = 0.000609044567681849, model saved at 3\n",
      "val_losses[-1] = 0.0006004387978464365, best_loss = 0.0006084589404053986, model saved at 4\n",
      "val_losses[-1] = 0.0005854934570379555, best_loss = 0.0006004387978464365, model saved at 5\n",
      "val_losses[-1] = 0.0005818579811602831, best_loss = 0.0005854934570379555, model saved at 6\n",
      "val_losses[-1] = 0.0005777691840194166, best_loss = 0.0005818579811602831, model saved at 7\n",
      "val_losses[-1] = 0.000573601690120995, best_loss = 0.0005777691840194166, model saved at 9\n",
      "val_losses[-1] = 0.0005709466058760881, best_loss = 0.000573601690120995, model saved at 10\n",
      "val_losses[-1] = 0.0005701306508854032, best_loss = 0.0005709466058760881, model saved at 11\n",
      "val_losses[-1] = 0.000244968687184155, best_loss = 0.0005701306508854032, model saved at 12\n",
      "val_losses[-1] = 0.00015753894695080817, best_loss = 0.000244968687184155, model saved at 13\n",
      "val_losses[-1] = 0.00015003097360022366, best_loss = 0.00015753894695080817, model saved at 16\n",
      "val_losses[-1] = 0.00014668925723526627, best_loss = 0.00015003097360022366, model saved at 22\n",
      "val_losses[-1] = 0.000146656806464307, best_loss = 0.00014668925723526627, model saved at 23\n",
      "val_losses[-1] = 0.00014581707364413887, best_loss = 0.000146656806464307, model saved at 24\n",
      "val_losses[-1] = 0.00014402257511392236, best_loss = 0.00014581707364413887, model saved at 25\n",
      "val_losses[-1] = 0.00014210269728209823, best_loss = 0.00014402257511392236, model saved at 28\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006351912743411958, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006247911369428039, best_loss = 0.0006351912743411958, model saved at 1\n",
      "val_losses[-1] = 0.0006210136343725026, best_loss = 0.0006247911369428039, model saved at 2\n",
      "val_losses[-1] = 0.0006012271041981876, best_loss = 0.0006210136343725026, model saved at 3\n",
      "val_losses[-1] = 0.00011017458018613979, best_loss = 0.0006012271041981876, model saved at 4\n",
      "val_losses[-1] = 8.504902507411316e-05, best_loss = 0.00011017458018613979, model saved at 5\n",
      "val_losses[-1] = 8.446134597761557e-05, best_loss = 8.504902507411316e-05, model saved at 6\n",
      "val_losses[-1] = 7.977407949510962e-05, best_loss = 8.446134597761557e-05, model saved at 7\n",
      "val_losses[-1] = 7.941491639940068e-05, best_loss = 7.977407949510962e-05, model saved at 8\n",
      "val_losses[-1] = 7.753667159704491e-05, best_loss = 7.941491639940068e-05, model saved at 14\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006271196762099862, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006213134038262069, best_loss = 0.0006271196762099862, model saved at 1\n",
      "val_losses[-1] = 0.0006126697408035398, best_loss = 0.0006213134038262069, model saved at 2\n",
      "val_losses[-1] = 0.000611263036262244, best_loss = 0.0006126697408035398, model saved at 7\n",
      "val_losses[-1] = 0.0005995651008561254, best_loss = 0.000611263036262244, model saved at 8\n",
      "val_losses[-1] = 0.0005809603608213365, best_loss = 0.0005995651008561254, model saved at 9\n",
      "val_losses[-1] = 0.0005614826222881675, best_loss = 0.0005809603608213365, model saved at 10\n",
      "val_losses[-1] = 0.0005545348394662142, best_loss = 0.0005614826222881675, model saved at 11\n",
      "val_losses[-1] = 0.0005528986221179366, best_loss = 0.0005545348394662142, model saved at 12\n",
      "val_losses[-1] = 0.0005488140741363168, best_loss = 0.0005528986221179366, model saved at 13\n",
      "val_losses[-1] = 0.0005267001688480377, best_loss = 0.0005488140741363168, model saved at 14\n",
      "val_losses[-1] = 0.0005119783454574645, best_loss = 0.0005267001688480377, model saved at 15\n",
      "val_losses[-1] = 0.0004980585654266179, best_loss = 0.0005119783454574645, model saved at 17\n",
      "val_losses[-1] = 9.90225889836438e-05, best_loss = 0.0004980585654266179, model saved at 18\n",
      "val_losses[-1] = 8.737180178286508e-05, best_loss = 9.90225889836438e-05, model saved at 19\n",
      "val_losses[-1] = 8.583463204558939e-05, best_loss = 8.737180178286508e-05, model saved at 20\n",
      "val_losses[-1] = 8.531634375685826e-05, best_loss = 8.583463204558939e-05, model saved at 21\n",
      "val_losses[-1] = 8.499264367856085e-05, best_loss = 8.531634375685826e-05, model saved at 22\n",
      "val_losses[-1] = 7.917923358036205e-05, best_loss = 8.499264367856085e-05, model saved at 25\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0011565119493752718, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005901515251025558, best_loss = 0.0011565119493752718, model saved at 1\n",
      "val_losses[-1] = 0.000516842061188072, best_loss = 0.0005901515251025558, model saved at 2\n",
      "val_losses[-1] = 0.00048655684804543853, best_loss = 0.000516842061188072, model saved at 3\n",
      "val_losses[-1] = 0.00047545830602757633, best_loss = 0.00048655684804543853, model saved at 4\n",
      "val_losses[-1] = 0.0004442378703970462, best_loss = 0.00047545830602757633, model saved at 5\n",
      "val_losses[-1] = 0.0001431249111192301, best_loss = 0.0004442378703970462, model saved at 6\n",
      "val_losses[-1] = 9.304554259870201e-05, best_loss = 0.0001431249111192301, model saved at 7\n",
      "val_losses[-1] = 8.721672929823399e-05, best_loss = 9.304554259870201e-05, model saved at 8\n",
      "val_losses[-1] = 8.700267790118232e-05, best_loss = 8.721672929823399e-05, model saved at 10\n",
      "val_losses[-1] = 7.893072324804962e-05, best_loss = 8.700267790118232e-05, model saved at 11\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006265247939154506, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006247248384170234, best_loss = 0.0006265247939154506, model saved at 1\n",
      "val_losses[-1] = 0.0006234993925318122, best_loss = 0.0006247248384170234, model saved at 2\n",
      "val_losses[-1] = 0.0006234347238205373, best_loss = 0.0006234993925318122, model saved at 3\n",
      "val_losses[-1] = 0.0006233672611415386, best_loss = 0.0006234347238205373, model saved at 4\n",
      "val_losses[-1] = 0.0006233400199562311, best_loss = 0.0006233672611415386, model saved at 8\n",
      "val_losses[-1] = 0.0005780686624348164, best_loss = 0.0006233400199562311, model saved at 9\n",
      "val_losses[-1] = 0.0005383752868510783, best_loss = 0.0005780686624348164, model saved at 10\n",
      "val_losses[-1] = 0.0005231020622886717, best_loss = 0.0005383752868510783, model saved at 11\n",
      "val_losses[-1] = 0.0004987367428839207, best_loss = 0.0005231020622886717, model saved at 12\n",
      "val_losses[-1] = 0.0004908315604552627, best_loss = 0.0004987367428839207, model saved at 13\n",
      "val_losses[-1] = 0.0004705372266471386, best_loss = 0.0004908315604552627, model saved at 14\n",
      "val_losses[-1] = 0.0004570520541165024, best_loss = 0.0004705372266471386, model saved at 15\n",
      "val_losses[-1] = 0.00043201851076446474, best_loss = 0.0004570520541165024, model saved at 16\n",
      "val_losses[-1] = 0.0004217304813209921, best_loss = 0.00043201851076446474, model saved at 17\n",
      "val_losses[-1] = 0.000404772290494293, best_loss = 0.0004217304813209921, model saved at 19\n",
      "val_losses[-1] = 0.00012604209769051522, best_loss = 0.000404772290494293, model saved at 20\n",
      "val_losses[-1] = 7.905285019660369e-05, best_loss = 0.00012604209769051522, model saved at 21\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006203515804372728, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005932197673246264, best_loss = 0.0006203515804372728, model saved at 1\n",
      "val_losses[-1] = 9.77059971773997e-05, best_loss = 0.0005932197673246264, model saved at 2\n",
      "val_losses[-1] = 8.744464867049828e-05, best_loss = 9.77059971773997e-05, model saved at 3\n",
      "val_losses[-1] = 7.596531941089779e-05, best_loss = 8.744464867049828e-05, model saved at 5\n",
      "val_losses[-1] = 7.427701348206028e-05, best_loss = 7.596531941089779e-05, model saved at 21\n",
      "(1, 0.7)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006284108385443687, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006234375759959221, best_loss = 0.0006284108385443687, model saved at 1\n",
      "val_losses[-1] = 0.0006234104512259364, best_loss = 0.0006234375759959221, model saved at 9\n",
      "val_losses[-1] = 0.0006229749415069818, best_loss = 0.0006234104512259364, model saved at 26\n",
      "val_losses[-1] = 0.0006001702276989818, best_loss = 0.0006229749415069818, model saved at 29\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006849284982308745, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006671638693660498, best_loss = 0.0006849284982308745, model saved at 1\n",
      "val_losses[-1] = 0.0006477298447862267, best_loss = 0.0006671638693660498, model saved at 2\n",
      "val_losses[-1] = 0.0006348706665448844, best_loss = 0.0006477298447862267, model saved at 3\n",
      "val_losses[-1] = 0.0006255170446820557, best_loss = 0.0006348706665448844, model saved at 4\n",
      "val_losses[-1] = 0.0006202959921211004, best_loss = 0.0006255170446820557, model saved at 5\n",
      "val_losses[-1] = 0.0006172487628646195, best_loss = 0.0006202959921211004, model saved at 6\n",
      "val_losses[-1] = 0.0006039371364749968, best_loss = 0.0006172487628646195, model saved at 7\n",
      "val_losses[-1] = 0.00046682782704010606, best_loss = 0.0006039371364749968, model saved at 8\n",
      "val_losses[-1] = 0.0004032269644085318, best_loss = 0.00046682782704010606, model saved at 9\n",
      "val_losses[-1] = 0.0004023737274110317, best_loss = 0.0004032269644085318, model saved at 10\n",
      "val_losses[-1] = 0.00039149323129095137, best_loss = 0.0004023737274110317, model saved at 11\n",
      "val_losses[-1] = 0.0003839558339677751, best_loss = 0.00039149323129095137, model saved at 12\n",
      "val_losses[-1] = 0.0003745248541235924, best_loss = 0.0003839558339677751, model saved at 13\n",
      "val_losses[-1] = 0.0003683464019559324, best_loss = 0.0003745248541235924, model saved at 17\n",
      "val_losses[-1] = 0.00036741772782988846, best_loss = 0.0003683464019559324, model saved at 19\n",
      "val_losses[-1] = 0.00036635607830248773, best_loss = 0.00036741772782988846, model saved at 22\n",
      "val_losses[-1] = 0.0003652354935184121, best_loss = 0.00036635607830248773, model saved at 25\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007345277117565274, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006407060427591205, best_loss = 0.0007345277117565274, model saved at 2\n",
      "val_losses[-1] = 0.0006190622225403786, best_loss = 0.0006407060427591205, model saved at 3\n",
      "val_losses[-1] = 0.0006125397048890591, best_loss = 0.0006190622225403786, model saved at 4\n",
      "val_losses[-1] = 0.0006088603986427188, best_loss = 0.0006125397048890591, model saved at 5\n",
      "val_losses[-1] = 0.0006079825107008219, best_loss = 0.0006088603986427188, model saved at 6\n",
      "val_losses[-1] = 0.0006047273054718971, best_loss = 0.0006079825107008219, model saved at 7\n",
      "val_losses[-1] = 0.0006023337482474744, best_loss = 0.0006047273054718971, model saved at 8\n",
      "val_losses[-1] = 0.0006003024172969162, best_loss = 0.0006023337482474744, model saved at 9\n",
      "val_losses[-1] = 0.0006000037537887692, best_loss = 0.0006003024172969162, model saved at 10\n",
      "val_losses[-1] = 0.0005995983374305069, best_loss = 0.0006000037537887692, model saved at 11\n",
      "val_losses[-1] = 0.0005988813354633749, best_loss = 0.0005995983374305069, model saved at 12\n",
      "val_losses[-1] = 0.0005983824376016855, best_loss = 0.0005988813354633749, model saved at 13\n",
      "val_losses[-1] = 0.0005976308602839708, best_loss = 0.0005983824376016855, model saved at 14\n",
      "val_losses[-1] = 0.0005969822523184121, best_loss = 0.0005976308602839708, model saved at 15\n",
      "val_losses[-1] = 0.0005964859738014638, best_loss = 0.0005969822523184121, model saved at 17\n",
      "val_losses[-1] = 0.0005962156574241817, best_loss = 0.0005964859738014638, model saved at 19\n",
      "val_losses[-1] = 0.0005961947026662529, best_loss = 0.0005962156574241817, model saved at 20\n",
      "val_losses[-1] = 0.0005957504035905004, best_loss = 0.0005961947026662529, model saved at 21\n",
      "val_losses[-1] = 0.0005957087851129472, best_loss = 0.0005957504035905004, model saved at 22\n",
      "val_losses[-1] = 0.0005952503997832537, best_loss = 0.0005957087851129472, model saved at 23\n",
      "val_losses[-1] = 0.0005945603479631245, best_loss = 0.0005952503997832537, model saved at 24\n",
      "val_losses[-1] = 0.0005931901396252215, best_loss = 0.0005945603479631245, model saved at 26\n",
      "val_losses[-1] = 0.0005795836332254112, best_loss = 0.0005931901396252215, model saved at 27\n",
      "val_losses[-1] = 0.0005311318091116846, best_loss = 0.0005795836332254112, model saved at 28\n",
      "val_losses[-1] = 0.0004724534519482404, best_loss = 0.0005311318091116846, model saved at 29\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006295688217505813, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00045794190373271704, best_loss = 0.0006295688217505813, model saved at 1\n",
      "val_losses[-1] = 0.0004087011329829693, best_loss = 0.00045794190373271704, model saved at 2\n",
      "val_losses[-1] = 0.0004039797349832952, best_loss = 0.0004087011329829693, model saved at 4\n",
      "val_losses[-1] = 0.00039144541369751096, best_loss = 0.0004039797349832952, model saved at 7\n",
      "val_losses[-1] = 0.00038589941686950624, best_loss = 0.00039144541369751096, model saved at 8\n",
      "val_losses[-1] = 0.0003822678991127759, best_loss = 0.00038589941686950624, model saved at 9\n",
      "val_losses[-1] = 0.00037518315366469324, best_loss = 0.0003822678991127759, model saved at 10\n",
      "val_losses[-1] = 0.0003746338770724833, best_loss = 0.00037518315366469324, model saved at 11\n",
      "val_losses[-1] = 0.0003685171832330525, best_loss = 0.0003746338770724833, model saved at 15\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006274781771935523, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006203887169249356, best_loss = 0.0006274781771935523, model saved at 1\n",
      "val_losses[-1] = 0.0006174800219014287, best_loss = 0.0006203887169249356, model saved at 2\n",
      "val_losses[-1] = 0.0006114533171057701, best_loss = 0.0006174800219014287, model saved at 4\n",
      "val_losses[-1] = 0.000607460446190089, best_loss = 0.0006114533171057701, model saved at 5\n",
      "val_losses[-1] = 0.0006064856424927711, best_loss = 0.000607460446190089, model saved at 6\n",
      "val_losses[-1] = 0.0006055289413779974, best_loss = 0.0006064856424927711, model saved at 7\n",
      "val_losses[-1] = 0.0006050599040463567, best_loss = 0.0006055289413779974, model saved at 8\n",
      "val_losses[-1] = 0.0006043108296580613, best_loss = 0.0006050599040463567, model saved at 9\n",
      "val_losses[-1] = 0.0006041541928425431, best_loss = 0.0006043108296580613, model saved at 11\n",
      "val_losses[-1] = 0.0006023886380717158, best_loss = 0.0006041541928425431, model saved at 12\n",
      "val_losses[-1] = 0.0006009633070789278, best_loss = 0.0006023886380717158, model saved at 16\n",
      "val_losses[-1] = 0.0006004594033583999, best_loss = 0.0006009633070789278, model saved at 18\n",
      "val_losses[-1] = 0.00048686377704143524, best_loss = 0.0006004594033583999, model saved at 19\n",
      "val_losses[-1] = 0.00041369168320670724, best_loss = 0.00048686377704143524, model saved at 20\n",
      "val_losses[-1] = 0.0003981014306191355, best_loss = 0.00041369168320670724, model saved at 21\n",
      "val_losses[-1] = 0.0003910594095941633, best_loss = 0.0003981014306191355, model saved at 22\n",
      "val_losses[-1] = 0.00038858092739246786, best_loss = 0.0003910594095941633, model saved at 23\n",
      "val_losses[-1] = 0.0003740149550139904, best_loss = 0.00038858092739246786, model saved at 24\n",
      "val_losses[-1] = 0.0003720575477927923, best_loss = 0.0003740149550139904, model saved at 28\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006329912575893104, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006294809281826019, best_loss = 0.0006329912575893104, model saved at 1\n",
      "val_losses[-1] = 0.0006282261456362903, best_loss = 0.0006294809281826019, model saved at 2\n",
      "val_losses[-1] = 0.0006249550497159362, best_loss = 0.0006282261456362903, model saved at 3\n",
      "val_losses[-1] = 0.00021479847782757133, best_loss = 0.0006249550497159362, model saved at 4\n",
      "val_losses[-1] = 0.000141670840093866, best_loss = 0.00021479847782757133, model saved at 5\n",
      "val_losses[-1] = 0.00013403219054453075, best_loss = 0.000141670840093866, model saved at 6\n",
      "val_losses[-1] = 0.00013214127102401108, best_loss = 0.00013403219054453075, model saved at 17\n",
      "val_losses[-1] = 0.00013086473336443305, best_loss = 0.00013214127102401108, model saved at 18\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0008012185571715236, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006211365689523518, best_loss = 0.0008012185571715236, model saved at 1\n",
      "val_losses[-1] = 0.0004284385358914733, best_loss = 0.0006211365689523518, model saved at 2\n",
      "val_losses[-1] = 0.00015336951764766127, best_loss = 0.0004284385358914733, model saved at 3\n",
      "val_losses[-1] = 0.000142865494126454, best_loss = 0.00015336951764766127, model saved at 4\n",
      "val_losses[-1] = 0.00013352443056646734, best_loss = 0.000142865494126454, model saved at 5\n",
      "val_losses[-1] = 0.00013201279216445982, best_loss = 0.00013352443056646734, model saved at 7\n",
      "val_losses[-1] = 0.00012042837624903768, best_loss = 0.00013201279216445982, model saved at 8\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007821600884199142, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006396747194230556, best_loss = 0.0007821600884199142, model saved at 1\n",
      "val_losses[-1] = 0.0006034234538674355, best_loss = 0.0006396747194230556, model saved at 2\n",
      "val_losses[-1] = 0.0005803037784062326, best_loss = 0.0006034234538674355, model saved at 3\n",
      "val_losses[-1] = 0.0005681897746399045, best_loss = 0.0005803037784062326, model saved at 4\n",
      "val_losses[-1] = 0.0005532013019546866, best_loss = 0.0005681897746399045, model saved at 5\n",
      "val_losses[-1] = 0.00040526455268263817, best_loss = 0.0005532013019546866, model saved at 6\n",
      "val_losses[-1] = 0.00017190721700899303, best_loss = 0.00040526455268263817, model saved at 7\n",
      "val_losses[-1] = 0.00015336529759224504, best_loss = 0.00017190721700899303, model saved at 8\n",
      "val_losses[-1] = 0.00014258123701438308, best_loss = 0.00015336529759224504, model saved at 10\n",
      "val_losses[-1] = 0.00014178043056745082, best_loss = 0.00014258123701438308, model saved at 11\n",
      "val_losses[-1] = 0.00013695952657144517, best_loss = 0.00014178043056745082, model saved at 12\n",
      "val_losses[-1] = 0.0001328687503701076, best_loss = 0.00013695952657144517, model saved at 14\n",
      "val_losses[-1] = 0.00012895964027848095, best_loss = 0.0001328687503701076, model saved at 15\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006089911912567914, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00030636333394795656, best_loss = 0.0006089911912567914, model saved at 1\n",
      "val_losses[-1] = 0.00016956038598436862, best_loss = 0.00030636333394795656, model saved at 2\n",
      "val_losses[-1] = 0.00016747570771258324, best_loss = 0.00016956038598436862, model saved at 3\n",
      "val_losses[-1] = 0.00014815469330642372, best_loss = 0.00016747570771258324, model saved at 4\n",
      "val_losses[-1] = 0.00013820741150993854, best_loss = 0.00014815469330642372, model saved at 5\n",
      "val_losses[-1] = 0.00013714210945181549, best_loss = 0.00013820741150993854, model saved at 8\n",
      "val_losses[-1] = 0.0001351892715319991, best_loss = 0.00013714210945181549, model saved at 15\n",
      "val_losses[-1] = 0.0001341096212854609, best_loss = 0.0001351892715319991, model saved at 17\n",
      "val_losses[-1] = 0.000132874192786403, best_loss = 0.0001341096212854609, model saved at 18\n",
      "val_losses[-1] = 0.00012998422607779503, best_loss = 0.000132874192786403, model saved at 21\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006245588883757591, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006105357315391302, best_loss = 0.0006245588883757591, model saved at 1\n",
      "val_losses[-1] = 0.0006053325487300754, best_loss = 0.0006105357315391302, model saved at 2\n",
      "val_losses[-1] = 0.000602702668402344, best_loss = 0.0006053325487300754, model saved at 3\n",
      "val_losses[-1] = 0.0005947980098426342, best_loss = 0.000602702668402344, model saved at 4\n",
      "val_losses[-1] = 0.0005830694572068751, best_loss = 0.0005947980098426342, model saved at 5\n",
      "val_losses[-1] = 0.0005807967390865088, best_loss = 0.0005830694572068751, model saved at 6\n",
      "val_losses[-1] = 0.0005775458412244916, best_loss = 0.0005807967390865088, model saved at 7\n",
      "val_losses[-1] = 0.0005747099639847875, best_loss = 0.0005775458412244916, model saved at 8\n",
      "val_losses[-1] = 0.0005708799581043422, best_loss = 0.0005747099639847875, model saved at 10\n",
      "val_losses[-1] = 0.0005701599875465035, best_loss = 0.0005708799581043422, model saved at 11\n",
      "val_losses[-1] = 0.0005692710401490331, best_loss = 0.0005701599875465035, model saved at 12\n",
      "val_losses[-1] = 0.0005643604672513902, best_loss = 0.0005692710401490331, model saved at 13\n",
      "val_losses[-1] = 0.0005546638858504593, best_loss = 0.0005643604672513902, model saved at 15\n",
      "val_losses[-1] = 0.0005500898114405572, best_loss = 0.0005546638858504593, model saved at 16\n",
      "val_losses[-1] = 0.0005458163213916123, best_loss = 0.0005500898114405572, model saved at 17\n",
      "val_losses[-1] = 0.000539395899977535, best_loss = 0.0005458163213916123, model saved at 18\n",
      "val_losses[-1] = 0.00017603028391022235, best_loss = 0.000539395899977535, model saved at 19\n",
      "val_losses[-1] = 0.00015920847363304347, best_loss = 0.00017603028391022235, model saved at 20\n",
      "val_losses[-1] = 0.0001548158616060391, best_loss = 0.00015920847363304347, model saved at 21\n",
      "val_losses[-1] = 0.0001464464730815962, best_loss = 0.0001548158616060391, model saved at 22\n",
      "val_losses[-1] = 0.00014510487380903214, best_loss = 0.0001464464730815962, model saved at 23\n",
      "val_losses[-1] = 0.00014463445404544473, best_loss = 0.00014510487380903214, model saved at 25\n",
      "val_losses[-1] = 0.00013685096928384155, best_loss = 0.00014463445404544473, model saved at 27\n",
      "val_losses[-1] = 0.00013610137102659792, best_loss = 0.00013685096928384155, model saved at 28\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006255875341594219, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006036926060914993, best_loss = 0.0006255875341594219, model saved at 1\n",
      "val_losses[-1] = 0.000591625866945833, best_loss = 0.0006036926060914993, model saved at 3\n",
      "val_losses[-1] = 0.000579146493691951, best_loss = 0.000591625866945833, model saved at 4\n",
      "val_losses[-1] = 0.0005668213707394898, best_loss = 0.000579146493691951, model saved at 5\n",
      "val_losses[-1] = 0.0005459014791995287, best_loss = 0.0005668213707394898, model saved at 6\n",
      "val_losses[-1] = 0.00010164368723053485, best_loss = 0.0005459014791995287, model saved at 7\n",
      "val_losses[-1] = 8.617994899395853e-05, best_loss = 0.00010164368723053485, model saved at 8\n",
      "val_losses[-1] = 8.593319944338873e-05, best_loss = 8.617994899395853e-05, model saved at 10\n",
      "val_losses[-1] = 8.300649642478675e-05, best_loss = 8.593319944338873e-05, model saved at 11\n",
      "val_losses[-1] = 8.226681529777125e-05, best_loss = 8.300649642478675e-05, model saved at 12\n",
      "val_losses[-1] = 8.049800817389041e-05, best_loss = 8.226681529777125e-05, model saved at 13\n",
      "val_losses[-1] = 7.913495937827975e-05, best_loss = 8.049800817389041e-05, model saved at 14\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006269606528803706, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00061518739676103, best_loss = 0.0006269606528803706, model saved at 1\n",
      "val_losses[-1] = 9.321132529294118e-05, best_loss = 0.00061518739676103, model saved at 2\n",
      "val_losses[-1] = 8.585903560742736e-05, best_loss = 9.321132529294118e-05, model saved at 3\n",
      "val_losses[-1] = 7.724719034740701e-05, best_loss = 8.585903560742736e-05, model saved at 4\n",
      "val_losses[-1] = 7.482938963221386e-05, best_loss = 7.724719034740701e-05, model saved at 15\n",
      "val_losses[-1] = 7.436124724335968e-05, best_loss = 7.482938963221386e-05, model saved at 25\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0008130719070322812, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005612015374936163, best_loss = 0.0008130719070322812, model saved at 1\n",
      "val_losses[-1] = 0.0005149231874383986, best_loss = 0.0005612015374936163, model saved at 2\n",
      "val_losses[-1] = 0.0004928815760649741, best_loss = 0.0005149231874383986, model saved at 3\n",
      "val_losses[-1] = 0.00046415062388405204, best_loss = 0.0004928815760649741, model saved at 4\n",
      "val_losses[-1] = 0.00042263022623956203, best_loss = 0.00046415062388405204, model saved at 5\n",
      "val_losses[-1] = 0.00012037037959089503, best_loss = 0.00042263022623956203, model saved at 6\n",
      "val_losses[-1] = 9.145022340817377e-05, best_loss = 0.00012037037959089503, model saved at 7\n",
      "val_losses[-1] = 8.38948690216057e-05, best_loss = 9.145022340817377e-05, model saved at 8\n",
      "val_losses[-1] = 7.697143155382946e-05, best_loss = 8.38948690216057e-05, model saved at 11\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006259089568629861, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00010127803398063406, best_loss = 0.0006259089568629861, model saved at 1\n",
      "val_losses[-1] = 8.700808393768966e-05, best_loss = 0.00010127803398063406, model saved at 2\n",
      "val_losses[-1] = 7.938824273878708e-05, best_loss = 8.700808393768966e-05, model saved at 3\n",
      "val_losses[-1] = 7.570669549750164e-05, best_loss = 7.938824273878708e-05, model saved at 20\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006186403334140778, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005958856781944633, best_loss = 0.0006186403334140778, model saved at 1\n",
      "val_losses[-1] = 0.0005709564429707825, best_loss = 0.0005958856781944633, model saved at 2\n",
      "val_losses[-1] = 0.0005495385848917067, best_loss = 0.0005709564429707825, model saved at 3\n",
      "val_losses[-1] = 0.00053218292305246, best_loss = 0.0005495385848917067, model saved at 4\n",
      "val_losses[-1] = 0.0005138332489877939, best_loss = 0.00053218292305246, model saved at 5\n",
      "val_losses[-1] = 0.0005011183093301952, best_loss = 0.0005138332489877939, model saved at 6\n",
      "val_losses[-1] = 0.00048456399235874414, best_loss = 0.0005011183093301952, model saved at 7\n",
      "val_losses[-1] = 0.00011204290785826743, best_loss = 0.00048456399235874414, model saved at 9\n",
      "val_losses[-1] = 9.02740066521801e-05, best_loss = 0.00011204290785826743, model saved at 10\n",
      "val_losses[-1] = 8.168927161023021e-05, best_loss = 9.02740066521801e-05, model saved at 11\n",
      "val_losses[-1] = 7.862904749345034e-05, best_loss = 8.168927161023021e-05, model saved at 14\n",
      "val_losses[-1] = 7.452426507370546e-05, best_loss = 7.862904749345034e-05, model saved at 21\n",
      "(1, 0.6)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006235063192434609, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006234371685422957, best_loss = 0.0006235063192434609, model saved at 1\n",
      "val_losses[-1] = 0.0006231012521311641, best_loss = 0.0006234371685422957, model saved at 4\n",
      "val_losses[-1] = 0.0006162798381410539, best_loss = 0.0006231012521311641, model saved at 5\n",
      "val_losses[-1] = 0.000614064047113061, best_loss = 0.0006162798381410539, model saved at 6\n",
      "val_losses[-1] = 0.0006122144404798746, best_loss = 0.000614064047113061, model saved at 7\n",
      "val_losses[-1] = 0.0006095286807976663, best_loss = 0.0006122144404798746, model saved at 8\n",
      "val_losses[-1] = 0.0006011470686644316, best_loss = 0.0006095286807976663, model saved at 9\n",
      "val_losses[-1] = 0.0005936054512858391, best_loss = 0.0006011470686644316, model saved at 10\n",
      "val_losses[-1] = 0.0005896120565012097, best_loss = 0.0005936054512858391, model saved at 11\n",
      "val_losses[-1] = 0.0005875497008673847, best_loss = 0.0005896120565012097, model saved at 12\n",
      "val_losses[-1] = 0.0005837142816744745, best_loss = 0.0005875497008673847, model saved at 14\n",
      "val_losses[-1] = 0.0005830178270116448, best_loss = 0.0005837142816744745, model saved at 15\n",
      "val_losses[-1] = 0.0005804156535305083, best_loss = 0.0005830178270116448, model saved at 16\n",
      "val_losses[-1] = 0.0005796205368824303, best_loss = 0.0005804156535305083, model saved at 17\n",
      "val_losses[-1] = 0.0005781138315796852, best_loss = 0.0005796205368824303, model saved at 18\n",
      "val_losses[-1] = 0.0005768573028035462, best_loss = 0.0005781138315796852, model saved at 19\n",
      "val_losses[-1] = 0.0005754248122684658, best_loss = 0.0005768573028035462, model saved at 21\n",
      "val_losses[-1] = 0.0005743848159909248, best_loss = 0.0005754248122684658, model saved at 23\n",
      "val_losses[-1] = 0.0005161339649930596, best_loss = 0.0005743848159909248, model saved at 24\n",
      "val_losses[-1] = 0.0004472791915759444, best_loss = 0.0005161339649930596, model saved at 25\n",
      "val_losses[-1] = 0.0004240027046762407, best_loss = 0.0004472791915759444, model saved at 26\n",
      "val_losses[-1] = 0.00042195653077214956, best_loss = 0.0004240027046762407, model saved at 27\n",
      "val_losses[-1] = 0.00041735803824849427, best_loss = 0.00042195653077214956, model saved at 28\n",
      "val_losses[-1] = 0.0004093190946150571, best_loss = 0.00041735803824849427, model saved at 29\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0007017215830273926, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005821579252369702, best_loss = 0.0007017215830273926, model saved at 1\n",
      "val_losses[-1] = 0.0004631642659660429, best_loss = 0.0005821579252369702, model saved at 2\n",
      "val_losses[-1] = 0.00041442824294790626, best_loss = 0.0004631642659660429, model saved at 3\n",
      "val_losses[-1] = 0.0003975016879849136, best_loss = 0.00041442824294790626, model saved at 5\n",
      "val_losses[-1] = 0.0003819926641881466, best_loss = 0.0003975016879849136, model saved at 6\n",
      "val_losses[-1] = 0.0003678284992929548, best_loss = 0.0003819926641881466, model saved at 7\n",
      "val_losses[-1] = 0.00036056063254363835, best_loss = 0.0003678284992929548, model saved at 9\n",
      "val_losses[-1] = 0.00035974718048237264, best_loss = 0.00036056063254363835, model saved at 13\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007797483704052866, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006438450654968619, best_loss = 0.0007797483704052866, model saved at 1\n",
      "val_losses[-1] = 0.0006186419050209224, best_loss = 0.0006438450654968619, model saved at 2\n",
      "val_losses[-1] = 0.0006093830452300608, best_loss = 0.0006186419050209224, model saved at 3\n",
      "val_losses[-1] = 0.0006059344159439206, best_loss = 0.0006093830452300608, model saved at 4\n",
      "val_losses[-1] = 0.0006030171061865985, best_loss = 0.0006059344159439206, model saved at 6\n",
      "val_losses[-1] = 0.0005979703855700791, best_loss = 0.0006030171061865985, model saved at 7\n",
      "val_losses[-1] = 0.0005941856070421636, best_loss = 0.0005979703855700791, model saved at 8\n",
      "val_losses[-1] = 0.0005785414250567555, best_loss = 0.0005941856070421636, model saved at 9\n",
      "val_losses[-1] = 0.00047595734940841794, best_loss = 0.0005785414250567555, model saved at 10\n",
      "val_losses[-1] = 0.0004138596123084426, best_loss = 0.00047595734940841794, model saved at 11\n",
      "val_losses[-1] = 0.00039797290810383856, best_loss = 0.0004138596123084426, model saved at 12\n",
      "val_losses[-1] = 0.0003922681789845228, best_loss = 0.00039797290810383856, model saved at 13\n",
      "val_losses[-1] = 0.0003765729779843241, best_loss = 0.0003922681789845228, model saved at 14\n",
      "val_losses[-1] = 0.0003755557117983699, best_loss = 0.0003765729779843241, model saved at 23\n",
      "val_losses[-1] = 0.00037481170147657394, best_loss = 0.0003755557117983699, model saved at 27\n",
      "val_losses[-1] = 0.0003744345158338547, best_loss = 0.00037481170147657394, model saved at 28\n",
      "val_losses[-1] = 0.0003700180386658758, best_loss = 0.0003744345158338547, model saved at 29\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006241452065296471, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006171492277644575, best_loss = 0.0006241452065296471, model saved at 1\n",
      "val_losses[-1] = 0.0006008284981362522, best_loss = 0.0006171492277644575, model saved at 2\n",
      "val_losses[-1] = 0.00045049688196741045, best_loss = 0.0006008284981362522, model saved at 3\n",
      "val_losses[-1] = 0.0003991207340732217, best_loss = 0.00045049688196741045, model saved at 4\n",
      "val_losses[-1] = 0.0003856166440527886, best_loss = 0.0003991207340732217, model saved at 7\n",
      "val_losses[-1] = 0.00038091986789368093, best_loss = 0.0003856166440527886, model saved at 9\n",
      "val_losses[-1] = 0.0003776686789933592, best_loss = 0.00038091986789368093, model saved at 10\n",
      "val_losses[-1] = 0.0003761814732570201, best_loss = 0.0003776686789933592, model saved at 11\n",
      "val_losses[-1] = 0.00037173135206103325, best_loss = 0.0003761814732570201, model saved at 15\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006262934766709805, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006196430185809731, best_loss = 0.0006262934766709805, model saved at 1\n",
      "val_losses[-1] = 0.0006159675540402532, best_loss = 0.0006196430185809731, model saved at 2\n",
      "val_losses[-1] = 0.0006135006551630795, best_loss = 0.0006159675540402532, model saved at 5\n",
      "val_losses[-1] = 0.0006094324635341763, best_loss = 0.0006135006551630795, model saved at 6\n",
      "val_losses[-1] = 0.0006078134174458683, best_loss = 0.0006094324635341763, model saved at 7\n",
      "val_losses[-1] = 0.0006063910550437868, best_loss = 0.0006078134174458683, model saved at 8\n",
      "val_losses[-1] = 0.0006058649742044508, best_loss = 0.0006063910550437868, model saved at 9\n",
      "val_losses[-1] = 0.000605021312367171, best_loss = 0.0006058649742044508, model saved at 10\n",
      "val_losses[-1] = 0.0006040403386577964, best_loss = 0.000605021312367171, model saved at 11\n",
      "val_losses[-1] = 0.0006036123959347606, best_loss = 0.0006040403386577964, model saved at 12\n",
      "val_losses[-1] = 0.0006034643156453967, best_loss = 0.0006036123959347606, model saved at 15\n",
      "val_losses[-1] = 0.0006022704183124006, best_loss = 0.0006034643156453967, model saved at 16\n",
      "val_losses[-1] = 0.0006014897953718901, best_loss = 0.0006022704183124006, model saved at 17\n",
      "val_losses[-1] = 0.0006008215132169425, best_loss = 0.0006014897953718901, model saved at 20\n",
      "val_losses[-1] = 0.000600495608523488, best_loss = 0.0006008215132169425, model saved at 23\n",
      "val_losses[-1] = 0.0005995081155560911, best_loss = 0.000600495608523488, model saved at 25\n",
      "val_losses[-1] = 0.0005991713842377067, best_loss = 0.0005995081155560911, model saved at 26\n",
      "val_losses[-1] = 0.0005989528144709766, best_loss = 0.0005991713842377067, model saved at 28\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006320812972262502, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006291851750575006, best_loss = 0.0006320812972262502, model saved at 1\n",
      "val_losses[-1] = 0.0006264435360208154, best_loss = 0.0006291851750575006, model saved at 2\n",
      "val_losses[-1] = 0.0006255217012949288, best_loss = 0.0006264435360208154, model saved at 3\n",
      "val_losses[-1] = 0.0006248161662369967, best_loss = 0.0006255217012949288, model saved at 4\n",
      "val_losses[-1] = 0.0006241172086447477, best_loss = 0.0006248161662369967, model saved at 5\n",
      "val_losses[-1] = 0.0006233978783711791, best_loss = 0.0006241172086447477, model saved at 8\n",
      "val_losses[-1] = 0.0006233771564438939, best_loss = 0.0006233978783711791, model saved at 9\n",
      "val_losses[-1] = 0.0006230658036656678, best_loss = 0.0006233771564438939, model saved at 13\n",
      "val_losses[-1] = 0.0006200414500199258, best_loss = 0.0006230658036656678, model saved at 14\n",
      "val_losses[-1] = 0.0006069535156711936, best_loss = 0.0006200414500199258, model saved at 15\n",
      "val_losses[-1] = 0.0005954646039754152, best_loss = 0.0006069535156711936, model saved at 16\n",
      "val_losses[-1] = 0.0005820360966026783, best_loss = 0.0005954646039754152, model saved at 17\n",
      "val_losses[-1] = 0.0005732654826715589, best_loss = 0.0005820360966026783, model saved at 18\n",
      "val_losses[-1] = 0.0005665058270096779, best_loss = 0.0005732654826715589, model saved at 19\n",
      "val_losses[-1] = 0.0001903004158521071, best_loss = 0.0005665058270096779, model saved at 20\n",
      "val_losses[-1] = 0.00014969625044614077, best_loss = 0.0001903004158521071, model saved at 21\n",
      "val_losses[-1] = 0.0001488357229391113, best_loss = 0.00014969625044614077, model saved at 23\n",
      "val_losses[-1] = 0.00014544444275088608, best_loss = 0.0001488357229391113, model saved at 24\n",
      "val_losses[-1] = 0.0001417872990714386, best_loss = 0.00014544444275088608, model saved at 25\n",
      "val_losses[-1] = 0.00013739972200710326, best_loss = 0.0001417872990714386, model saved at 27\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006701531819999218, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006156250601634383, best_loss = 0.0006701531819999218, model saved at 1\n",
      "val_losses[-1] = 0.0005560839781537652, best_loss = 0.0006156250601634383, model saved at 2\n",
      "val_losses[-1] = 0.00017500009562354535, best_loss = 0.0005560839781537652, model saved at 3\n",
      "val_losses[-1] = 0.00014764118532184511, best_loss = 0.00017500009562354535, model saved at 4\n",
      "val_losses[-1] = 0.00013780347944702953, best_loss = 0.00014764118532184511, model saved at 5\n",
      "val_losses[-1] = 0.00013683272118214518, best_loss = 0.00013780347944702953, model saved at 7\n",
      "val_losses[-1] = 0.00012589523976203054, best_loss = 0.00013683272118214518, model saved at 8\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007332435343414545, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006111575639806688, best_loss = 0.0007332435343414545, model saved at 1\n",
      "val_losses[-1] = 0.0005853219772689044, best_loss = 0.0006111575639806688, model saved at 2\n",
      "val_losses[-1] = 0.0005697433953173459, best_loss = 0.0005853219772689044, model saved at 3\n",
      "val_losses[-1] = 0.0005557708209380507, best_loss = 0.0005697433953173459, model saved at 4\n",
      "val_losses[-1] = 0.0005482863052748144, best_loss = 0.0005557708209380507, model saved at 5\n",
      "val_losses[-1] = 0.00043495630961842835, best_loss = 0.0005482863052748144, model saved at 6\n",
      "val_losses[-1] = 0.0001684312883298844, best_loss = 0.00043495630961842835, model saved at 7\n",
      "val_losses[-1] = 0.00015430165512952954, best_loss = 0.0001684312883298844, model saved at 8\n",
      "val_losses[-1] = 0.00014828484563622624, best_loss = 0.00015430165512952954, model saved at 9\n",
      "val_losses[-1] = 0.0001440745691070333, best_loss = 0.00014828484563622624, model saved at 10\n",
      "val_losses[-1] = 0.00013684775331057608, best_loss = 0.0001440745691070333, model saved at 12\n",
      "val_losses[-1] = 0.00013675179798156023, best_loss = 0.00013684775331057608, model saved at 14\n",
      "val_losses[-1] = 0.00012882560258731246, best_loss = 0.00013675179798156023, model saved at 15\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006150584667921066, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0001950567530002445, best_loss = 0.0006150584667921066, model saved at 1\n",
      "val_losses[-1] = 0.00014824708341620862, best_loss = 0.0001950567530002445, model saved at 2\n",
      "val_losses[-1] = 0.000138135626912117, best_loss = 0.00014824708341620862, model saved at 4\n",
      "val_losses[-1] = 0.00012935898848809302, best_loss = 0.000138135626912117, model saved at 5\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006318729720078409, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006092449766583741, best_loss = 0.0006318729720078409, model saved at 1\n",
      "val_losses[-1] = 0.0006019103457219899, best_loss = 0.0006092449766583741, model saved at 2\n",
      "val_losses[-1] = 0.0005969898775219917, best_loss = 0.0006019103457219899, model saved at 3\n",
      "val_losses[-1] = 0.0005925765726715326, best_loss = 0.0005969898775219917, model saved at 4\n",
      "val_losses[-1] = 0.0005878899246454239, best_loss = 0.0005925765726715326, model saved at 5\n",
      "val_losses[-1] = 0.0005797054036520422, best_loss = 0.0005878899246454239, model saved at 6\n",
      "val_losses[-1] = 0.0005791642470285296, best_loss = 0.0005797054036520422, model saved at 7\n",
      "val_losses[-1] = 0.0005773804150521755, best_loss = 0.0005791642470285296, model saved at 8\n",
      "val_losses[-1] = 0.000573397264815867, best_loss = 0.0005773804150521755, model saved at 9\n",
      "val_losses[-1] = 0.0005725346854887903, best_loss = 0.000573397264815867, model saved at 10\n",
      "val_losses[-1] = 0.0005675004213117063, best_loss = 0.0005725346854887903, model saved at 13\n",
      "val_losses[-1] = 0.0005653734551742673, best_loss = 0.0005675004213117063, model saved at 14\n",
      "val_losses[-1] = 0.0005616567796096206, best_loss = 0.0005653734551742673, model saved at 15\n",
      "val_losses[-1] = 0.000557315128389746, best_loss = 0.0005616567796096206, model saved at 16\n",
      "val_losses[-1] = 0.0005520361009985209, best_loss = 0.000557315128389746, model saved at 17\n",
      "val_losses[-1] = 0.00020169747585896403, best_loss = 0.0005520361009985209, model saved at 18\n",
      "val_losses[-1] = 0.00017045412096194923, best_loss = 0.00020169747585896403, model saved at 19\n",
      "val_losses[-1] = 0.0001602441625436768, best_loss = 0.00017045412096194923, model saved at 20\n",
      "val_losses[-1] = 0.00015293950855266303, best_loss = 0.0001602441625436768, model saved at 21\n",
      "val_losses[-1] = 0.00014890050806570798, best_loss = 0.00015293950855266303, model saved at 22\n",
      "val_losses[-1] = 0.00014606493641622365, best_loss = 0.00014890050806570798, model saved at 24\n",
      "val_losses[-1] = 0.0001455387973692268, best_loss = 0.00014606493641622365, model saved at 27\n",
      "val_losses[-1] = 0.0001407394593115896, best_loss = 0.0001455387973692268, model saved at 28\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.000631420174613595, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006156426388770342, best_loss = 0.000631420174613595, model saved at 2\n",
      "val_losses[-1] = 0.00014118544640950859, best_loss = 0.0006156426388770342, model saved at 6\n",
      "val_losses[-1] = 8.239338785642758e-05, best_loss = 0.00014118544640950859, model saved at 7\n",
      "val_losses[-1] = 8.163522579707205e-05, best_loss = 8.239338785642758e-05, model saved at 8\n",
      "val_losses[-1] = 7.923015800770372e-05, best_loss = 8.163522579707205e-05, model saved at 13\n",
      "val_losses[-1] = 7.893314614193514e-05, best_loss = 7.923015800770372e-05, model saved at 26\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006431583897210658, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000607281515840441, best_loss = 0.0006431583897210658, model saved at 1\n",
      "val_losses[-1] = 8.945939043769613e-05, best_loss = 0.000607281515840441, model saved at 2\n",
      "val_losses[-1] = 8.75644400366582e-05, best_loss = 8.945939043769613e-05, model saved at 3\n",
      "val_losses[-1] = 7.86149685154669e-05, best_loss = 8.75644400366582e-05, model saved at 4\n",
      "val_losses[-1] = 7.773985271342099e-05, best_loss = 7.86149685154669e-05, model saved at 8\n",
      "val_losses[-1] = 7.684939191676676e-05, best_loss = 7.773985271342099e-05, model saved at 15\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0006755100330337882, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006614135927520692, best_loss = 0.0006755100330337882, model saved at 1\n",
      "val_losses[-1] = 0.0006561885820701718, best_loss = 0.0006614135927520692, model saved at 2\n",
      "val_losses[-1] = 0.0005291287670843303, best_loss = 0.0006561885820701718, model saved at 3\n",
      "val_losses[-1] = 0.0004883433575741947, best_loss = 0.0005291287670843303, model saved at 4\n",
      "val_losses[-1] = 0.000458592752693221, best_loss = 0.0004883433575741947, model saved at 5\n",
      "val_losses[-1] = 0.00011264095519436523, best_loss = 0.000458592752693221, model saved at 6\n",
      "val_losses[-1] = 8.75374098541215e-05, best_loss = 0.00011264095519436523, model saved at 7\n",
      "val_losses[-1] = 8.506748417858034e-05, best_loss = 8.75374098541215e-05, model saved at 8\n",
      "val_losses[-1] = 7.440235640387982e-05, best_loss = 8.506748417858034e-05, model saved at 11\n",
      "iter 3...\n",
      "val_losses[-1] = 0.00061980658210814, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00011078637180617079, best_loss = 0.00061980658210814, model saved at 1\n",
      "val_losses[-1] = 8.974804222816601e-05, best_loss = 0.00011078637180617079, model saved at 2\n",
      "val_losses[-1] = 8.120374695863575e-05, best_loss = 8.974804222816601e-05, model saved at 3\n",
      "val_losses[-1] = 8.065197471296415e-05, best_loss = 8.120374695863575e-05, model saved at 8\n",
      "val_losses[-1] = 7.628130697412416e-05, best_loss = 8.065197471296415e-05, model saved at 9\n",
      "val_losses[-1] = 7.572315371362492e-05, best_loss = 7.628130697412416e-05, model saved at 18\n",
      "val_losses[-1] = 7.303872553166002e-05, best_loss = 7.572315371362492e-05, model saved at 20\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006164307706058025, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005838118959218264, best_loss = 0.0006164307706058025, model saved at 1\n",
      "val_losses[-1] = 0.000560592336114496, best_loss = 0.0005838118959218264, model saved at 2\n",
      "val_losses[-1] = 0.0005389084690250456, best_loss = 0.000560592336114496, model saved at 3\n",
      "val_losses[-1] = 0.000519504421390593, best_loss = 0.0005389084690250456, model saved at 4\n",
      "val_losses[-1] = 0.0004901894135400653, best_loss = 0.000519504421390593, model saved at 5\n",
      "val_losses[-1] = 0.0004633482894860208, best_loss = 0.0004901894135400653, model saved at 6\n",
      "val_losses[-1] = 0.0004386327927932143, best_loss = 0.0004633482894860208, model saved at 7\n",
      "val_losses[-1] = 0.00043016846757382154, best_loss = 0.0004386327927932143, model saved at 8\n",
      "val_losses[-1] = 0.0001062610826920718, best_loss = 0.00043016846757382154, model saved at 9\n",
      "val_losses[-1] = 8.564789459342137e-05, best_loss = 0.0001062610826920718, model saved at 10\n",
      "val_losses[-1] = 8.538043039152399e-05, best_loss = 8.564789459342137e-05, model saved at 12\n",
      "val_losses[-1] = 7.976456981850788e-05, best_loss = 8.538043039152399e-05, model saved at 15\n",
      "val_losses[-1] = 7.331764209084213e-05, best_loss = 7.976456981850788e-05, model saved at 21\n",
      "(1, 0.5)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006236704648472369, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006178093608468771, best_loss = 0.0006236704648472369, model saved at 2\n",
      "val_losses[-1] = 0.0005626920028589666, best_loss = 0.0006178093608468771, model saved at 10\n",
      "val_losses[-1] = 0.000432233267929405, best_loss = 0.0005626920028589666, model saved at 11\n",
      "val_losses[-1] = 0.000409542175475508, best_loss = 0.000432233267929405, model saved at 12\n",
      "val_losses[-1] = 0.0003958045563194901, best_loss = 0.000409542175475508, model saved at 13\n",
      "val_losses[-1] = 0.0003800922422669828, best_loss = 0.0003958045563194901, model saved at 15\n",
      "val_losses[-1] = 0.0003757186059374362, best_loss = 0.0003800922422669828, model saved at 18\n",
      "val_losses[-1] = 0.00037181988591328263, best_loss = 0.0003757186059374362, model saved at 19\n",
      "val_losses[-1] = 0.00036910007474943995, best_loss = 0.00037181988591328263, model saved at 25\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006400038837455213, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006186225218698382, best_loss = 0.0006400038837455213, model saved at 1\n",
      "val_losses[-1] = 0.0004568852309603244, best_loss = 0.0006186225218698382, model saved at 2\n",
      "val_losses[-1] = 0.00040638772770762444, best_loss = 0.0004568852309603244, model saved at 3\n",
      "val_losses[-1] = 0.000406318751629442, best_loss = 0.00040638772770762444, model saved at 4\n",
      "val_losses[-1] = 0.00039084136369638145, best_loss = 0.000406318751629442, model saved at 5\n",
      "val_losses[-1] = 0.00037535230512730777, best_loss = 0.00039084136369638145, model saved at 6\n",
      "val_losses[-1] = 0.00036762116360478103, best_loss = 0.00037535230512730777, model saved at 7\n",
      "val_losses[-1] = 0.0003624323580879718, best_loss = 0.00036762116360478103, model saved at 9\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007081569056026638, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006346164736896753, best_loss = 0.0007081569056026638, model saved at 1\n",
      "val_losses[-1] = 0.0006147536332719028, best_loss = 0.0006346164736896753, model saved at 2\n",
      "val_losses[-1] = 0.00060696667060256, best_loss = 0.0006147536332719028, model saved at 3\n",
      "val_losses[-1] = 0.0006040028529241681, best_loss = 0.00060696667060256, model saved at 4\n",
      "val_losses[-1] = 0.000602790794800967, best_loss = 0.0006040028529241681, model saved at 5\n",
      "val_losses[-1] = 0.0006027886993251741, best_loss = 0.000602790794800967, model saved at 6\n",
      "val_losses[-1] = 0.0005926552112214267, best_loss = 0.0006027886993251741, model saved at 7\n",
      "val_losses[-1] = 0.0005887997103855014, best_loss = 0.0005926552112214267, model saved at 9\n",
      "val_losses[-1] = 0.0005885407445020974, best_loss = 0.0005887997103855014, model saved at 18\n",
      "val_losses[-1] = 0.0005295900045894086, best_loss = 0.0005885407445020974, model saved at 19\n",
      "val_losses[-1] = 0.00043458855361677706, best_loss = 0.0005295900045894086, model saved at 20\n",
      "val_losses[-1] = 0.000416510330978781, best_loss = 0.00043458855361677706, model saved at 21\n",
      "val_losses[-1] = 0.0004006545932497829, best_loss = 0.000416510330978781, model saved at 22\n",
      "val_losses[-1] = 0.0003954946296289563, best_loss = 0.0004006545932497829, model saved at 23\n",
      "val_losses[-1] = 0.00039279108750633895, best_loss = 0.0003954946296289563, model saved at 24\n",
      "val_losses[-1] = 0.0003886040358338505, best_loss = 0.00039279108750633895, model saved at 25\n",
      "val_losses[-1] = 0.0003815671370830387, best_loss = 0.0003886040358338505, model saved at 26\n",
      "val_losses[-1] = 0.0003803325234912336, best_loss = 0.0003815671370830387, model saved at 27\n",
      "val_losses[-1] = 0.00037668770528398454, best_loss = 0.0003803325234912336, model saved at 28\n",
      "val_losses[-1] = 0.0003737598308362067, best_loss = 0.00037668770528398454, model saved at 29\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006401030695997179, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006145193474367261, best_loss = 0.0006401030695997179, model saved at 1\n",
      "val_losses[-1] = 0.0006126387161202729, best_loss = 0.0006145193474367261, model saved at 2\n",
      "val_losses[-1] = 0.0006103642517700791, best_loss = 0.0006126387161202729, model saved at 3\n",
      "val_losses[-1] = 0.0006086272769607604, best_loss = 0.0006103642517700791, model saved at 4\n",
      "val_losses[-1] = 0.0006080237799324095, best_loss = 0.0006086272769607604, model saved at 5\n",
      "val_losses[-1] = 0.0006046481430530548, best_loss = 0.0006080237799324095, model saved at 7\n",
      "val_losses[-1] = 0.0006003949092701077, best_loss = 0.0006046481430530548, model saved at 9\n",
      "val_losses[-1] = 0.0005982181173749268, best_loss = 0.0006003949092701077, model saved at 11\n",
      "val_losses[-1] = 0.0005952342180535197, best_loss = 0.0005982181173749268, model saved at 12\n",
      "val_losses[-1] = 0.0005926067824475467, best_loss = 0.0005952342180535197, model saved at 13\n",
      "val_losses[-1] = 0.0005910894251428545, best_loss = 0.0005926067824475467, model saved at 14\n",
      "val_losses[-1] = 0.0005888562882319093, best_loss = 0.0005910894251428545, model saved at 16\n",
      "val_losses[-1] = 0.0005875039496459067, best_loss = 0.0005888562882319093, model saved at 17\n",
      "val_losses[-1] = 0.0005867687868885696, best_loss = 0.0005875039496459067, model saved at 18\n",
      "val_losses[-1] = 0.0005865755374543369, best_loss = 0.0005867687868885696, model saved at 19\n",
      "val_losses[-1] = 0.0005849756416864693, best_loss = 0.0005865755374543369, model saved at 20\n",
      "val_losses[-1] = 0.0005832225433550775, best_loss = 0.0005849756416864693, model saved at 21\n",
      "val_losses[-1] = 0.0005823810352012515, best_loss = 0.0005832225433550775, model saved at 22\n",
      "val_losses[-1] = 0.0005820406950078905, best_loss = 0.0005823810352012515, model saved at 23\n",
      "val_losses[-1] = 0.0005644104676321149, best_loss = 0.0005820406950078905, model saved at 24\n",
      "val_losses[-1] = 0.0004376489669084549, best_loss = 0.0005644104676321149, model saved at 25\n",
      "val_losses[-1] = 0.0004115686460863799, best_loss = 0.0004376489669084549, model saved at 26\n",
      "val_losses[-1] = 0.0004000184708274901, best_loss = 0.0004115686460863799, model saved at 27\n",
      "val_losses[-1] = 0.0003841255384031683, best_loss = 0.0004000184708274901, model saved at 29\n",
      "iter 4...\n",
      "val_losses[-1] = 0.000624839507509023, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006185316015034914, best_loss = 0.000624839507509023, model saved at 1\n",
      "val_losses[-1] = 0.0006163205252960324, best_loss = 0.0006185316015034914, model saved at 2\n",
      "val_losses[-1] = 0.000613081210758537, best_loss = 0.0006163205252960324, model saved at 5\n",
      "val_losses[-1] = 0.0006090837414376438, best_loss = 0.000613081210758537, model saved at 6\n",
      "val_losses[-1] = 0.0006077889120206237, best_loss = 0.0006090837414376438, model saved at 7\n",
      "val_losses[-1] = 0.0006064864574000239, best_loss = 0.0006077889120206237, model saved at 8\n",
      "val_losses[-1] = 0.0006063862820155919, best_loss = 0.0006064864574000239, model saved at 9\n",
      "val_losses[-1] = 0.000605578999966383, best_loss = 0.0006063862820155919, model saved at 10\n",
      "val_losses[-1] = 0.0006033697864040732, best_loss = 0.000605578999966383, model saved at 11\n",
      "val_losses[-1] = 0.0006024246686138213, best_loss = 0.0006033697864040732, model saved at 12\n",
      "val_losses[-1] = 0.0005573209491558373, best_loss = 0.0006024246686138213, model saved at 13\n",
      "val_losses[-1] = 0.0004614904464688152, best_loss = 0.0005573209491558373, model saved at 14\n",
      "val_losses[-1] = 0.00042343512177467346, best_loss = 0.0004614904464688152, model saved at 15\n",
      "val_losses[-1] = 0.00040111117414198816, best_loss = 0.00042343512177467346, model saved at 16\n",
      "val_losses[-1] = 0.00038372320705093443, best_loss = 0.00040111117414198816, model saved at 18\n",
      "val_losses[-1] = 0.00038203943404369056, best_loss = 0.00038372320705093443, model saved at 20\n",
      "val_losses[-1] = 0.0003787917084991932, best_loss = 0.00038203943404369056, model saved at 21\n",
      "val_losses[-1] = 0.0003734584024641663, best_loss = 0.0003787917084991932, model saved at 22\n",
      "val_losses[-1] = 0.00037128565600141883, best_loss = 0.0003734584024641663, model saved at 24\n",
      "val_losses[-1] = 0.0003614132874645293, best_loss = 0.00037128565600141883, model saved at 28\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006302541587501764, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006276531494222581, best_loss = 0.0006302541587501764, model saved at 1\n",
      "val_losses[-1] = 0.000625702494289726, best_loss = 0.0006276531494222581, model saved at 2\n",
      "val_losses[-1] = 0.0006251959130167961, best_loss = 0.000625702494289726, model saved at 3\n",
      "val_losses[-1] = 0.0006244624964892864, best_loss = 0.0006251959130167961, model saved at 4\n",
      "val_losses[-1] = 0.000623987871222198, best_loss = 0.0006244624964892864, model saved at 5\n",
      "val_losses[-1] = 0.0006238000933080912, best_loss = 0.000623987871222198, model saved at 6\n",
      "val_losses[-1] = 0.0006084449705667794, best_loss = 0.0006238000933080912, model saved at 8\n",
      "val_losses[-1] = 0.0005936333909630775, best_loss = 0.0006084449705667794, model saved at 9\n",
      "val_losses[-1] = 0.000565079681109637, best_loss = 0.0005936333909630775, model saved at 11\n",
      "val_losses[-1] = 0.000558770087081939, best_loss = 0.000565079681109637, model saved at 12\n",
      "val_losses[-1] = 0.0005487437592819333, best_loss = 0.000558770087081939, model saved at 13\n",
      "val_losses[-1] = 0.000540121051017195, best_loss = 0.0005487437592819333, model saved at 14\n",
      "val_losses[-1] = 0.0005311698187142611, best_loss = 0.000540121051017195, model saved at 15\n",
      "val_losses[-1] = 0.0005251708789728582, best_loss = 0.0005311698187142611, model saved at 16\n",
      "val_losses[-1] = 0.0005211136303842068, best_loss = 0.0005251708789728582, model saved at 18\n",
      "val_losses[-1] = 0.00016023799253161997, best_loss = 0.0005211136303842068, model saved at 19\n",
      "val_losses[-1] = 0.00015996642468962818, best_loss = 0.00016023799253161997, model saved at 20\n",
      "val_losses[-1] = 0.00014690218085888773, best_loss = 0.00015996642468962818, model saved at 21\n",
      "val_losses[-1] = 0.00014244749036151916, best_loss = 0.00014690218085888773, model saved at 23\n",
      "val_losses[-1] = 0.0001369087112834677, best_loss = 0.00014244749036151916, model saved at 25\n",
      "val_losses[-1] = 0.000132782879518345, best_loss = 0.0001369087112834677, model saved at 27\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0008217146969400346, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000615644094068557, best_loss = 0.0008217146969400346, model saved at 1\n",
      "val_losses[-1] = 0.0005844291881658137, best_loss = 0.000615644094068557, model saved at 2\n",
      "val_losses[-1] = 0.0005716612213291228, best_loss = 0.0005844291881658137, model saved at 3\n",
      "val_losses[-1] = 0.0005671136896125972, best_loss = 0.0005716612213291228, model saved at 4\n",
      "val_losses[-1] = 0.0005633808905258775, best_loss = 0.0005671136896125972, model saved at 5\n",
      "val_losses[-1] = 0.0005612290697172284, best_loss = 0.0005633808905258775, model saved at 6\n",
      "val_losses[-1] = 0.0005599413416348398, best_loss = 0.0005612290697172284, model saved at 7\n",
      "val_losses[-1] = 0.000546760973520577, best_loss = 0.0005599413416348398, model saved at 8\n",
      "val_losses[-1] = 0.0005429730517789721, best_loss = 0.000546760973520577, model saved at 9\n",
      "val_losses[-1] = 0.0005271834670566022, best_loss = 0.0005429730517789721, model saved at 10\n",
      "val_losses[-1] = 0.00017615823890082538, best_loss = 0.0005271834670566022, model saved at 11\n",
      "val_losses[-1] = 0.00015058771532494575, best_loss = 0.00017615823890082538, model saved at 12\n",
      "val_losses[-1] = 0.00014929343888070434, best_loss = 0.00015058771532494575, model saved at 13\n",
      "val_losses[-1] = 0.00014188818749971688, best_loss = 0.00014929343888070434, model saved at 16\n",
      "val_losses[-1] = 0.00013887193927075714, best_loss = 0.00014188818749971688, model saved at 17\n",
      "val_losses[-1] = 0.00013671164924744517, best_loss = 0.00013887193927075714, model saved at 20\n",
      "iter 2...\n",
      "val_losses[-1] = 0.000709771178662777, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006086054490879178, best_loss = 0.000709771178662777, model saved at 2\n",
      "val_losses[-1] = 0.0005914203939028084, best_loss = 0.0006086054490879178, model saved at 4\n",
      "val_losses[-1] = 0.0005795119795948267, best_loss = 0.0005914203939028084, model saved at 6\n",
      "val_losses[-1] = 0.0005770635907538235, best_loss = 0.0005795119795948267, model saved at 7\n",
      "val_losses[-1] = 0.0005625490448437631, best_loss = 0.0005770635907538235, model saved at 8\n",
      "val_losses[-1] = 0.00020366332319099456, best_loss = 0.0005625490448437631, model saved at 9\n",
      "val_losses[-1] = 0.00016239259275607765, best_loss = 0.00020366332319099456, model saved at 10\n",
      "val_losses[-1] = 0.00014531308261211962, best_loss = 0.00016239259275607765, model saved at 11\n",
      "val_losses[-1] = 0.00014465345884673297, best_loss = 0.00014531308261211962, model saved at 12\n",
      "val_losses[-1] = 0.00014179505524225533, best_loss = 0.00014465345884673297, model saved at 14\n",
      "val_losses[-1] = 0.00013383323675952852, best_loss = 0.00014179505524225533, model saved at 15\n",
      "val_losses[-1] = 0.00013291813957039267, best_loss = 0.00013383323675952852, model saved at 25\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006072739488445222, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0001663793227635324, best_loss = 0.0006072739488445222, model saved at 1\n",
      "val_losses[-1] = 0.00014542108692694455, best_loss = 0.0001663793227635324, model saved at 2\n",
      "val_losses[-1] = 0.00013670144835487008, best_loss = 0.00014542108692694455, model saved at 4\n",
      "val_losses[-1] = 0.00012873676314484328, best_loss = 0.00013670144835487008, model saved at 5\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006169120315462351, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000600518484134227, best_loss = 0.0006169120315462351, model saved at 1\n",
      "val_losses[-1] = 0.0005711446283385158, best_loss = 0.000600518484134227, model saved at 2\n",
      "val_losses[-1] = 0.0005547368782572448, best_loss = 0.0005711446283385158, model saved at 3\n",
      "val_losses[-1] = 0.0005412542959675193, best_loss = 0.0005547368782572448, model saved at 4\n",
      "val_losses[-1] = 0.00022625710698775947, best_loss = 0.0005412542959675193, model saved at 5\n",
      "val_losses[-1] = 0.00015780716785229743, best_loss = 0.00022625710698775947, model saved at 6\n",
      "val_losses[-1] = 0.0001402633060934022, best_loss = 0.00015780716785229743, model saved at 8\n",
      "val_losses[-1] = 0.00013787372154183686, best_loss = 0.0001402633060934022, model saved at 13\n",
      "val_losses[-1] = 0.00013401843898463994, best_loss = 0.00013787372154183686, model saved at 14\n",
      "val_losses[-1] = 0.0001311341766268015, best_loss = 0.00013401843898463994, model saved at 18\n",
      "val_losses[-1] = 0.00013100421347189695, best_loss = 0.0001311341766268015, model saved at 23\n",
      "val_losses[-1] = 0.00012870201317127794, best_loss = 0.00013100421347189695, model saved at 28\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006587285897694528, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006369594484567642, best_loss = 0.0006587285897694528, model saved at 1\n",
      "val_losses[-1] = 0.00010898539767367765, best_loss = 0.0006369594484567642, model saved at 2\n",
      "val_losses[-1] = 7.806374924257398e-05, best_loss = 0.00010898539767367765, model saved at 3\n",
      "val_losses[-1] = 7.61520495871082e-05, best_loss = 7.806374924257398e-05, model saved at 5\n",
      "val_losses[-1] = 7.441729394486174e-05, best_loss = 7.61520495871082e-05, model saved at 13\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006509096128866076, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005950359045527875, best_loss = 0.0006509096128866076, model saved at 1\n",
      "val_losses[-1] = 0.0005699769244529307, best_loss = 0.0005950359045527875, model saved at 3\n",
      "val_losses[-1] = 0.0005439594388008118, best_loss = 0.0005699769244529307, model saved at 4\n",
      "val_losses[-1] = 0.0005183466710150242, best_loss = 0.0005439594388008118, model saved at 5\n",
      "val_losses[-1] = 0.0005104735027998686, best_loss = 0.0005183466710150242, model saved at 6\n",
      "val_losses[-1] = 0.000497537839692086, best_loss = 0.0005104735027998686, model saved at 7\n",
      "val_losses[-1] = 0.00012722302926704288, best_loss = 0.000497537839692086, model saved at 8\n",
      "val_losses[-1] = 9.789592149900272e-05, best_loss = 0.00012722302926704288, model saved at 9\n",
      "val_losses[-1] = 8.279159374069422e-05, best_loss = 9.789592149900272e-05, model saved at 10\n",
      "val_losses[-1] = 7.841213664505631e-05, best_loss = 8.279159374069422e-05, model saved at 15\n",
      "val_losses[-1] = 7.722809095866978e-05, best_loss = 7.841213664505631e-05, model saved at 25\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0008091424242593348, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000601629726588726, best_loss = 0.0008091424242593348, model saved at 1\n",
      "val_losses[-1] = 0.0005800469662062824, best_loss = 0.000601629726588726, model saved at 2\n",
      "val_losses[-1] = 0.0005426358547993004, best_loss = 0.0005800469662062824, model saved at 3\n",
      "val_losses[-1] = 0.0005339389899745584, best_loss = 0.0005426358547993004, model saved at 4\n",
      "val_losses[-1] = 0.0005050257313996553, best_loss = 0.0005339389899745584, model saved at 5\n",
      "val_losses[-1] = 0.0004698722332250327, best_loss = 0.0005050257313996553, model saved at 6\n",
      "val_losses[-1] = 0.00045183353358879685, best_loss = 0.0004698722332250327, model saved at 7\n",
      "val_losses[-1] = 0.000295830424875021, best_loss = 0.00045183353358879685, model saved at 8\n",
      "val_losses[-1] = 0.00010835942521225661, best_loss = 0.000295830424875021, model saved at 9\n",
      "val_losses[-1] = 9.83889403869398e-05, best_loss = 0.00010835942521225661, model saved at 10\n",
      "val_losses[-1] = 8.342724322574213e-05, best_loss = 9.83889403869398e-05, model saved at 11\n",
      "val_losses[-1] = 7.898260810179636e-05, best_loss = 8.342724322574213e-05, model saved at 14\n",
      "val_losses[-1] = 7.648078462807462e-05, best_loss = 7.898260810179636e-05, model saved at 16\n",
      "val_losses[-1] = 7.543115498265252e-05, best_loss = 7.648078462807462e-05, model saved at 17\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0004420910554472357, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00011232936230953783, best_loss = 0.0004420910554472357, model saved at 1\n",
      "val_losses[-1] = 8.95059056347236e-05, best_loss = 0.00011232936230953783, model saved at 2\n",
      "val_losses[-1] = 7.844623178243637e-05, best_loss = 8.95059056347236e-05, model saved at 3\n",
      "val_losses[-1] = 7.548810390289873e-05, best_loss = 7.844623178243637e-05, model saved at 20\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006061519961804152, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005825093830935657, best_loss = 0.0006061519961804152, model saved at 1\n",
      "val_losses[-1] = 0.0005631623789668083, best_loss = 0.0005825093830935657, model saved at 2\n",
      "val_losses[-1] = 0.0005488472525030375, best_loss = 0.0005631623789668083, model saved at 3\n",
      "val_losses[-1] = 0.0005323294899426401, best_loss = 0.0005488472525030375, model saved at 4\n",
      "val_losses[-1] = 0.0005144831957295537, best_loss = 0.0005323294899426401, model saved at 5\n",
      "val_losses[-1] = 0.0004962654202245176, best_loss = 0.0005144831957295537, model saved at 6\n",
      "val_losses[-1] = 0.0004773840482812375, best_loss = 0.0004962654202245176, model saved at 7\n",
      "val_losses[-1] = 9.327767475042492e-05, best_loss = 0.0004773840482812375, model saved at 8\n",
      "val_losses[-1] = 8.965434244601056e-05, best_loss = 9.327767475042492e-05, model saved at 9\n",
      "val_losses[-1] = 8.520516712451354e-05, best_loss = 8.965434244601056e-05, model saved at 10\n",
      "val_losses[-1] = 8.190510561689734e-05, best_loss = 8.520516712451354e-05, model saved at 11\n",
      "val_losses[-1] = 7.983397517818958e-05, best_loss = 8.190510561689734e-05, model saved at 12\n",
      "val_losses[-1] = 7.825312786735594e-05, best_loss = 7.983397517818958e-05, model saved at 14\n",
      "val_losses[-1] = 7.672765786992386e-05, best_loss = 7.825312786735594e-05, model saved at 15\n",
      "val_losses[-1] = 7.517902849940583e-05, best_loss = 7.672765786992386e-05, model saved at 21\n",
      "(1, 0.4)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006242650561034679, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006234374595806003, best_loss = 0.0006242650561034679, model saved at 1\n",
      "val_losses[-1] = 0.0006233868771232665, best_loss = 0.0006234374595806003, model saved at 4\n",
      "val_losses[-1] = 0.0006215265020728111, best_loss = 0.0006233868771232665, model saved at 5\n",
      "val_losses[-1] = 0.000601450155954808, best_loss = 0.0006215265020728111, model saved at 6\n",
      "val_losses[-1] = 0.0005242577753961086, best_loss = 0.000601450155954808, model saved at 7\n",
      "val_losses[-1] = 0.00043787527829408646, best_loss = 0.0005242577753961086, model saved at 8\n",
      "val_losses[-1] = 0.0004070849681738764, best_loss = 0.00043787527829408646, model saved at 9\n",
      "val_losses[-1] = 0.0003959585737902671, best_loss = 0.0004070849681738764, model saved at 10\n",
      "val_losses[-1] = 0.0003829563211183995, best_loss = 0.0003959585737902671, model saved at 11\n",
      "val_losses[-1] = 0.00037032304680906236, best_loss = 0.0003829563211183995, model saved at 12\n",
      "val_losses[-1] = 0.0003670401929412037, best_loss = 0.00037032304680906236, model saved at 15\n",
      "val_losses[-1] = 0.00036216690205037594, best_loss = 0.0003670401929412037, model saved at 19\n",
      "val_losses[-1] = 0.0003608330152928829, best_loss = 0.00036216690205037594, model saved at 25\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006332704797387123, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006221525254659355, best_loss = 0.0006332704797387123, model saved at 1\n",
      "val_losses[-1] = 0.000616108940448612, best_loss = 0.0006221525254659355, model saved at 2\n",
      "val_losses[-1] = 0.0006041312008164823, best_loss = 0.000616108940448612, model saved at 3\n",
      "val_losses[-1] = 0.0005989136407151818, best_loss = 0.0006041312008164823, model saved at 4\n",
      "val_losses[-1] = 0.0005914050270803273, best_loss = 0.0005989136407151818, model saved at 5\n",
      "val_losses[-1] = 0.0005579630378633738, best_loss = 0.0005914050270803273, model saved at 6\n",
      "val_losses[-1] = 0.000494811509270221, best_loss = 0.0005579630378633738, model saved at 7\n",
      "val_losses[-1] = 0.00043884001206606627, best_loss = 0.000494811509270221, model saved at 8\n",
      "val_losses[-1] = 0.0004017736064270139, best_loss = 0.00043884001206606627, model saved at 9\n",
      "val_losses[-1] = 0.0003966665535699576, best_loss = 0.0004017736064270139, model saved at 10\n",
      "val_losses[-1] = 0.00038537909858860075, best_loss = 0.0003966665535699576, model saved at 11\n",
      "val_losses[-1] = 0.0003768011520151049, best_loss = 0.00038537909858860075, model saved at 12\n",
      "val_losses[-1] = 0.0003731427132152021, best_loss = 0.0003768011520151049, model saved at 13\n",
      "val_losses[-1] = 0.00037155806785449386, best_loss = 0.0003731427132152021, model saved at 15\n",
      "val_losses[-1] = 0.00036546087358146906, best_loss = 0.00037155806785449386, model saved at 19\n",
      "val_losses[-1] = 0.00036518057459034026, best_loss = 0.00036546087358146906, model saved at 25\n",
      "val_losses[-1] = 0.0003637433983385563, best_loss = 0.00036518057459034026, model saved at 27\n",
      "iter 2...\n",
      "val_losses[-1] = 0.000700745265930891, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006373684736900032, best_loss = 0.000700745265930891, model saved at 1\n",
      "val_losses[-1] = 0.0006235481705516577, best_loss = 0.0006373684736900032, model saved at 3\n",
      "val_losses[-1] = 0.0006151945563033223, best_loss = 0.0006235481705516577, model saved at 4\n",
      "val_losses[-1] = 0.000608745904173702, best_loss = 0.0006151945563033223, model saved at 5\n",
      "val_losses[-1] = 0.000607303052674979, best_loss = 0.000608745904173702, model saved at 6\n",
      "val_losses[-1] = 0.0006034296820871532, best_loss = 0.000607303052674979, model saved at 7\n",
      "val_losses[-1] = 0.0006009749486111104, best_loss = 0.0006034296820871532, model saved at 8\n",
      "val_losses[-1] = 0.0005968354525975883, best_loss = 0.0006009749486111104, model saved at 10\n",
      "val_losses[-1] = 0.000596199301071465, best_loss = 0.0005968354525975883, model saved at 11\n",
      "val_losses[-1] = 0.0005835292395204306, best_loss = 0.000596199301071465, model saved at 12\n",
      "val_losses[-1] = 0.00048480575787834823, best_loss = 0.0005835292395204306, model saved at 13\n",
      "val_losses[-1] = 0.0004219230031594634, best_loss = 0.00048480575787834823, model saved at 14\n",
      "val_losses[-1] = 0.000403329060645774, best_loss = 0.0004219230031594634, model saved at 15\n",
      "val_losses[-1] = 0.00039831327740103006, best_loss = 0.000403329060645774, model saved at 16\n",
      "val_losses[-1] = 0.00039185196510516107, best_loss = 0.00039831327740103006, model saved at 17\n",
      "val_losses[-1] = 0.0003830557980109006, best_loss = 0.00039185196510516107, model saved at 20\n",
      "val_losses[-1] = 0.0003792916249949485, best_loss = 0.0003830557980109006, model saved at 22\n",
      "val_losses[-1] = 0.0003784623695537448, best_loss = 0.0003792916249949485, model saved at 25\n",
      "val_losses[-1] = 0.00037120378692634404, best_loss = 0.0003784623695537448, model saved at 26\n",
      "val_losses[-1] = 0.00037048428202979267, best_loss = 0.00037120378692634404, model saved at 27\n",
      "val_losses[-1] = 0.00036713501322083175, best_loss = 0.00037048428202979267, model saved at 28\n",
      "val_losses[-1] = 0.00036340963561087847, best_loss = 0.00036713501322083175, model saved at 29\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0005103216972202063, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00041927851270884275, best_loss = 0.0005103216972202063, model saved at 1\n",
      "val_losses[-1] = 0.0003918235597666353, best_loss = 0.00041927851270884275, model saved at 2\n",
      "val_losses[-1] = 0.0003835394454654306, best_loss = 0.0003918235597666353, model saved at 4\n",
      "val_losses[-1] = 0.00038081634556874633, best_loss = 0.0003835394454654306, model saved at 5\n",
      "val_losses[-1] = 0.00037474269629456103, best_loss = 0.00038081634556874633, model saved at 7\n",
      "val_losses[-1] = 0.00037324108416214585, best_loss = 0.00037474269629456103, model saved at 8\n",
      "val_losses[-1] = 0.00036837501102127135, best_loss = 0.00037324108416214585, model saved at 9\n",
      "val_losses[-1] = 0.0003631642321124673, best_loss = 0.00036837501102127135, model saved at 10\n",
      "val_losses[-1] = 0.0003612527798395604, best_loss = 0.0003631642321124673, model saved at 15\n",
      "val_losses[-1] = 0.0003600511699914932, best_loss = 0.0003612527798395604, model saved at 21\n",
      "val_losses[-1] = 0.0003578547912184149, best_loss = 0.0003600511699914932, model saved at 29\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006233672029338777, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000616727105807513, best_loss = 0.0006233672029338777, model saved at 1\n",
      "val_losses[-1] = 0.0006111155380494893, best_loss = 0.000616727105807513, model saved at 2\n",
      "val_losses[-1] = 0.0006090766983106732, best_loss = 0.0006111155380494893, model saved at 3\n",
      "val_losses[-1] = 0.0006073865806683898, best_loss = 0.0006090766983106732, model saved at 4\n",
      "val_losses[-1] = 0.0006067012436687946, best_loss = 0.0006073865806683898, model saved at 5\n",
      "val_losses[-1] = 0.0006038590217940509, best_loss = 0.0006067012436687946, model saved at 6\n",
      "val_losses[-1] = 0.0006022626184858382, best_loss = 0.0006038590217940509, model saved at 7\n",
      "val_losses[-1] = 0.0006015788530930877, best_loss = 0.0006022626184858382, model saved at 8\n",
      "val_losses[-1] = 0.0006005563191138208, best_loss = 0.0006015788530930877, model saved at 9\n",
      "val_losses[-1] = 0.00043917333823628724, best_loss = 0.0006005563191138208, model saved at 10\n",
      "val_losses[-1] = 0.000395463575841859, best_loss = 0.00043917333823628724, model saved at 11\n",
      "val_losses[-1] = 0.00038217956898733974, best_loss = 0.000395463575841859, model saved at 12\n",
      "val_losses[-1] = 0.000375687814084813, best_loss = 0.00038217956898733974, model saved at 15\n",
      "val_losses[-1] = 0.00037409208016470075, best_loss = 0.000375687814084813, model saved at 22\n",
      "val_losses[-1] = 0.0003736307844519615, best_loss = 0.00037409208016470075, model saved at 26\n",
      "val_losses[-1] = 0.000366174936061725, best_loss = 0.0003736307844519615, model saved at 28\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006275305058807135, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006234407192096114, best_loss = 0.0006275305058807135, model saved at 1\n",
      "val_losses[-1] = 0.0006229321006685495, best_loss = 0.0006234407192096114, model saved at 3\n",
      "val_losses[-1] = 0.000622752879280597, best_loss = 0.0006229321006685495, model saved at 4\n",
      "val_losses[-1] = 0.0006224809330888093, best_loss = 0.000622752879280597, model saved at 5\n",
      "val_losses[-1] = 0.0005958876572549343, best_loss = 0.0006224809330888093, model saved at 6\n",
      "val_losses[-1] = 0.0005824102554470301, best_loss = 0.0005958876572549343, model saved at 7\n",
      "val_losses[-1] = 0.0005727937677875161, best_loss = 0.0005824102554470301, model saved at 8\n",
      "val_losses[-1] = 0.0005678259185515344, best_loss = 0.0005727937677875161, model saved at 9\n",
      "val_losses[-1] = 0.000492471968755126, best_loss = 0.0005678259185515344, model saved at 10\n",
      "val_losses[-1] = 0.0001789098314475268, best_loss = 0.000492471968755126, model saved at 11\n",
      "val_losses[-1] = 0.0001493449235567823, best_loss = 0.0001789098314475268, model saved at 12\n",
      "val_losses[-1] = 0.00014397542690858245, best_loss = 0.0001493449235567823, model saved at 13\n",
      "val_losses[-1] = 0.00014288260717876256, best_loss = 0.00014397542690858245, model saved at 14\n",
      "val_losses[-1] = 0.00013990316074341536, best_loss = 0.00014288260717876256, model saved at 16\n",
      "val_losses[-1] = 0.00013525752001442015, best_loss = 0.00013990316074341536, model saved at 17\n",
      "val_losses[-1] = 0.000135181107907556, best_loss = 0.00013525752001442015, model saved at 18\n",
      "val_losses[-1] = 0.0001327112113358453, best_loss = 0.000135181107907556, model saved at 27\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006275875493884087, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005965407472103834, best_loss = 0.0006275875493884087, model saved at 1\n",
      "val_losses[-1] = 0.0005668686935678124, best_loss = 0.0005965407472103834, model saved at 2\n",
      "val_losses[-1] = 0.0005410764715634286, best_loss = 0.0005668686935678124, model saved at 3\n",
      "val_losses[-1] = 0.0005368302809074521, best_loss = 0.0005410764715634286, model saved at 4\n",
      "val_losses[-1] = 0.0005318680196069181, best_loss = 0.0005368302809074521, model saved at 6\n",
      "val_losses[-1] = 0.0005228373338468373, best_loss = 0.0005318680196069181, model saved at 7\n",
      "val_losses[-1] = 0.0005215019336901605, best_loss = 0.0005228373338468373, model saved at 8\n",
      "val_losses[-1] = 0.0005182753666304052, best_loss = 0.0005215019336901605, model saved at 9\n",
      "val_losses[-1] = 0.0005179063300602138, best_loss = 0.0005182753666304052, model saved at 10\n",
      "val_losses[-1] = 0.0005101491115055978, best_loss = 0.0005179063300602138, model saved at 11\n",
      "val_losses[-1] = 0.00022788198839407414, best_loss = 0.0005101491115055978, model saved at 12\n",
      "val_losses[-1] = 0.00015566361253149807, best_loss = 0.00022788198839407414, model saved at 13\n",
      "val_losses[-1] = 0.00015175665612332523, best_loss = 0.00015566361253149807, model saved at 15\n",
      "val_losses[-1] = 0.00014714107965119183, best_loss = 0.00015175665612332523, model saved at 16\n",
      "val_losses[-1] = 0.0001427786919521168, best_loss = 0.00014714107965119183, model saved at 17\n",
      "val_losses[-1] = 0.00014193946844898164, best_loss = 0.0001427786919521168, model saved at 18\n",
      "val_losses[-1] = 0.00014024620759300888, best_loss = 0.00014193946844898164, model saved at 20\n",
      "val_losses[-1] = 0.0001389758981531486, best_loss = 0.00014024620759300888, model saved at 24\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007389069069176912, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006665564142167568, best_loss = 0.0007389069069176912, model saved at 1\n",
      "val_losses[-1] = 0.0005873123882338405, best_loss = 0.0006665564142167568, model saved at 2\n",
      "val_losses[-1] = 0.0005726200179196894, best_loss = 0.0005873123882338405, model saved at 3\n",
      "val_losses[-1] = 0.0005186238558962941, best_loss = 0.0005726200179196894, model saved at 4\n",
      "val_losses[-1] = 0.00020089111058041453, best_loss = 0.0005186238558962941, model saved at 5\n",
      "val_losses[-1] = 0.00015767240256536752, best_loss = 0.00020089111058041453, model saved at 6\n",
      "val_losses[-1] = 0.00015099288430064917, best_loss = 0.00015767240256536752, model saved at 7\n",
      "val_losses[-1] = 0.00013941848010290414, best_loss = 0.00015099288430064917, model saved at 8\n",
      "val_losses[-1] = 0.00013328871864359826, best_loss = 0.00013941848010290414, model saved at 11\n",
      "val_losses[-1] = 0.0001268110063392669, best_loss = 0.00013328871864359826, model saved at 14\n",
      "val_losses[-1] = 0.00012527394574135542, best_loss = 0.0001268110063392669, model saved at 15\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0005951612256467342, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00018017466936726123, best_loss = 0.0005951612256467342, model saved at 1\n",
      "val_losses[-1] = 0.00015368718595709652, best_loss = 0.00018017466936726123, model saved at 2\n",
      "val_losses[-1] = 0.00014114972145762295, best_loss = 0.00015368718595709652, model saved at 4\n",
      "val_losses[-1] = 0.00013263527944218367, best_loss = 0.00014114972145762295, model saved at 5\n",
      "val_losses[-1] = 0.00013214867794886231, best_loss = 0.00013263527944218367, model saved at 8\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006125150248408318, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005912435590289533, best_loss = 0.0006125150248408318, model saved at 1\n",
      "val_losses[-1] = 0.00016002909978851676, best_loss = 0.0005912435590289533, model saved at 2\n",
      "val_losses[-1] = 0.00014570829807780683, best_loss = 0.00016002909978851676, model saved at 3\n",
      "val_losses[-1] = 0.00013866470544598997, best_loss = 0.00014570829807780683, model saved at 5\n",
      "val_losses[-1] = 0.00013866381777916104, best_loss = 0.00013866470544598997, model saved at 7\n",
      "val_losses[-1] = 0.0001336701971013099, best_loss = 0.00013866381777916104, model saved at 8\n",
      "val_losses[-1] = 0.00013360244338400662, best_loss = 0.0001336701971013099, model saved at 14\n",
      "val_losses[-1] = 0.00013096533075440675, best_loss = 0.00013360244338400662, model saved at 16\n",
      "val_losses[-1] = 0.00013093689631205052, best_loss = 0.00013096533075440675, model saved at 18\n",
      "val_losses[-1] = 0.00012988163507543504, best_loss = 0.00013093689631205052, model saved at 23\n",
      "val_losses[-1] = 0.00012937825522385538, best_loss = 0.00012988163507543504, model saved at 25\n",
      "val_losses[-1] = 0.00012436976248864084, best_loss = 0.00012937825522385538, model saved at 28\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006499849259853363, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000625754299107939, best_loss = 0.0006499849259853363, model saved at 1\n",
      "val_losses[-1] = 0.00020562068675644696, best_loss = 0.000625754299107939, model saved at 2\n",
      "val_losses[-1] = 8.018837979761884e-05, best_loss = 0.00020562068675644696, model saved at 3\n",
      "val_losses[-1] = 7.698682748014107e-05, best_loss = 8.018837979761884e-05, model saved at 5\n",
      "val_losses[-1] = 7.652644126210362e-05, best_loss = 7.698682748014107e-05, model saved at 7\n",
      "val_losses[-1] = 7.401011680485681e-05, best_loss = 7.652644126210362e-05, model saved at 13\n",
      "iter 1...\n",
      "val_losses[-1] = 0.000642661820165813, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005823852261528373, best_loss = 0.000642661820165813, model saved at 1\n",
      "val_losses[-1] = 0.0005581845180131495, best_loss = 0.0005823852261528373, model saved at 2\n",
      "val_losses[-1] = 0.0005229469970799983, best_loss = 0.0005581845180131495, model saved at 3\n",
      "val_losses[-1] = 0.0005023854901082814, best_loss = 0.0005229469970799983, model saved at 4\n",
      "val_losses[-1] = 0.0004838465538341552, best_loss = 0.0005023854901082814, model saved at 5\n",
      "val_losses[-1] = 0.000467661302536726, best_loss = 0.0004838465538341552, model saved at 6\n",
      "val_losses[-1] = 0.0004428013926371932, best_loss = 0.000467661302536726, model saved at 7\n",
      "val_losses[-1] = 0.0004412808921188116, best_loss = 0.0004428013926371932, model saved at 8\n",
      "val_losses[-1] = 0.0002337852492928505, best_loss = 0.0004412808921188116, model saved at 9\n",
      "val_losses[-1] = 9.213777229888365e-05, best_loss = 0.0002337852492928505, model saved at 10\n",
      "val_losses[-1] = 8.499404793838039e-05, best_loss = 9.213777229888365e-05, model saved at 11\n",
      "val_losses[-1] = 8.493825589539483e-05, best_loss = 8.499404793838039e-05, model saved at 13\n",
      "val_losses[-1] = 7.898205512901768e-05, best_loss = 8.493825589539483e-05, model saved at 15\n",
      "val_losses[-1] = 7.724195893388242e-05, best_loss = 7.898205512901768e-05, model saved at 25\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0008729302790015936, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00047631055349484086, best_loss = 0.0008729302790015936, model saved at 1\n",
      "val_losses[-1] = 0.00022187258582562208, best_loss = 0.00047631055349484086, model saved at 2\n",
      "val_losses[-1] = 0.000107481588202063, best_loss = 0.00022187258582562208, model saved at 3\n",
      "val_losses[-1] = 9.850557398749515e-05, best_loss = 0.000107481588202063, model saved at 4\n",
      "val_losses[-1] = 8.584652096033096e-05, best_loss = 9.850557398749515e-05, model saved at 5\n",
      "val_losses[-1] = 8.458357478957623e-05, best_loss = 8.584652096033096e-05, model saved at 10\n",
      "val_losses[-1] = 8.062169945333153e-05, best_loss = 8.458357478957623e-05, model saved at 14\n",
      "val_losses[-1] = 8.035661448957399e-05, best_loss = 8.062169945333153e-05, model saved at 16\n",
      "val_losses[-1] = 7.825122156646103e-05, best_loss = 8.035661448957399e-05, model saved at 17\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006401303107850254, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00010297227709088475, best_loss = 0.0006401303107850254, model saved at 1\n",
      "val_losses[-1] = 8.61770095070824e-05, best_loss = 0.00010297227709088475, model saved at 2\n",
      "val_losses[-1] = 8.009414159459993e-05, best_loss = 8.61770095070824e-05, model saved at 3\n",
      "val_losses[-1] = 7.614314381498843e-05, best_loss = 8.009414159459993e-05, model saved at 9\n",
      "val_losses[-1] = 7.516051118727773e-05, best_loss = 7.614314381498843e-05, model saved at 20\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006020608125254512, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000570570002309978, best_loss = 0.0006020608125254512, model saved at 1\n",
      "val_losses[-1] = 0.0005527878529392183, best_loss = 0.000570570002309978, model saved at 2\n",
      "val_losses[-1] = 0.000531169178429991, best_loss = 0.0005527878529392183, model saved at 3\n",
      "val_losses[-1] = 0.00011040504614356905, best_loss = 0.000531169178429991, model saved at 4\n",
      "val_losses[-1] = 7.465945236617699e-05, best_loss = 0.00011040504614356905, model saved at 5\n",
      "val_losses[-1] = 7.296090188901871e-05, best_loss = 7.465945236617699e-05, model saved at 21\n",
      "(1, 0.3)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006389550981111825, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006189222331158817, best_loss = 0.0006389550981111825, model saved at 1\n",
      "val_losses[-1] = 0.0006157693569548428, best_loss = 0.0006189222331158817, model saved at 2\n",
      "val_losses[-1] = 0.000613757933024317, best_loss = 0.0006157693569548428, model saved at 3\n",
      "val_losses[-1] = 0.0005982479779049754, best_loss = 0.000613757933024317, model saved at 4\n",
      "val_losses[-1] = 0.0005844272091053426, best_loss = 0.0005982479779049754, model saved at 5\n",
      "val_losses[-1] = 0.0005024332203902304, best_loss = 0.0005844272091053426, model saved at 6\n",
      "val_losses[-1] = 0.00041596300434321165, best_loss = 0.0005024332203902304, model saved at 7\n",
      "val_losses[-1] = 0.0003854333481285721, best_loss = 0.00041596300434321165, model saved at 8\n",
      "val_losses[-1] = 0.000379923585569486, best_loss = 0.0003854333481285721, model saved at 9\n",
      "val_losses[-1] = 0.0003752234624698758, best_loss = 0.000379923585569486, model saved at 10\n",
      "val_losses[-1] = 0.00036935656680725515, best_loss = 0.0003752234624698758, model saved at 11\n",
      "val_losses[-1] = 0.000359921163180843, best_loss = 0.00036935656680725515, model saved at 12\n",
      "val_losses[-1] = 0.00035845881211571395, best_loss = 0.000359921163180843, model saved at 15\n",
      "val_losses[-1] = 0.00035718115395866334, best_loss = 0.00035845881211571395, model saved at 19\n",
      "val_losses[-1] = 0.00035542913246899843, best_loss = 0.00035718115395866334, model saved at 25\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006322829285636544, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005975965177640319, best_loss = 0.0006322829285636544, model saved at 1\n",
      "val_losses[-1] = 0.0004219631664454937, best_loss = 0.0005975965177640319, model saved at 2\n",
      "val_losses[-1] = 0.0003959693422075361, best_loss = 0.0004219631664454937, model saved at 3\n",
      "val_losses[-1] = 0.0003866499464493245, best_loss = 0.0003959693422075361, model saved at 5\n",
      "val_losses[-1] = 0.00037651037564501166, best_loss = 0.0003866499464493245, model saved at 6\n",
      "val_losses[-1] = 0.0003672502061817795, best_loss = 0.00037651037564501166, model saved at 7\n",
      "val_losses[-1] = 0.0003610329586081207, best_loss = 0.0003672502061817795, model saved at 9\n",
      "val_losses[-1] = 0.0003597258182708174, best_loss = 0.0003610329586081207, model saved at 13\n",
      "val_losses[-1] = 0.0003575955342967063, best_loss = 0.0003597258182708174, model saved at 22\n",
      "val_losses[-1] = 0.0003555081784725189, best_loss = 0.0003575955342967063, model saved at 25\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0006759798270650208, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006154708098620176, best_loss = 0.0006759798270650208, model saved at 1\n",
      "val_losses[-1] = 0.0006093530682846904, best_loss = 0.0006154708098620176, model saved at 2\n",
      "val_losses[-1] = 0.0005971817299723625, best_loss = 0.0006093530682846904, model saved at 4\n",
      "val_losses[-1] = 0.000592213065829128, best_loss = 0.0005971817299723625, model saved at 5\n",
      "val_losses[-1] = 0.0005902864504605532, best_loss = 0.000592213065829128, model saved at 6\n",
      "val_losses[-1] = 0.0005899944226257503, best_loss = 0.0005902864504605532, model saved at 7\n",
      "val_losses[-1] = 0.000588275317568332, best_loss = 0.0005899944226257503, model saved at 8\n",
      "val_losses[-1] = 0.0005877750809304416, best_loss = 0.000588275317568332, model saved at 9\n",
      "val_losses[-1] = 0.0005843032267875969, best_loss = 0.0005877750809304416, model saved at 10\n",
      "val_losses[-1] = 0.0004395268333610147, best_loss = 0.0005843032267875969, model saved at 11\n",
      "val_losses[-1] = 0.0003978234308306128, best_loss = 0.0004395268333610147, model saved at 12\n",
      "val_losses[-1] = 0.000391191802918911, best_loss = 0.0003978234308306128, model saved at 13\n",
      "val_losses[-1] = 0.0003701517707668245, best_loss = 0.000391191802918911, model saved at 14\n",
      "val_losses[-1] = 0.00036858991370536387, best_loss = 0.0003701517707668245, model saved at 23\n",
      "val_losses[-1] = 0.00036823845584876835, best_loss = 0.00036858991370536387, model saved at 25\n",
      "val_losses[-1] = 0.0003668634162750095, best_loss = 0.00036823845584876835, model saved at 26\n",
      "val_losses[-1] = 0.0003649546124506742, best_loss = 0.0003668634162750095, model saved at 27\n",
      "val_losses[-1] = 0.00036385550629347563, best_loss = 0.0003649546124506742, model saved at 28\n",
      "val_losses[-1] = 0.00036002349224872887, best_loss = 0.00036385550629347563, model saved at 29\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006567936507053673, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006158002070151269, best_loss = 0.0006567936507053673, model saved at 1\n",
      "val_losses[-1] = 0.0005758310435339808, best_loss = 0.0006158002070151269, model saved at 2\n",
      "val_losses[-1] = 0.0004961385275237262, best_loss = 0.0005758310435339808, model saved at 3\n",
      "val_losses[-1] = 0.0004254526284057647, best_loss = 0.0004961385275237262, model saved at 4\n",
      "val_losses[-1] = 0.00040144240483641624, best_loss = 0.0004254526284057647, model saved at 5\n",
      "val_losses[-1] = 0.00039798690704628825, best_loss = 0.00040144240483641624, model saved at 6\n",
      "val_losses[-1] = 0.0003809498157352209, best_loss = 0.00039798690704628825, model saved at 7\n",
      "val_losses[-1] = 0.0003769010945688933, best_loss = 0.0003809498157352209, model saved at 8\n",
      "val_losses[-1] = 0.00037224814877845347, best_loss = 0.0003769010945688933, model saved at 9\n",
      "val_losses[-1] = 0.00036693288711830974, best_loss = 0.00037224814877845347, model saved at 10\n",
      "val_losses[-1] = 0.0003639209899120033, best_loss = 0.00036693288711830974, model saved at 15\n",
      "val_losses[-1] = 0.00036239117616787553, best_loss = 0.0003639209899120033, model saved at 21\n",
      "val_losses[-1] = 0.0003574377915356308, best_loss = 0.00036239117616787553, model saved at 29\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006217408808879554, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006119604804553092, best_loss = 0.0006217408808879554, model saved at 1\n",
      "val_losses[-1] = 0.0006079819286242127, best_loss = 0.0006119604804553092, model saved at 2\n",
      "val_losses[-1] = 0.0006011457298882306, best_loss = 0.0006079819286242127, model saved at 3\n",
      "val_losses[-1] = 0.0005923310527577996, best_loss = 0.0006011457298882306, model saved at 4\n",
      "val_losses[-1] = 0.0005757589242421091, best_loss = 0.0005923310527577996, model saved at 6\n",
      "val_losses[-1] = 0.0004318308492656797, best_loss = 0.0005757589242421091, model saved at 7\n",
      "val_losses[-1] = 0.00039531884249299765, best_loss = 0.0004318308492656797, model saved at 8\n",
      "val_losses[-1] = 0.00037785127642564476, best_loss = 0.00039531884249299765, model saved at 9\n",
      "val_losses[-1] = 0.0003681113012135029, best_loss = 0.00037785127642564476, model saved at 10\n",
      "val_losses[-1] = 0.0003652909363154322, best_loss = 0.0003681113012135029, model saved at 11\n",
      "val_losses[-1] = 0.00036423257552087307, best_loss = 0.0003652909363154322, model saved at 12\n",
      "val_losses[-1] = 0.00036254138103686273, best_loss = 0.00036423257552087307, model saved at 16\n",
      "val_losses[-1] = 0.000360348290996626, best_loss = 0.00036254138103686273, model saved at 18\n",
      "val_losses[-1] = 0.0003602495708037168, best_loss = 0.000360348290996626, model saved at 24\n",
      "val_losses[-1] = 0.0003539459721650928, best_loss = 0.0003602495708037168, model saved at 28\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006300149252638221, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006248807185329497, best_loss = 0.0006300149252638221, model saved at 1\n",
      "val_losses[-1] = 0.00020601895812433213, best_loss = 0.0006248807185329497, model saved at 2\n",
      "val_losses[-1] = 0.00014325848314911127, best_loss = 0.00020601895812433213, model saved at 3\n",
      "val_losses[-1] = 0.00013930659042671323, best_loss = 0.00014325848314911127, model saved at 4\n",
      "val_losses[-1] = 0.00013530159776564687, best_loss = 0.00013930659042671323, model saved at 5\n",
      "val_losses[-1] = 0.00013182660040911287, best_loss = 0.00013530159776564687, model saved at 6\n",
      "val_losses[-1] = 0.00013070846034679562, best_loss = 0.00013182660040911287, model saved at 7\n",
      "val_losses[-1] = 0.0001294537796638906, best_loss = 0.00013070846034679562, model saved at 12\n",
      "val_losses[-1] = 0.00012702590902335942, best_loss = 0.0001294537796638906, model saved at 18\n",
      "val_losses[-1] = 0.00012661307118833065, best_loss = 0.00012702590902335942, model saved at 19\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0007308238418772817, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005807004636153579, best_loss = 0.0007308238418772817, model saved at 1\n",
      "val_losses[-1] = 0.0005533586954697967, best_loss = 0.0005807004636153579, model saved at 2\n",
      "val_losses[-1] = 0.0005347183905541897, best_loss = 0.0005533586954697967, model saved at 3\n",
      "val_losses[-1] = 0.0005252677947282791, best_loss = 0.0005347183905541897, model saved at 4\n",
      "val_losses[-1] = 0.000153263914398849, best_loss = 0.0005252677947282791, model saved at 5\n",
      "val_losses[-1] = 0.00015109650848899037, best_loss = 0.000153263914398849, model saved at 6\n",
      "val_losses[-1] = 0.00013687627506442368, best_loss = 0.00015109650848899037, model saved at 7\n",
      "val_losses[-1] = 0.0001273220987059176, best_loss = 0.00013687627506442368, model saved at 8\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007012492278590798, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006768068415112793, best_loss = 0.0007012492278590798, model saved at 1\n",
      "val_losses[-1] = 0.0005744157242588699, best_loss = 0.0006768068415112793, model saved at 2\n",
      "val_losses[-1] = 0.0005486123845912516, best_loss = 0.0005744157242588699, model saved at 3\n",
      "val_losses[-1] = 0.0005384070100262761, best_loss = 0.0005486123845912516, model saved at 4\n",
      "val_losses[-1] = 0.0005382135859690607, best_loss = 0.0005384070100262761, model saved at 5\n",
      "val_losses[-1] = 0.0005275757284834981, best_loss = 0.0005382135859690607, model saved at 6\n",
      "val_losses[-1] = 0.0005179329891689122, best_loss = 0.0005275757284834981, model saved at 7\n",
      "val_losses[-1] = 0.000512672821059823, best_loss = 0.0005179329891689122, model saved at 8\n",
      "val_losses[-1] = 0.0005055718938820064, best_loss = 0.000512672821059823, model saved at 9\n",
      "val_losses[-1] = 0.00017965141159947962, best_loss = 0.0005055718938820064, model saved at 10\n",
      "val_losses[-1] = 0.00014288928650785238, best_loss = 0.00017965141159947962, model saved at 11\n",
      "val_losses[-1] = 0.00014214670227374882, best_loss = 0.00014288928650785238, model saved at 12\n",
      "val_losses[-1] = 0.00013846647925674915, best_loss = 0.00014214670227374882, model saved at 14\n",
      "val_losses[-1] = 0.00013272100477479398, best_loss = 0.00013846647925674915, model saved at 15\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006199549534358084, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00016471177514176816, best_loss = 0.0006199549534358084, model saved at 1\n",
      "val_losses[-1] = 0.0001455617166357115, best_loss = 0.00016471177514176816, model saved at 2\n",
      "val_losses[-1] = 0.00014529016334563494, best_loss = 0.0001455617166357115, model saved at 3\n",
      "val_losses[-1] = 0.00013556709745898843, best_loss = 0.00014529016334563494, model saved at 4\n",
      "val_losses[-1] = 0.00012851129577029496, best_loss = 0.00013556709745898843, model saved at 5\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006102207116782665, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00017427070997655392, best_loss = 0.0006102207116782665, model saved at 1\n",
      "val_losses[-1] = 0.00014641130110248923, best_loss = 0.00017427070997655392, model saved at 2\n",
      "val_losses[-1] = 0.00014354832819662988, best_loss = 0.00014641130110248923, model saved at 3\n",
      "val_losses[-1] = 0.0001365698262816295, best_loss = 0.00014354832819662988, model saved at 5\n",
      "val_losses[-1] = 0.0001320080627920106, best_loss = 0.0001365698262816295, model saved at 8\n",
      "val_losses[-1] = 0.0001309287763433531, best_loss = 0.0001320080627920106, model saved at 14\n",
      "val_losses[-1] = 0.0001306454505538568, best_loss = 0.0001309287763433531, model saved at 18\n",
      "val_losses[-1] = 0.0001303507888223976, best_loss = 0.0001306454505538568, model saved at 23\n",
      "val_losses[-1] = 0.00012955818965565413, best_loss = 0.0001303507888223976, model saved at 27\n",
      "val_losses[-1] = 0.00012560772302094847, best_loss = 0.00012955818965565413, model saved at 28\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006422565784305334, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006234880420379341, best_loss = 0.0006422565784305334, model saved at 1\n",
      "val_losses[-1] = 9.44163984968327e-05, best_loss = 0.0006234880420379341, model saved at 2\n",
      "val_losses[-1] = 7.956551417009905e-05, best_loss = 9.44163984968327e-05, model saved at 3\n",
      "val_losses[-1] = 7.93897415860556e-05, best_loss = 7.956551417009905e-05, model saved at 5\n",
      "val_losses[-1] = 7.845272921258584e-05, best_loss = 7.93897415860556e-05, model saved at 7\n",
      "val_losses[-1] = 7.63527350500226e-05, best_loss = 7.845272921258584e-05, model saved at 13\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006161542260088027, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005481019034050405, best_loss = 0.0006161542260088027, model saved at 1\n",
      "val_losses[-1] = 0.0003561366756912321, best_loss = 0.0005481019034050405, model saved at 2\n",
      "val_losses[-1] = 0.00010230354382656515, best_loss = 0.0003561366756912321, model saved at 3\n",
      "val_losses[-1] = 8.561043068766594e-05, best_loss = 0.00010230354382656515, model saved at 4\n",
      "val_losses[-1] = 8.454388444079086e-05, best_loss = 8.561043068766594e-05, model saved at 5\n",
      "val_losses[-1] = 7.935975736472756e-05, best_loss = 8.454388444079086e-05, model saved at 6\n",
      "val_losses[-1] = 7.61016272008419e-05, best_loss = 7.935975736472756e-05, model saved at 15\n",
      "val_losses[-1] = 7.424097566399723e-05, best_loss = 7.61016272008419e-05, model saved at 25\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0008539161062799394, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006029517971910536, best_loss = 0.0008539161062799394, model saved at 1\n",
      "val_losses[-1] = 0.00040341855492442846, best_loss = 0.0006029517971910536, model saved at 2\n",
      "val_losses[-1] = 0.00011432090832386166, best_loss = 0.00040341855492442846, model saved at 3\n",
      "val_losses[-1] = 9.735543426359072e-05, best_loss = 0.00011432090832386166, model saved at 4\n",
      "val_losses[-1] = 8.735455048736185e-05, best_loss = 9.735543426359072e-05, model saved at 5\n",
      "val_losses[-1] = 8.703153434908018e-05, best_loss = 8.735455048736185e-05, model saved at 6\n",
      "val_losses[-1] = 8.618626452516764e-05, best_loss = 8.703153434908018e-05, model saved at 7\n",
      "val_losses[-1] = 8.268145757028833e-05, best_loss = 8.618626452516764e-05, model saved at 11\n",
      "val_losses[-1] = 8.005203562788665e-05, best_loss = 8.268145757028833e-05, model saved at 14\n",
      "val_losses[-1] = 7.859316247049719e-05, best_loss = 8.005203562788665e-05, model saved at 16\n",
      "val_losses[-1] = 7.788422954035923e-05, best_loss = 7.859316247049719e-05, model saved at 17\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0004094105097465217, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 9.712404425954446e-05, best_loss = 0.0004094105097465217, model saved at 1\n",
      "val_losses[-1] = 8.858976070769131e-05, best_loss = 9.712404425954446e-05, model saved at 2\n",
      "val_losses[-1] = 8.626918861409649e-05, best_loss = 8.858976070769131e-05, model saved at 3\n",
      "val_losses[-1] = 8.360745414393023e-05, best_loss = 8.626918861409649e-05, model saved at 6\n",
      "val_losses[-1] = 7.994742918526754e-05, best_loss = 8.360745414393023e-05, model saved at 9\n",
      "val_losses[-1] = 7.978856592671946e-05, best_loss = 7.994742918526754e-05, model saved at 11\n",
      "val_losses[-1] = 7.659929542569444e-05, best_loss = 7.978856592671946e-05, model saved at 15\n",
      "val_losses[-1] = 7.580587407574058e-05, best_loss = 7.659929542569444e-05, model saved at 16\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0005975693347863853, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0001945697149494663, best_loss = 0.0005975693347863853, model saved at 1\n",
      "val_losses[-1] = 9.509663505014032e-05, best_loss = 0.0001945697149494663, model saved at 2\n",
      "val_losses[-1] = 8.749958215048537e-05, best_loss = 9.509663505014032e-05, model saved at 3\n",
      "val_losses[-1] = 8.705028449185193e-05, best_loss = 8.749958215048537e-05, model saved at 4\n",
      "val_losses[-1] = 7.395118882413954e-05, best_loss = 8.705028449185193e-05, model saved at 5\n",
      "val_losses[-1] = 7.229997572721913e-05, best_loss = 7.395118882413954e-05, model saved at 21\n",
      "(1, 0.2)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006450967630371451, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006240184884518385, best_loss = 0.0006450967630371451, model saved at 1\n",
      "val_losses[-1] = 0.0005528866313397884, best_loss = 0.0006240184884518385, model saved at 2\n",
      "val_losses[-1] = 0.0004323114990256727, best_loss = 0.0005528866313397884, model saved at 3\n",
      "val_losses[-1] = 0.00038686691550537944, best_loss = 0.0004323114990256727, model saved at 4\n",
      "val_losses[-1] = 0.00037034525303170085, best_loss = 0.00038686691550537944, model saved at 5\n",
      "val_losses[-1] = 0.0003592314606066793, best_loss = 0.00037034525303170085, model saved at 6\n",
      "val_losses[-1] = 0.00035347489756532013, best_loss = 0.0003592314606066793, model saved at 12\n",
      "val_losses[-1] = 0.0003531280963215977, best_loss = 0.00035347489756532013, model saved at 19\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006111884140409529, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006103127961978316, best_loss = 0.0006111884140409529, model saved at 1\n",
      "val_losses[-1] = 0.0005979065899737179, best_loss = 0.0006103127961978316, model saved at 2\n",
      "val_losses[-1] = 0.00043854990508407354, best_loss = 0.0005979065899737179, model saved at 3\n",
      "val_losses[-1] = 0.00040654055192135274, best_loss = 0.00043854990508407354, model saved at 4\n",
      "val_losses[-1] = 0.0003894668770954013, best_loss = 0.00040654055192135274, model saved at 5\n",
      "val_losses[-1] = 0.00037325432640500367, best_loss = 0.0003894668770954013, model saved at 6\n",
      "val_losses[-1] = 0.00036536442348733544, best_loss = 0.00037325432640500367, model saved at 7\n",
      "val_losses[-1] = 0.00035922977258451283, best_loss = 0.00036536442348733544, model saved at 9\n",
      "val_losses[-1] = 0.00035773179843090475, best_loss = 0.00035922977258451283, model saved at 25\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007045272504910827, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006198809714987874, best_loss = 0.0007045272504910827, model saved at 1\n",
      "val_losses[-1] = 0.0006057068821974099, best_loss = 0.0006198809714987874, model saved at 2\n",
      "val_losses[-1] = 0.0005988616612739861, best_loss = 0.0006057068821974099, model saved at 3\n",
      "val_losses[-1] = 0.0005926064332015812, best_loss = 0.0005988616612739861, model saved at 4\n",
      "val_losses[-1] = 0.0005881433608010411, best_loss = 0.0005926064332015812, model saved at 5\n",
      "val_losses[-1] = 0.000586050795391202, best_loss = 0.0005881433608010411, model saved at 9\n",
      "val_losses[-1] = 0.0005857686046510935, best_loss = 0.000586050795391202, model saved at 10\n",
      "val_losses[-1] = 0.0005826044362038374, best_loss = 0.0005857686046510935, model saved at 11\n",
      "val_losses[-1] = 0.0005457235965877771, best_loss = 0.0005826044362038374, model saved at 12\n",
      "val_losses[-1] = 0.0004487541154958308, best_loss = 0.0005457235965877771, model saved at 13\n",
      "val_losses[-1] = 0.00039249530527740717, best_loss = 0.0004487541154958308, model saved at 14\n",
      "val_losses[-1] = 0.0003860742144752294, best_loss = 0.00039249530527740717, model saved at 15\n",
      "val_losses[-1] = 0.0003758730599656701, best_loss = 0.0003860742144752294, model saved at 17\n",
      "val_losses[-1] = 0.0003675631305668503, best_loss = 0.0003758730599656701, model saved at 20\n",
      "val_losses[-1] = 0.0003648422716651112, best_loss = 0.0003675631305668503, model saved at 23\n",
      "val_losses[-1] = 0.00036118103889748454, best_loss = 0.0003648422716651112, model saved at 26\n",
      "val_losses[-1] = 0.0003606969548854977, best_loss = 0.00036118103889748454, model saved at 27\n",
      "val_losses[-1] = 0.00035924295661970973, best_loss = 0.0003606969548854977, model saved at 28\n",
      "val_losses[-1] = 0.00035485258558765054, best_loss = 0.00035924295661970973, model saved at 29\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006201605428941548, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005740004708059132, best_loss = 0.0006201605428941548, model saved at 1\n",
      "val_losses[-1] = 0.0004322176391724497, best_loss = 0.0005740004708059132, model saved at 2\n",
      "val_losses[-1] = 0.0004004304646514356, best_loss = 0.0004322176391724497, model saved at 3\n",
      "val_losses[-1] = 0.00037343380972743034, best_loss = 0.0004004304646514356, model saved at 4\n",
      "val_losses[-1] = 0.0003676490450743586, best_loss = 0.00037343380972743034, model saved at 7\n",
      "val_losses[-1] = 0.00036702409852296114, best_loss = 0.0003676490450743586, model saved at 9\n",
      "val_losses[-1] = 0.0003613491135183722, best_loss = 0.00036702409852296114, model saved at 10\n",
      "val_losses[-1] = 0.00035817630123347044, best_loss = 0.0003613491135183722, model saved at 21\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006165319355204701, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006141344783827662, best_loss = 0.0006165319355204701, model saved at 1\n",
      "val_losses[-1] = 0.0006135707371868193, best_loss = 0.0006141344783827662, model saved at 2\n",
      "val_losses[-1] = 0.0006049092626199126, best_loss = 0.0006135707371868193, model saved at 3\n",
      "val_losses[-1] = 0.000602525775320828, best_loss = 0.0006049092626199126, model saved at 4\n",
      "val_losses[-1] = 0.0006006993935443461, best_loss = 0.000602525775320828, model saved at 5\n",
      "val_losses[-1] = 0.0005991995567455888, best_loss = 0.0006006993935443461, model saved at 6\n",
      "val_losses[-1] = 0.0005984096205793321, best_loss = 0.0005991995567455888, model saved at 7\n",
      "val_losses[-1] = 0.000597989943344146, best_loss = 0.0005984096205793321, model saved at 8\n",
      "val_losses[-1] = 0.0005973916850052774, best_loss = 0.000597989943344146, model saved at 9\n",
      "val_losses[-1] = 0.0005962253781035542, best_loss = 0.0005973916850052774, model saved at 10\n",
      "val_losses[-1] = 0.0005951925413683057, best_loss = 0.0005962253781035542, model saved at 12\n",
      "val_losses[-1] = 0.0005940733244642615, best_loss = 0.0005951925413683057, model saved at 13\n",
      "val_losses[-1] = 0.0005935997469350696, best_loss = 0.0005940733244642615, model saved at 15\n",
      "val_losses[-1] = 0.0005935050430707633, best_loss = 0.0005935997469350696, model saved at 16\n",
      "val_losses[-1] = 0.0005929415347054601, best_loss = 0.0005935050430707633, model saved at 17\n",
      "val_losses[-1] = 0.0005921843694522977, best_loss = 0.0005929415347054601, model saved at 18\n",
      "val_losses[-1] = 0.0005909898318350315, best_loss = 0.0005921843694522977, model saved at 20\n",
      "val_losses[-1] = 0.0005909712635912001, best_loss = 0.0005909898318350315, model saved at 23\n",
      "val_losses[-1] = 0.0005831721937283874, best_loss = 0.0005909712635912001, model saved at 24\n",
      "val_losses[-1] = 0.00046173721784725785, best_loss = 0.0005831721937283874, model saved at 25\n",
      "val_losses[-1] = 0.00040719498065300286, best_loss = 0.00046173721784725785, model saved at 26\n",
      "val_losses[-1] = 0.00038187444442883134, best_loss = 0.00040719498065300286, model saved at 27\n",
      "val_losses[-1] = 0.00037044502096250653, best_loss = 0.00038187444442883134, model saved at 28\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.000636001059319824, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000611534749623388, best_loss = 0.000636001059319824, model saved at 1\n",
      "val_losses[-1] = 0.0006059569423086941, best_loss = 0.000611534749623388, model saved at 2\n",
      "val_losses[-1] = 0.00023889377189334482, best_loss = 0.0006059569423086941, model saved at 3\n",
      "val_losses[-1] = 0.00014887413999531418, best_loss = 0.00023889377189334482, model saved at 4\n",
      "val_losses[-1] = 0.00013527889677789062, best_loss = 0.00014887413999531418, model saved at 6\n",
      "val_losses[-1] = 0.00013229342584963888, best_loss = 0.00013527889677789062, model saved at 18\n",
      "val_losses[-1] = 0.00013151238090358675, best_loss = 0.00013229342584963888, model saved at 19\n",
      "val_losses[-1] = 0.00013055976887699217, best_loss = 0.00013151238090358675, model saved at 27\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006217708578333259, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006167799583636224, best_loss = 0.0006217708578333259, model saved at 1\n",
      "val_losses[-1] = 0.0002220042806584388, best_loss = 0.0006167799583636224, model saved at 2\n",
      "val_losses[-1] = 0.0001562982506584376, best_loss = 0.0002220042806584388, model saved at 3\n",
      "val_losses[-1] = 0.00014150203787721694, best_loss = 0.0001562982506584376, model saved at 4\n",
      "val_losses[-1] = 0.00013520618085749447, best_loss = 0.00014150203787721694, model saved at 5\n",
      "val_losses[-1] = 0.00013217248488217592, best_loss = 0.00013520618085749447, model saved at 7\n",
      "val_losses[-1] = 0.0001240353740286082, best_loss = 0.00013217248488217592, model saved at 8\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0006540004978887737, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005671094986610115, best_loss = 0.0006540004978887737, model saved at 1\n",
      "val_losses[-1] = 0.00033480525598861277, best_loss = 0.0005671094986610115, model saved at 2\n",
      "val_losses[-1] = 0.00020440549997147173, best_loss = 0.00033480525598861277, model saved at 3\n",
      "val_losses[-1] = 0.00016455836885143071, best_loss = 0.00020440549997147173, model saved at 4\n",
      "val_losses[-1] = 0.00016093053272925317, best_loss = 0.00016455836885143071, model saved at 5\n",
      "val_losses[-1] = 0.00014634641411248595, best_loss = 0.00016093053272925317, model saved at 6\n",
      "val_losses[-1] = 0.00013993013999424875, best_loss = 0.00014634641411248595, model saved at 8\n",
      "val_losses[-1] = 0.00013956980546936393, best_loss = 0.00013993013999424875, model saved at 9\n",
      "val_losses[-1] = 0.0001341943716397509, best_loss = 0.00013956980546936393, model saved at 10\n",
      "val_losses[-1] = 0.0001320677256444469, best_loss = 0.0001341943716397509, model saved at 11\n",
      "val_losses[-1] = 0.00012782900012098253, best_loss = 0.0001320677256444469, model saved at 14\n",
      "val_losses[-1] = 0.00012715495540760458, best_loss = 0.00012782900012098253, model saved at 15\n",
      "iter 3...\n",
      "val_losses[-1] = 0.00042366169509477913, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00015755914500914514, best_loss = 0.00042366169509477913, model saved at 1\n",
      "val_losses[-1] = 0.00014297400775831193, best_loss = 0.00015755914500914514, model saved at 2\n",
      "val_losses[-1] = 0.0001411562698194757, best_loss = 0.00014297400775831193, model saved at 4\n",
      "val_losses[-1] = 0.00013524341920856386, best_loss = 0.0001411562698194757, model saved at 5\n",
      "val_losses[-1] = 0.00013168531586416066, best_loss = 0.00013524341920856386, model saved at 8\n",
      "val_losses[-1] = 0.00012664409587159753, best_loss = 0.00013168531586416066, model saved at 17\n",
      "iter 4...\n",
      "val_losses[-1] = 0.00047619661199860275, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00016333781240973622, best_loss = 0.00047619661199860275, model saved at 1\n",
      "val_losses[-1] = 0.00014498084783554077, best_loss = 0.00016333781240973622, model saved at 2\n",
      "val_losses[-1] = 0.00013970649160910398, best_loss = 0.00014498084783554077, model saved at 3\n",
      "val_losses[-1] = 0.00013769915676675737, best_loss = 0.00013970649160910398, model saved at 5\n",
      "val_losses[-1] = 0.0001352889375993982, best_loss = 0.00013769915676675737, model saved at 7\n",
      "val_losses[-1] = 0.00012808626343030483, best_loss = 0.0001352889375993982, model saved at 8\n",
      "val_losses[-1] = 0.00012673271703533828, best_loss = 0.00012808626343030483, model saved at 23\n",
      "val_losses[-1] = 0.0001247748004971072, best_loss = 0.00012673271703533828, model saved at 28\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006438682903535664, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005688876262865961, best_loss = 0.0006438682903535664, model saved at 1\n",
      "val_losses[-1] = 8.99691876838915e-05, best_loss = 0.0005688876262865961, model saved at 2\n",
      "val_losses[-1] = 7.879552867962047e-05, best_loss = 8.99691876838915e-05, model saved at 3\n",
      "val_losses[-1] = 7.835384167265147e-05, best_loss = 7.879552867962047e-05, model saved at 5\n",
      "val_losses[-1] = 7.77840250520967e-05, best_loss = 7.835384167265147e-05, model saved at 7\n",
      "val_losses[-1] = 7.393430860247463e-05, best_loss = 7.77840250520967e-05, model saved at 13\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006003378075547516, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005957470857538283, best_loss = 0.0006003378075547516, model saved at 1\n",
      "val_losses[-1] = 9.940791642293334e-05, best_loss = 0.0005957470857538283, model saved at 2\n",
      "val_losses[-1] = 8.551213977625594e-05, best_loss = 9.940791642293334e-05, model saved at 4\n",
      "val_losses[-1] = 8.197120041586459e-05, best_loss = 8.551213977625594e-05, model saved at 6\n",
      "val_losses[-1] = 8.118498226394877e-05, best_loss = 8.197120041586459e-05, model saved at 8\n",
      "val_losses[-1] = 8.053658530116081e-05, best_loss = 8.118498226394877e-05, model saved at 12\n",
      "val_losses[-1] = 7.642632408533245e-05, best_loss = 8.053658530116081e-05, model saved at 15\n",
      "val_losses[-1] = 7.46791556593962e-05, best_loss = 7.642632408533245e-05, model saved at 25\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0006901795859448612, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005551403155550361, best_loss = 0.0006901795859448612, model saved at 1\n",
      "val_losses[-1] = 0.0005249592941254377, best_loss = 0.0005551403155550361, model saved at 2\n",
      "val_losses[-1] = 0.00012091025564586744, best_loss = 0.0005249592941254377, model saved at 3\n",
      "val_losses[-1] = 9.308523294748738e-05, best_loss = 0.00012091025564586744, model saved at 4\n",
      "val_losses[-1] = 8.455305214738473e-05, best_loss = 9.308523294748738e-05, model saved at 5\n",
      "val_losses[-1] = 8.216135756811127e-05, best_loss = 8.455305214738473e-05, model saved at 6\n",
      "val_losses[-1] = 8.176140545401722e-05, best_loss = 8.216135756811127e-05, model saved at 9\n",
      "val_losses[-1] = 7.857303717173636e-05, best_loss = 8.176140545401722e-05, model saved at 11\n",
      "val_losses[-1] = 7.759262371109799e-05, best_loss = 7.857303717173636e-05, model saved at 14\n",
      "val_losses[-1] = 7.326962804654613e-05, best_loss = 7.759262371109799e-05, model saved at 16\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0005849716253578663, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00016560664516873658, best_loss = 0.0005849716253578663, model saved at 1\n",
      "val_losses[-1] = 9.40159588935785e-05, best_loss = 0.00016560664516873658, model saved at 2\n",
      "val_losses[-1] = 8.845556294545531e-05, best_loss = 9.40159588935785e-05, model saved at 3\n",
      "val_losses[-1] = 8.597420674050227e-05, best_loss = 8.845556294545531e-05, model saved at 6\n",
      "val_losses[-1] = 8.294470171676949e-05, best_loss = 8.597420674050227e-05, model saved at 7\n",
      "val_losses[-1] = 7.904732774477452e-05, best_loss = 8.294470171676949e-05, model saved at 9\n",
      "val_losses[-1] = 7.836452277842909e-05, best_loss = 7.904732774477452e-05, model saved at 15\n",
      "val_losses[-1] = 7.64838041504845e-05, best_loss = 7.836452277842909e-05, model saved at 16\n",
      "val_losses[-1] = 7.389323582174256e-05, best_loss = 7.64838041504845e-05, model saved at 20\n",
      "iter 4...\n",
      "val_losses[-1] = 0.000583176442887634, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 9.562760533299297e-05, best_loss = 0.000583176442887634, model saved at 1\n",
      "val_losses[-1] = 7.95365049270913e-05, best_loss = 9.562760533299297e-05, model saved at 2\n",
      "val_losses[-1] = 7.659780385438353e-05, best_loss = 7.95365049270913e-05, model saved at 5\n",
      "val_losses[-1] = 7.144873961806297e-05, best_loss = 7.659780385438353e-05, model saved at 21\n",
      "(1, 0.1)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006551626138389111, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006232794257812202, best_loss = 0.0006551626138389111, model saved at 1\n",
      "val_losses[-1] = 0.0006089823436923325, best_loss = 0.0006232794257812202, model saved at 2\n",
      "val_losses[-1] = 0.0006083553307689726, best_loss = 0.0006089823436923325, model saved at 3\n",
      "val_losses[-1] = 0.0006026191986165941, best_loss = 0.0006083553307689726, model saved at 4\n",
      "val_losses[-1] = 0.000575603567995131, best_loss = 0.0006026191986165941, model saved at 5\n",
      "val_losses[-1] = 0.0004959034849889576, best_loss = 0.000575603567995131, model saved at 6\n",
      "val_losses[-1] = 0.00041829756810329854, best_loss = 0.0004959034849889576, model saved at 7\n",
      "val_losses[-1] = 0.0003876631672028452, best_loss = 0.00041829756810329854, model saved at 8\n",
      "val_losses[-1] = 0.0003811422793660313, best_loss = 0.0003876631672028452, model saved at 9\n",
      "val_losses[-1] = 0.0003751774784177542, best_loss = 0.0003811422793660313, model saved at 10\n",
      "val_losses[-1] = 0.0003674482577480376, best_loss = 0.0003751774784177542, model saved at 11\n",
      "val_losses[-1] = 0.00035884155659005046, best_loss = 0.0003674482577480376, model saved at 12\n",
      "val_losses[-1] = 0.000356442469637841, best_loss = 0.00035884155659005046, model saved at 19\n",
      "val_losses[-1] = 0.00035620431299321353, best_loss = 0.000356442469637841, model saved at 25\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006092315306887031, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00043033319525420666, best_loss = 0.0006092315306887031, model saved at 1\n",
      "val_losses[-1] = 0.00040406189509667456, best_loss = 0.00043033319525420666, model saved at 2\n",
      "val_losses[-1] = 0.00040362379513680935, best_loss = 0.00040406189509667456, model saved at 6\n",
      "val_losses[-1] = 0.00039190633106045425, best_loss = 0.00040362379513680935, model saved at 7\n",
      "val_losses[-1] = 0.00038205613964237273, best_loss = 0.00039190633106045425, model saved at 8\n",
      "val_losses[-1] = 0.00037022505421191454, best_loss = 0.00038205613964237273, model saved at 9\n",
      "val_losses[-1] = 0.00035980454413220286, best_loss = 0.00037022505421191454, model saved at 13\n",
      "val_losses[-1] = 0.0003580607008188963, best_loss = 0.00035980454413220286, model saved at 19\n",
      "val_losses[-1] = 0.00035509944427758455, best_loss = 0.0003580607008188963, model saved at 22\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0006867340998724103, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006267838762141764, best_loss = 0.0006867340998724103, model saved at 1\n",
      "val_losses[-1] = 0.0006088145892135799, best_loss = 0.0006267838762141764, model saved at 2\n",
      "val_losses[-1] = 0.0004996550269424915, best_loss = 0.0006088145892135799, model saved at 3\n",
      "val_losses[-1] = 0.0003921246388927102, best_loss = 0.0004996550269424915, model saved at 4\n",
      "val_losses[-1] = 0.00036153275868855417, best_loss = 0.0003921246388927102, model saved at 5\n",
      "val_losses[-1] = 0.0003569532709661871, best_loss = 0.00036153275868855417, model saved at 10\n",
      "val_losses[-1] = 0.0003558361204341054, best_loss = 0.0003569532709661871, model saved at 17\n",
      "val_losses[-1] = 0.000355642318027094, best_loss = 0.0003558361204341054, model saved at 20\n",
      "val_losses[-1] = 0.00035385755472816527, best_loss = 0.000355642318027094, model saved at 27\n",
      "val_losses[-1] = 0.0003533744311425835, best_loss = 0.00035385755472816527, model saved at 28\n",
      "val_losses[-1] = 0.00035063730319961905, best_loss = 0.0003533744311425835, model saved at 29\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0004911323776468635, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0004063408705405891, best_loss = 0.0004911323776468635, model saved at 1\n",
      "val_losses[-1] = 0.0003857673145830631, best_loss = 0.0004063408705405891, model saved at 2\n",
      "val_losses[-1] = 0.0003826833562925458, best_loss = 0.0003857673145830631, model saved at 4\n",
      "val_losses[-1] = 0.00037374894600361586, best_loss = 0.0003826833562925458, model saved at 5\n",
      "val_losses[-1] = 0.00037343561416491866, best_loss = 0.00037374894600361586, model saved at 6\n",
      "val_losses[-1] = 0.00037148362025618553, best_loss = 0.00037343561416491866, model saved at 7\n",
      "val_losses[-1] = 0.0003644404059741646, best_loss = 0.00037148362025618553, model saved at 9\n",
      "val_losses[-1] = 0.00036244746297597885, best_loss = 0.0003644404059741646, model saved at 10\n",
      "val_losses[-1] = 0.00036031275521963835, best_loss = 0.00036244746297597885, model saved at 16\n",
      "val_losses[-1] = 0.0003577799943741411, best_loss = 0.00036031275521963835, model saved at 21\n",
      "val_losses[-1] = 0.000357304816134274, best_loss = 0.0003577799943741411, model saved at 29\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006115963333286345, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006077194702811539, best_loss = 0.0006115963333286345, model saved at 1\n",
      "val_losses[-1] = 0.0005485511501319706, best_loss = 0.0006077194702811539, model saved at 2\n",
      "val_losses[-1] = 0.00041742122266441584, best_loss = 0.0005485511501319706, model saved at 3\n",
      "val_losses[-1] = 0.00038233393570408225, best_loss = 0.00041742122266441584, model saved at 4\n",
      "val_losses[-1] = 0.0003700616944115609, best_loss = 0.00038233393570408225, model saved at 5\n",
      "val_losses[-1] = 0.0003691949532367289, best_loss = 0.0003700616944115609, model saved at 6\n",
      "val_losses[-1] = 0.0003660589281935245, best_loss = 0.0003691949532367289, model saved at 7\n",
      "val_losses[-1] = 0.0003551920526660979, best_loss = 0.0003660589281935245, model saved at 9\n",
      "val_losses[-1] = 0.00035448087146505713, best_loss = 0.0003551920526660979, model saved at 28\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006309648742899299, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006294423947110772, best_loss = 0.0006309648742899299, model saved at 1\n",
      "val_losses[-1] = 0.00017061532707884908, best_loss = 0.0006294423947110772, model saved at 2\n",
      "val_losses[-1] = 0.00014310426195152104, best_loss = 0.00017061532707884908, model saved at 3\n",
      "val_losses[-1] = 0.00013796552957501262, best_loss = 0.00014310426195152104, model saved at 4\n",
      "val_losses[-1] = 0.00013336613483261317, best_loss = 0.00013796552957501262, model saved at 6\n",
      "val_losses[-1] = 0.00013132745516486466, best_loss = 0.00013336613483261317, model saved at 7\n",
      "val_losses[-1] = 0.00013082673831377178, best_loss = 0.00013132745516486466, model saved at 18\n",
      "val_losses[-1] = 0.00012997727026231587, best_loss = 0.00013082673831377178, model saved at 27\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006665516993962228, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005901235854253173, best_loss = 0.0006665516993962228, model saved at 1\n",
      "val_losses[-1] = 0.00015118079318199307, best_loss = 0.0005901235854253173, model saved at 2\n",
      "val_losses[-1] = 0.0001391600671922788, best_loss = 0.00015118079318199307, model saved at 3\n",
      "val_losses[-1] = 0.00013389141531661153, best_loss = 0.0001391600671922788, model saved at 5\n",
      "val_losses[-1] = 0.0001307937636738643, best_loss = 0.00013389141531661153, model saved at 7\n",
      "val_losses[-1] = 0.00012401738786138594, best_loss = 0.0001307937636738643, model saved at 8\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0006748398300260305, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006094323471188545, best_loss = 0.0006748398300260305, model saved at 1\n",
      "val_losses[-1] = 0.0004971977323293686, best_loss = 0.0006094323471188545, model saved at 2\n",
      "val_losses[-1] = 0.00015993131091818213, best_loss = 0.0004971977323293686, model saved at 3\n",
      "val_losses[-1] = 0.0001516503980383277, best_loss = 0.00015993131091818213, model saved at 4\n",
      "val_losses[-1] = 0.0001493158924859017, best_loss = 0.0001516503980383277, model saved at 5\n",
      "val_losses[-1] = 0.00014253139670472592, best_loss = 0.0001493158924859017, model saved at 6\n",
      "val_losses[-1] = 0.0001391023542964831, best_loss = 0.00014253139670472592, model saved at 7\n",
      "val_losses[-1] = 0.000135599504574202, best_loss = 0.0001391023542964831, model saved at 9\n",
      "val_losses[-1] = 0.00013487545948009938, best_loss = 0.000135599504574202, model saved at 10\n",
      "val_losses[-1] = 0.00013185571879148483, best_loss = 0.00013487545948009938, model saved at 11\n",
      "val_losses[-1] = 0.00012797085219062865, best_loss = 0.00013185571879148483, model saved at 15\n",
      "iter 3...\n",
      "val_losses[-1] = 0.00022337978589348495, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00015824496222194284, best_loss = 0.00022337978589348495, model saved at 1\n",
      "val_losses[-1] = 0.0001463802473153919, best_loss = 0.00015824496222194284, model saved at 2\n",
      "val_losses[-1] = 0.0001420541957486421, best_loss = 0.0001463802473153919, model saved at 3\n",
      "val_losses[-1] = 0.00013858384045306593, best_loss = 0.0001420541957486421, model saved at 4\n",
      "val_losses[-1] = 0.00013339750876184553, best_loss = 0.00013858384045306593, model saved at 5\n",
      "val_losses[-1] = 0.00013135043263901025, best_loss = 0.00013339750876184553, model saved at 10\n",
      "val_losses[-1] = 0.00012988636444788426, best_loss = 0.00013135043263901025, model saved at 19\n",
      "val_losses[-1] = 0.0001287018967559561, best_loss = 0.00012988636444788426, model saved at 21\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0005679883761331439, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00016784331819508225, best_loss = 0.0005679883761331439, model saved at 1\n",
      "val_losses[-1] = 0.00015049544163048267, best_loss = 0.00016784331819508225, model saved at 2\n",
      "val_losses[-1] = 0.0001418546453351155, best_loss = 0.00015049544163048267, model saved at 3\n",
      "val_losses[-1] = 0.00013782917812932283, best_loss = 0.0001418546453351155, model saved at 5\n",
      "val_losses[-1] = 0.00013758250861428678, best_loss = 0.00013782917812932283, model saved at 7\n",
      "val_losses[-1] = 0.00013026550004724413, best_loss = 0.00013758250861428678, model saved at 8\n",
      "val_losses[-1] = 0.00012823785073123872, best_loss = 0.00013026550004724413, model saved at 18\n",
      "val_losses[-1] = 0.00012520630843937397, best_loss = 0.00012823785073123872, model saved at 28\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006276502972468734, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005932531203143299, best_loss = 0.0006276502972468734, model saved at 1\n",
      "val_losses[-1] = 0.0005774602759629488, best_loss = 0.0005932531203143299, model saved at 2\n",
      "val_losses[-1] = 0.0005248174420557916, best_loss = 0.0005774602759629488, model saved at 3\n",
      "val_losses[-1] = 9.361291449749842e-05, best_loss = 0.0005248174420557916, model saved at 4\n",
      "val_losses[-1] = 8.519384573446587e-05, best_loss = 9.361291449749842e-05, model saved at 5\n",
      "val_losses[-1] = 7.711051148362458e-05, best_loss = 8.519384573446587e-05, model saved at 7\n",
      "val_losses[-1] = 7.426536467391998e-05, best_loss = 7.711051148362458e-05, model saved at 13\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006099968450143933, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005310737760737538, best_loss = 0.0006099968450143933, model saved at 1\n",
      "val_losses[-1] = 8.71094671310857e-05, best_loss = 0.0005310737760737538, model saved at 2\n",
      "val_losses[-1] = 8.706469088792801e-05, best_loss = 8.71094671310857e-05, model saved at 3\n",
      "val_losses[-1] = 7.855727017158642e-05, best_loss = 8.706469088792801e-05, model saved at 4\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0006493519758805633, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005758478655479848, best_loss = 0.0006493519758805633, model saved at 1\n",
      "val_losses[-1] = 0.00037127669202163815, best_loss = 0.0005758478655479848, model saved at 2\n",
      "val_losses[-1] = 9.744353155838326e-05, best_loss = 0.00037127669202163815, model saved at 3\n",
      "val_losses[-1] = 9.29950547288172e-05, best_loss = 9.744353155838326e-05, model saved at 4\n",
      "val_losses[-1] = 8.748316759010777e-05, best_loss = 9.29950547288172e-05, model saved at 5\n",
      "val_losses[-1] = 8.465257997158915e-05, best_loss = 8.748316759010777e-05, model saved at 6\n",
      "val_losses[-1] = 8.175030961865559e-05, best_loss = 8.465257997158915e-05, model saved at 7\n",
      "val_losses[-1] = 7.858534809201956e-05, best_loss = 8.175030961865559e-05, model saved at 11\n",
      "val_losses[-1] = 7.819906022632495e-05, best_loss = 7.858534809201956e-05, model saved at 14\n",
      "val_losses[-1] = 7.78657995397225e-05, best_loss = 7.819906022632495e-05, model saved at 15\n",
      "val_losses[-1] = 7.542290404671803e-05, best_loss = 7.78657995397225e-05, model saved at 16\n",
      "iter 3...\n",
      "val_losses[-1] = 0.00023121929552871734, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 9.690519800642505e-05, best_loss = 0.00023121929552871734, model saved at 1\n",
      "val_losses[-1] = 8.692250412423164e-05, best_loss = 9.690519800642505e-05, model saved at 2\n",
      "val_losses[-1] = 8.334368612850085e-05, best_loss = 8.692250412423164e-05, model saved at 3\n",
      "val_losses[-1] = 7.958025526022539e-05, best_loss = 8.334368612850085e-05, model saved at 9\n",
      "val_losses[-1] = 7.773254037601873e-05, best_loss = 7.958025526022539e-05, model saved at 16\n",
      "val_losses[-1] = 7.549396832473576e-05, best_loss = 7.773254037601873e-05, model saved at 20\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0002338276244699955, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 9.428515477338806e-05, best_loss = 0.0002338276244699955, model saved at 1\n",
      "val_losses[-1] = 8.1482736277394e-05, best_loss = 9.428515477338806e-05, model saved at 2\n",
      "val_losses[-1] = 8.031995821511373e-05, best_loss = 8.1482736277394e-05, model saved at 3\n",
      "val_losses[-1] = 7.965919212438166e-05, best_loss = 8.031995821511373e-05, model saved at 5\n",
      "val_losses[-1] = 7.888315303716809e-05, best_loss = 7.965919212438166e-05, model saved at 6\n",
      "val_losses[-1] = 7.67536839703098e-05, best_loss = 7.888315303716809e-05, model saved at 11\n",
      "val_losses[-1] = 7.225037552416325e-05, best_loss = 7.67536839703098e-05, model saved at 21\n"
     ]
    }
   ],
   "source": [
    "for loss_ratios in all_loss_ratios:\n",
    "    print(loss_ratios)\n",
    "    for seq_length in seq_lengths:\n",
    "        print(seq_length)\n",
    "        models = []\n",
    "        for i in range(num_models):\n",
    "            print(f'iter {i}...')\n",
    "            torch.manual_seed(i)\n",
    "\n",
    "            dataset = torch.load(f\"data/mtl_fs_snr_{num_examples}_{seq_length}.pt\")\n",
    "            train_loader = dataset['train_loader']\n",
    "            val_loader = dataset['val_loader']\n",
    "\n",
    "            detector = preamble_detector_mtl()\n",
    "            detector.cuda()\n",
    "\n",
    "            loss_fn_fs = nn.MSELoss()\n",
    "            loss_fn_snr = nn.MSELoss()\n",
    "            optimizer = optim.Adam(detector.parameters(), lr=0.001, weight_decay=0.001)\n",
    "\n",
    "            num_epochs = 30\n",
    "\n",
    "            detector, losses, val_losses, snr_losses, fs_losses = train_mtl(detector, optimizer, train_loader, val_loader, \n",
    "                                                                            loss_fn_fs, loss_fn_snr, num_epochs=num_epochs,\n",
    "                                                                            loss_ratios=loss_ratios)\n",
    "\n",
    "            model_config = {\"weights\": detector.state_dict(),\n",
    "                            \"losses\": losses,\n",
    "                            \"val_losses\": val_losses,\n",
    "                            \"snr_losses\": snr_losses,\n",
    "                            \"fs_losses\": fs_losses}\n",
    "\n",
    "            models.append(model_config)\n",
    "\n",
    "        torch.save(models, f'models/continuous/mtl_fs_snr_{loss_ratios[0]}_{loss_ratios[1]}_{num_examples}_{seq_length}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, seq_length in enumerate(seq_lengths):\n",
    "    for model in torch.load(f'models/continuous/mtl_fs_snr_1_0.9_{num_examples}_{seq_length}.pt'):\n",
    "#         plt.plot(model['losses'], f'C{i}')\n",
    "        plt.plot(model['fs_losses'], f'C{i}')\n",
    "        plt.plot(model['val_losses'], f'C{i}--')\n",
    "# plt.ylim([0.002, 0.003])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mtl(detector, preamble_seq, snr_range, num_runs=200, payload=128, signal_length=400):\n",
    "    \n",
    "    accs = []\n",
    "    for snr in snr_range:\n",
    "        corrects = 0\n",
    "        for i in range(num_runs):\n",
    "            \n",
    "            tau = np.random.randint(0,signal_length-payload-len(preamble_seq))\n",
    "\n",
    "            my_frame = create_frame(preamble_seq, payload=payload, signal_length=signal_length, offset=tau)\n",
    "            my_frame = awgn(my_frame, snr)\n",
    "\n",
    "            new_frame = np.expand_dims(np.vstack((my_frame.real, my_frame.imag)),axis=(0,1))\n",
    "            new_frame = torch.tensor(new_frame).float()\n",
    "            nn_output, cfo_hat = detector(new_frame)\n",
    "\n",
    "            if nn_output.argmax() == tau:\n",
    "                corrects += 1\n",
    "\n",
    "        acc = corrects/num_runs\n",
    "        accs.append(acc)\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaling (1, 0.9)\n",
      "16\n",
      "32\n",
      "64\n",
      "Evaling (1, 0.8)\n",
      "16\n",
      "32\n",
      "64\n",
      "Evaling (1, 0.7)\n",
      "16\n",
      "32\n",
      "64\n",
      "Evaling (1, 0.6)\n",
      "16\n",
      "32\n",
      "64\n",
      "Evaling (1, 0.5)\n",
      "16\n",
      "32\n",
      "64\n",
      "Evaling (1, 0.4)\n",
      "16\n",
      "32\n",
      "64\n",
      "Evaling (1, 0.3)\n",
      "16\n",
      "32\n",
      "64\n",
      "Evaling (1, 0.2)\n",
      "16\n",
      "32\n",
      "64\n",
      "Evaling (1, 0.1)\n",
      "16\n",
      "32\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "for loss_ratios in all_loss_ratios:\n",
    "    print(f\"Evaling {loss_ratios}\")\n",
    "    for seq_length in seq_lengths:\n",
    "        print(seq_length)\n",
    "        results = []\n",
    "        for model in torch.load(f'models/continuous/mtl_fs_snr_{loss_ratios[0]}_{loss_ratios[1]}_{num_examples}_{seq_length}.pt'):\n",
    "            detector = preamble_detector_mtl()\n",
    "            detector.load_state_dict(model['weights'])\n",
    "\n",
    "            accs = test_mtl(detector, max_seq[:seq_length], snr_range=snr_range, num_runs=500)\n",
    "\n",
    "            result = {\"accs\": accs,\n",
    "                       \"snr_range\": snr_range,\n",
    "                       \"model\": model}\n",
    "\n",
    "            results.append(result)\n",
    "        torch.save(results, f'results/continuous/mtl_fs_snr_{loss_ratios[0]}_{loss_ratios[1]}_{num_examples}_{seq_length}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1, 0.9),\n",
       " (0.2, 0.8),\n",
       " (0.3, 0.7),\n",
       " (0.4, 0.6),\n",
       " (0.5, 0.5),\n",
       " (0.6, 0.4),\n",
       " (0.7, 0.3),\n",
       " (0.8, 0.2),\n",
       " (0.9, 0.1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_loss_ratios = []\n",
    "for i in range(1,10):\n",
    "    models = []\n",
    "\n",
    "    fs_weight = round(i*0.1,1)\n",
    "    snr_weight = round(1 - i*0.1, 1)\n",
    "    \n",
    "    loss_ratios = (fs_weight, snr_weight)\n",
    "    \n",
    "    all_loss_ratios.append(loss_ratios)\n",
    "all_loss_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1, 0.9)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006734164198860526, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006475901464000344, best_loss = 0.0006734164198860526, model saved at 1\n",
      "val_losses[-1] = 0.0006396989338099957, best_loss = 0.0006475901464000344, model saved at 2\n",
      "val_losses[-1] = 0.0006313839694485068, best_loss = 0.0006396989338099957, model saved at 3\n",
      "val_losses[-1] = 0.0006281970418058336, best_loss = 0.0006313839694485068, model saved at 4\n",
      "val_losses[-1] = 0.000625939923338592, best_loss = 0.0006281970418058336, model saved at 5\n",
      "val_losses[-1] = 0.0006249369471333921, best_loss = 0.000625939923338592, model saved at 6\n",
      "val_losses[-1] = 0.0006239913054741919, best_loss = 0.0006249369471333921, model saved at 7\n",
      "val_losses[-1] = 0.0006233396125026047, best_loss = 0.0006239913054741919, model saved at 8\n",
      "val_losses[-1] = 0.0006229704595170915, best_loss = 0.0006233396125026047, model saved at 9\n",
      "val_losses[-1] = 0.0006228489801287651, best_loss = 0.0006229704595170915, model saved at 10\n",
      "val_losses[-1] = 0.0006228350102901459, best_loss = 0.0006228489801287651, model saved at 11\n",
      "val_losses[-1] = 0.0006227981066331267, best_loss = 0.0006228350102901459, model saved at 12\n",
      "val_losses[-1] = 0.0006227522972039878, best_loss = 0.0006227981066331267, model saved at 13\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006249067955650389, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006237849011085927, best_loss = 0.0006249067955650389, model saved at 1\n",
      "val_losses[-1] = 0.0006234465399757028, best_loss = 0.0006237849011085927, model saved at 2\n",
      "val_losses[-1] = 0.0006233992171473801, best_loss = 0.0006234465399757028, model saved at 3\n",
      "val_losses[-1] = 0.0006233861204236746, best_loss = 0.0006233992171473801, model saved at 4\n",
      "val_losses[-1] = 0.0006233695894479752, best_loss = 0.0006233861204236746, model saved at 5\n",
      "val_losses[-1] = 0.0006233617314137518, best_loss = 0.0006233695894479752, model saved at 7\n",
      "val_losses[-1] = 0.0006233585299924016, best_loss = 0.0006233617314137518, model saved at 10\n",
      "val_losses[-1] = 0.0006233496242202818, best_loss = 0.0006233585299924016, model saved at 12\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0008791522704996169, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0007413977291435003, best_loss = 0.0008791522704996169, model saved at 1\n",
      "val_losses[-1] = 0.0006750663160346448, best_loss = 0.0007413977291435003, model saved at 2\n",
      "val_losses[-1] = 0.0006470209336839616, best_loss = 0.0006750663160346448, model saved at 3\n",
      "val_losses[-1] = 0.0006335590151138604, best_loss = 0.0006470209336839616, model saved at 4\n",
      "val_losses[-1] = 0.0006282874965108931, best_loss = 0.0006335590151138604, model saved at 5\n",
      "val_losses[-1] = 0.0006242408417165279, best_loss = 0.0006282874965108931, model saved at 6\n",
      "val_losses[-1] = 0.0006226887344382703, best_loss = 0.0006242408417165279, model saved at 7\n",
      "val_losses[-1] = 0.000622051302343607, best_loss = 0.0006226887344382703, model saved at 8\n",
      "val_losses[-1] = 0.0006220469367690384, best_loss = 0.000622051302343607, model saved at 10\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006613999721594155, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006278716609813273, best_loss = 0.0006613999721594155, model saved at 1\n",
      "val_losses[-1] = 0.000626911933068186, best_loss = 0.0006278716609813273, model saved at 2\n",
      "val_losses[-1] = 0.0006245366530492902, best_loss = 0.000626911933068186, model saved at 3\n",
      "val_losses[-1] = 0.0006223906530067325, best_loss = 0.0006245366530492902, model saved at 4\n",
      "val_losses[-1] = 0.0006220850627869368, best_loss = 0.0006223906530067325, model saved at 5\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006532176630571485, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006315381615422666, best_loss = 0.0006532176630571485, model saved at 1\n",
      "val_losses[-1] = 0.0006264699040912092, best_loss = 0.0006315381615422666, model saved at 2\n",
      "val_losses[-1] = 0.0006241755909286439, best_loss = 0.0006264699040912092, model saved at 3\n",
      "val_losses[-1] = 0.0006237815832719207, best_loss = 0.0006241755909286439, model saved at 4\n",
      "val_losses[-1] = 0.0006235144101083279, best_loss = 0.0006237815832719207, model saved at 5\n",
      "val_losses[-1] = 0.0006233805906958878, best_loss = 0.0006235144101083279, model saved at 6\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.000705244776327163, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000650281086564064, best_loss = 0.000705244776327163, model saved at 1\n",
      "val_losses[-1] = 0.0006349699688144028, best_loss = 0.000650281086564064, model saved at 2\n",
      "val_losses[-1] = 0.0006289411685429513, best_loss = 0.0006349699688144028, model saved at 3\n",
      "val_losses[-1] = 0.0006247773417271674, best_loss = 0.0006289411685429513, model saved at 4\n",
      "val_losses[-1] = 0.0006221936782822013, best_loss = 0.0006247773417271674, model saved at 5\n",
      "val_losses[-1] = 0.000621581042651087, best_loss = 0.0006221936782822013, model saved at 6\n",
      "val_losses[-1] = 0.0006206676480360329, best_loss = 0.000621581042651087, model saved at 7\n",
      "val_losses[-1] = 0.000620409322436899, best_loss = 0.0006206676480360329, model saved at 8\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006234375759959221, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006233666208572686, best_loss = 0.0006234375759959221, model saved at 6\n",
      "val_losses[-1] = 0.0006233350723050535, best_loss = 0.0006233666208572686, model saved at 7\n",
      "val_losses[-1] = 0.0006233219755813479, best_loss = 0.0006233350723050535, model saved at 8\n",
      "val_losses[-1] = 0.0006233184249140322, best_loss = 0.0006233219755813479, model saved at 14\n",
      "val_losses[-1] = 0.000623312487732619, best_loss = 0.0006233184249140322, model saved at 20\n",
      "val_losses[-1] = 0.0006232998566702008, best_loss = 0.000623312487732619, model saved at 23\n",
      "val_losses[-1] = 0.0006232828018255532, best_loss = 0.0006232998566702008, model saved at 29\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007353489636443555, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000653610797598958, best_loss = 0.0007353489636443555, model saved at 1\n",
      "val_losses[-1] = 0.000638163008261472, best_loss = 0.000653610797598958, model saved at 2\n",
      "val_losses[-1] = 0.0006215855246409774, best_loss = 0.000638163008261472, model saved at 3\n",
      "val_losses[-1] = 0.0006127174128778279, best_loss = 0.0006215855246409774, model saved at 4\n",
      "val_losses[-1] = 0.0006106302607804537, best_loss = 0.0006127174128778279, model saved at 5\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006791670457459986, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006255300249904394, best_loss = 0.0006791670457459986, model saved at 1\n",
      "val_losses[-1] = 0.0006113596609793603, best_loss = 0.0006255300249904394, model saved at 2\n",
      "val_losses[-1] = 0.0006096680881455541, best_loss = 0.0006113596609793603, model saved at 3\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006616360624320805, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006361856940202415, best_loss = 0.0006616360624320805, model saved at 1\n",
      "val_losses[-1] = 0.0006268214201554656, best_loss = 0.0006361856940202415, model saved at 2\n",
      "val_losses[-1] = 0.0006242000381462276, best_loss = 0.0006268214201554656, model saved at 3\n",
      "val_losses[-1] = 0.0006237749475985765, best_loss = 0.0006242000381462276, model saved at 4\n",
      "val_losses[-1] = 0.0006235906621441245, best_loss = 0.0006237749475985765, model saved at 5\n",
      "val_losses[-1] = 0.0006233726162463427, best_loss = 0.0006235906621441245, model saved at 6\n",
      "val_losses[-1] = 0.0006233460153453052, best_loss = 0.0006233726162463427, model saved at 8\n",
      "val_losses[-1] = 0.0006233321619220078, best_loss = 0.0006233460153453052, model saved at 9\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006929213413968682, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006423646118491888, best_loss = 0.0006929213413968682, model saved at 1\n",
      "val_losses[-1] = 0.0006283327238634229, best_loss = 0.0006423646118491888, model saved at 2\n",
      "val_losses[-1] = 0.0006282159592956305, best_loss = 0.0006283327238634229, model saved at 3\n",
      "val_losses[-1] = 0.0006265031988732517, best_loss = 0.0006282159592956305, model saved at 4\n",
      "val_losses[-1] = 0.0006245763506740332, best_loss = 0.0006265031988732517, model saved at 5\n",
      "val_losses[-1] = 0.0006219577044248581, best_loss = 0.0006245763506740332, model saved at 6\n",
      "val_losses[-1] = 0.0006210717256180942, best_loss = 0.0006219577044248581, model saved at 7\n",
      "val_losses[-1] = 0.0006197438924573362, best_loss = 0.0006210717256180942, model saved at 8\n",
      "val_losses[-1] = 0.0006196739268489182, best_loss = 0.0006197438924573362, model saved at 9\n",
      "val_losses[-1] = 0.0006193992448970675, best_loss = 0.0006196739268489182, model saved at 10\n",
      "iter 1...\n",
      "val_losses[-1] = 0.000643080216832459, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006320487009361386, best_loss = 0.000643080216832459, model saved at 2\n",
      "val_losses[-1] = 0.0006272937171161175, best_loss = 0.0006320487009361386, model saved at 3\n",
      "val_losses[-1] = 0.0006256679771468043, best_loss = 0.0006272937171161175, model saved at 4\n",
      "val_losses[-1] = 0.0006235814653337002, best_loss = 0.0006256679771468043, model saved at 5\n",
      "val_losses[-1] = 0.0006232024752534926, best_loss = 0.0006235814653337002, model saved at 6\n",
      "val_losses[-1] = 0.0006227231351658702, best_loss = 0.0006232024752534926, model saved at 7\n",
      "val_losses[-1] = 0.0006225670804269612, best_loss = 0.0006227231351658702, model saved at 9\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0010668818140402436, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0007120283553376794, best_loss = 0.0010668818140402436, model saved at 1\n",
      "val_losses[-1] = 0.0006886088522151113, best_loss = 0.0007120283553376794, model saved at 2\n",
      "val_losses[-1] = 0.0006616224418394268, best_loss = 0.0006886088522151113, model saved at 3\n",
      "val_losses[-1] = 0.0006368927424773574, best_loss = 0.0006616224418394268, model saved at 4\n",
      "val_losses[-1] = 0.0006267757853493094, best_loss = 0.0006368927424773574, model saved at 5\n",
      "val_losses[-1] = 0.0006208166596479714, best_loss = 0.0006267757853493094, model saved at 6\n",
      "val_losses[-1] = 0.0006204102537594736, best_loss = 0.0006208166596479714, model saved at 7\n",
      "val_losses[-1] = 0.0006179418996907771, best_loss = 0.0006204102537594736, model saved at 8\n",
      "val_losses[-1] = 0.0006178927142173052, best_loss = 0.0006179418996907771, model saved at 9\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006335359066724777, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006241471273824573, best_loss = 0.0006335359066724777, model saved at 1\n",
      "val_losses[-1] = 0.0006239943322725594, best_loss = 0.0006241471273824573, model saved at 2\n",
      "val_losses[-1] = 0.0006236464250832796, best_loss = 0.0006239943322725594, model saved at 3\n",
      "val_losses[-1] = 0.0006236034678295255, best_loss = 0.0006236464250832796, model saved at 4\n",
      "val_losses[-1] = 0.000623572152107954, best_loss = 0.0006236034678295255, model saved at 5\n",
      "val_losses[-1] = 0.0006234343745745718, best_loss = 0.000623572152107954, model saved at 6\n",
      "val_losses[-1] = 0.0006233980529941618, best_loss = 0.0006234343745745718, model saved at 8\n",
      "val_losses[-1] = 0.0006233666208572686, best_loss = 0.0006233980529941618, model saved at 12\n",
      "val_losses[-1] = 0.0006233658641576767, best_loss = 0.0006233666208572686, model saved at 18\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006620371132157743, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006378187099471688, best_loss = 0.0006620371132157743, model saved at 1\n",
      "val_losses[-1] = 0.0006312052137218416, best_loss = 0.0006378187099471688, model saved at 2\n",
      "val_losses[-1] = 0.0006249405560083687, best_loss = 0.0006312052137218416, model saved at 3\n",
      "val_losses[-1] = 0.0006230681319721043, best_loss = 0.0006249405560083687, model saved at 4\n",
      "val_losses[-1] = 0.0006226575351320207, best_loss = 0.0006230681319721043, model saved at 5\n",
      "val_losses[-1] = 0.000622618361376226, best_loss = 0.0006226575351320207, model saved at 6\n",
      "(0.2, 0.8)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006657472695223987, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006376784876920283, best_loss = 0.0006657472695223987, model saved at 1\n",
      "val_losses[-1] = 0.0006309605087153614, best_loss = 0.0006376784876920283, model saved at 2\n",
      "val_losses[-1] = 0.0006278879009187222, best_loss = 0.0006309605087153614, model saved at 3\n",
      "val_losses[-1] = 0.0006267540738917887, best_loss = 0.0006278879009187222, model saved at 4\n",
      "val_losses[-1] = 0.000625326472800225, best_loss = 0.0006267540738917887, model saved at 5\n",
      "val_losses[-1] = 0.0006235098699107766, best_loss = 0.000625326472800225, model saved at 6\n",
      "val_losses[-1] = 0.0006226254045031965, best_loss = 0.0006235098699107766, model saved at 7\n",
      "val_losses[-1] = 0.0006222490919753909, best_loss = 0.0006226254045031965, model saved at 8\n",
      "val_losses[-1] = 0.0006217677146196365, best_loss = 0.0006222490919753909, model saved at 9\n",
      "val_losses[-1] = 0.0006215086323209107, best_loss = 0.0006217677146196365, model saved at 10\n",
      "val_losses[-1] = 0.0006213391898199916, best_loss = 0.0006215086323209107, model saved at 11\n",
      "val_losses[-1] = 0.0006211397121660411, best_loss = 0.0006213391898199916, model saved at 12\n",
      "val_losses[-1] = 0.0006210581632331014, best_loss = 0.0006211397121660411, model saved at 13\n",
      "val_losses[-1] = 0.0006210244609974325, best_loss = 0.0006210581632331014, model saved at 14\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006242251256480813, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006235815235413611, best_loss = 0.0006242251256480813, model saved at 5\n",
      "val_losses[-1] = 0.0006232762825675309, best_loss = 0.0006235815235413611, model saved at 6\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007820292958058417, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006846851902082562, best_loss = 0.0007820292958058417, model saved at 1\n",
      "val_losses[-1] = 0.0006450998480431736, best_loss = 0.0006846851902082562, model saved at 2\n",
      "val_losses[-1] = 0.0006339360843412578, best_loss = 0.0006450998480431736, model saved at 3\n",
      "val_losses[-1] = 0.0006266261334531009, best_loss = 0.0006339360843412578, model saved at 4\n",
      "val_losses[-1] = 0.0006217755726538599, best_loss = 0.0006266261334531009, model saved at 5\n",
      "val_losses[-1] = 0.0006181317148730159, best_loss = 0.0006217755726538599, model saved at 6\n",
      "val_losses[-1] = 0.0006152669666334987, best_loss = 0.0006181317148730159, model saved at 7\n",
      "val_losses[-1] = 0.0006136602023616433, best_loss = 0.0006152669666334987, model saved at 8\n",
      "val_losses[-1] = 0.0006132983253337443, best_loss = 0.0006136602023616433, model saved at 9\n",
      "iter 3...\n",
      "val_losses[-1] = 0.000748173741158098, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006387250032275915, best_loss = 0.000748173741158098, model saved at 1\n",
      "val_losses[-1] = 0.0006363693973980844, best_loss = 0.0006387250032275915, model saved at 2\n",
      "val_losses[-1] = 0.0006237433990463614, best_loss = 0.0006363693973980844, model saved at 3\n",
      "val_losses[-1] = 0.0006217285990715027, best_loss = 0.0006237433990463614, model saved at 5\n",
      "val_losses[-1] = 0.00061945547349751, best_loss = 0.0006217285990715027, model saved at 7\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006454997346736491, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000628245179541409, best_loss = 0.0006454997346736491, model saved at 1\n",
      "val_losses[-1] = 0.000625504064373672, best_loss = 0.000628245179541409, model saved at 2\n",
      "val_losses[-1] = 0.0006248390418477356, best_loss = 0.000625504064373672, model saved at 3\n",
      "val_losses[-1] = 0.0006246615666896105, best_loss = 0.0006248390418477356, model saved at 4\n",
      "val_losses[-1] = 0.0006237542256712914, best_loss = 0.0006246615666896105, model saved at 5\n",
      "val_losses[-1] = 0.000623696600086987, best_loss = 0.0006237542256712914, model saved at 6\n",
      "val_losses[-1] = 0.0006234103930182755, best_loss = 0.000623696600086987, model saved at 7\n",
      "val_losses[-1] = 0.0006233783205971122, best_loss = 0.0006234103930182755, model saved at 8\n",
      "val_losses[-1] = 0.0006233443273231387, best_loss = 0.0006233783205971122, model saved at 11\n",
      "val_losses[-1] = 0.0006232995656318963, best_loss = 0.0006233443273231387, model saved at 12\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006649742717854679, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006312759942375124, best_loss = 0.0006649742717854679, model saved at 1\n",
      "val_losses[-1] = 0.0006246372358873487, best_loss = 0.0006312759942375124, model saved at 2\n",
      "val_losses[-1] = 0.0006226070690900087, best_loss = 0.0006246372358873487, model saved at 3\n",
      "val_losses[-1] = 0.0006216978072188795, best_loss = 0.0006226070690900087, model saved at 4\n",
      "val_losses[-1] = 0.0006188327097333968, best_loss = 0.0006216978072188795, model saved at 5\n",
      "val_losses[-1] = 0.0006170367123559117, best_loss = 0.0006188327097333968, model saved at 6\n",
      "val_losses[-1] = 0.0006158736068755388, best_loss = 0.0006170367123559117, model saved at 7\n",
      "val_losses[-1] = 0.0006146890809759498, best_loss = 0.0006158736068755388, model saved at 8\n",
      "val_losses[-1] = 0.0006141220219433308, best_loss = 0.0006146890809759498, model saved at 9\n",
      "val_losses[-1] = 0.0006140921032056212, best_loss = 0.0006141220219433308, model saved at 10\n",
      "val_losses[-1] = 0.0006138146272860467, best_loss = 0.0006140921032056212, model saved at 11\n",
      "val_losses[-1] = 0.0006136628799140453, best_loss = 0.0006138146272860467, model saved at 12\n",
      "val_losses[-1] = 0.0006132893031463027, best_loss = 0.0006136628799140453, model saved at 13\n",
      "val_losses[-1] = 0.00061298708897084, best_loss = 0.0006132893031463027, model saved at 15\n",
      "val_losses[-1] = 0.0006126058869995177, best_loss = 0.00061298708897084, model saved at 16\n",
      "val_losses[-1] = 0.0006120698526501656, best_loss = 0.0006126058869995177, model saved at 17\n",
      "val_losses[-1] = 0.000611914147157222, best_loss = 0.0006120698526501656, model saved at 18\n",
      "val_losses[-1] = 0.00061181397177279, best_loss = 0.000611914147157222, model saved at 19\n",
      "val_losses[-1] = 0.0006112739793024957, best_loss = 0.00061181397177279, model saved at 20\n",
      "val_losses[-1] = 0.000610167277045548, best_loss = 0.0006112739793024957, model saved at 21\n",
      "val_losses[-1] = 0.0006091304821893573, best_loss = 0.000610167277045548, model saved at 22\n",
      "val_losses[-1] = 0.0006085154600441456, best_loss = 0.0006091304821893573, model saved at 23\n",
      "val_losses[-1] = 0.0006079747108742595, best_loss = 0.0006085154600441456, model saved at 24\n",
      "val_losses[-1] = 0.0006073605036363006, best_loss = 0.0006079747108742595, model saved at 25\n",
      "val_losses[-1] = 0.0006069891969673336, best_loss = 0.0006073605036363006, model saved at 27\n",
      "val_losses[-1] = 0.0006066365167498589, best_loss = 0.0006069891969673336, model saved at 28\n",
      "val_losses[-1] = 0.0006064875051379204, best_loss = 0.0006066365167498589, model saved at 29\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0013422578340396285, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006346304435282946, best_loss = 0.0013422578340396285, model saved at 1\n",
      "val_losses[-1] = 0.0006331289187073708, best_loss = 0.0006346304435282946, model saved at 2\n",
      "val_losses[-1] = 0.0006288192817009985, best_loss = 0.0006331289187073708, model saved at 3\n",
      "val_losses[-1] = 0.000628226378466934, best_loss = 0.0006288192817009985, model saved at 4\n",
      "val_losses[-1] = 0.0006260784575715661, best_loss = 0.000628226378466934, model saved at 5\n",
      "val_losses[-1] = 0.0006254111649468541, best_loss = 0.0006260784575715661, model saved at 6\n",
      "val_losses[-1] = 0.0006240319926291704, best_loss = 0.0006254111649468541, model saved at 7\n",
      "val_losses[-1] = 0.0006234649918042123, best_loss = 0.0006240319926291704, model saved at 9\n",
      "val_losses[-1] = 0.0006233690655790269, best_loss = 0.0006234649918042123, model saved at 10\n",
      "val_losses[-1] = 0.0006233403109945357, best_loss = 0.0006233690655790269, model saved at 18\n",
      "val_losses[-1] = 0.0006233243620954454, best_loss = 0.0006233403109945357, model saved at 22\n",
      "val_losses[-1] = 0.0006233183667063713, best_loss = 0.0006233243620954454, model saved at 25\n",
      "val_losses[-1] = 0.0006233169115148485, best_loss = 0.0006233183667063713, model saved at 26\n",
      "iter 2...\n",
      "val_losses[-1] = 0.000799653644207865, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006954169366508722, best_loss = 0.000799653644207865, model saved at 1\n",
      "val_losses[-1] = 0.0006365018198266625, best_loss = 0.0006954169366508722, model saved at 2\n",
      "val_losses[-1] = 0.0006315609207376838, best_loss = 0.0006365018198266625, model saved at 3\n",
      "val_losses[-1] = 0.000618747784756124, best_loss = 0.0006315609207376838, model saved at 4\n",
      "val_losses[-1] = 0.0006145022925920784, best_loss = 0.000618747784756124, model saved at 5\n",
      "val_losses[-1] = 0.0006100776372477412, best_loss = 0.0006145022925920784, model saved at 6\n",
      "val_losses[-1] = 0.0006092765252105892, best_loss = 0.0006100776372477412, model saved at 7\n",
      "val_losses[-1] = 0.0006089733215048909, best_loss = 0.0006092765252105892, model saved at 8\n",
      "val_losses[-1] = 0.000608391419518739, best_loss = 0.0006089733215048909, model saved at 9\n",
      "val_losses[-1] = 0.0006078193546272814, best_loss = 0.000608391419518739, model saved at 10\n",
      "val_losses[-1] = 0.0006077610305510461, best_loss = 0.0006078193546272814, model saved at 11\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006734292255714536, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006156456074677408, best_loss = 0.0006734292255714536, model saved at 1\n",
      "val_losses[-1] = 0.0006068847142159939, best_loss = 0.0006156456074677408, model saved at 2\n",
      "val_losses[-1] = 0.0006059793522581458, best_loss = 0.0006068847142159939, model saved at 3\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006479027797468007, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006314205820672214, best_loss = 0.0006479027797468007, model saved at 1\n",
      "val_losses[-1] = 0.0006206014659255743, best_loss = 0.0006314205820672214, model saved at 2\n",
      "val_losses[-1] = 0.0006186968530528247, best_loss = 0.0006206014659255743, model saved at 3\n",
      "val_losses[-1] = 0.0006178094772621989, best_loss = 0.0006186968530528247, model saved at 4\n",
      "val_losses[-1] = 0.0006168335676193237, best_loss = 0.0006178094772621989, model saved at 5\n",
      "val_losses[-1] = 0.0006161562632769346, best_loss = 0.0006168335676193237, model saved at 6\n",
      "val_losses[-1] = 0.0006152613204903901, best_loss = 0.0006161562632769346, model saved at 7\n",
      "val_losses[-1] = 0.0006139419856481254, best_loss = 0.0006152613204903901, model saved at 8\n",
      "val_losses[-1] = 0.0006125636864453554, best_loss = 0.0006139419856481254, model saved at 9\n",
      "val_losses[-1] = 0.0006113624549470842, best_loss = 0.0006125636864453554, model saved at 10\n",
      "val_losses[-1] = 0.0006097837467677891, best_loss = 0.0006113624549470842, model saved at 11\n",
      "val_losses[-1] = 0.0006085410132072866, best_loss = 0.0006097837467677891, model saved at 12\n",
      "val_losses[-1] = 0.0006076571880839765, best_loss = 0.0006085410132072866, model saved at 13\n",
      "val_losses[-1] = 0.0006060297600924969, best_loss = 0.0006076571880839765, model saved at 14\n",
      "val_losses[-1] = 0.0006056404672563076, best_loss = 0.0006060297600924969, model saved at 15\n",
      "val_losses[-1] = 0.0006050102529115975, best_loss = 0.0006056404672563076, model saved at 16\n",
      "val_losses[-1] = 0.0006047369679436088, best_loss = 0.0006050102529115975, model saved at 17\n",
      "val_losses[-1] = 0.000603690161369741, best_loss = 0.0006047369679436088, model saved at 18\n",
      "val_losses[-1] = 0.0006027680356055498, best_loss = 0.000603690161369741, model saved at 19\n",
      "val_losses[-1] = 0.0006023428286425769, best_loss = 0.0006027680356055498, model saved at 20\n",
      "val_losses[-1] = 0.0006017511477693915, best_loss = 0.0006023428286425769, model saved at 21\n",
      "val_losses[-1] = 0.0006013938109390438, best_loss = 0.0006017511477693915, model saved at 23\n",
      "val_losses[-1] = 0.0006010931683704257, best_loss = 0.0006013938109390438, model saved at 24\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006689722649753094, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006269497098401189, best_loss = 0.0006689722649753094, model saved at 1\n",
      "val_losses[-1] = 0.0006203416851349175, best_loss = 0.0006269497098401189, model saved at 2\n",
      "val_losses[-1] = 0.000619018857832998, best_loss = 0.0006203416851349175, model saved at 4\n",
      "val_losses[-1] = 0.0006158900214359164, best_loss = 0.000619018857832998, model saved at 5\n",
      "val_losses[-1] = 0.0006109016248956323, best_loss = 0.0006158900214359164, model saved at 6\n",
      "val_losses[-1] = 0.0006098676822148263, best_loss = 0.0006109016248956323, model saved at 7\n",
      "val_losses[-1] = 0.0006081829196773469, best_loss = 0.0006098676822148263, model saved at 8\n",
      "val_losses[-1] = 0.0006079815211705863, best_loss = 0.0006081829196773469, model saved at 9\n",
      "val_losses[-1] = 0.0006068951333872974, best_loss = 0.0006079815211705863, model saved at 26\n",
      "val_losses[-1] = 0.0006032122764736414, best_loss = 0.0006068951333872974, model saved at 27\n",
      "val_losses[-1] = 0.0006007809424772859, best_loss = 0.0006032122764736414, model saved at 28\n",
      "val_losses[-1] = 0.0005989256897009909, best_loss = 0.0006007809424772859, model saved at 29\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0007419820176437497, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006964729400351644, best_loss = 0.0007419820176437497, model saved at 1\n",
      "val_losses[-1] = 0.0006585220107808709, best_loss = 0.0006964729400351644, model saved at 2\n",
      "val_losses[-1] = 0.0006563615752384067, best_loss = 0.0006585220107808709, model saved at 3\n",
      "val_losses[-1] = 0.0006360378465615213, best_loss = 0.0006563615752384067, model saved at 4\n",
      "val_losses[-1] = 0.0006316655781120062, best_loss = 0.0006360378465615213, model saved at 5\n",
      "val_losses[-1] = 0.0006277429638430476, best_loss = 0.0006316655781120062, model saved at 6\n",
      "val_losses[-1] = 0.0006273345788940787, best_loss = 0.0006277429638430476, model saved at 7\n",
      "val_losses[-1] = 0.0006263942341320217, best_loss = 0.0006273345788940787, model saved at 8\n",
      "val_losses[-1] = 0.0006257231580093503, best_loss = 0.0006263942341320217, model saved at 10\n",
      "val_losses[-1] = 0.0006246899720281363, best_loss = 0.0006257231580093503, model saved at 12\n",
      "val_losses[-1] = 0.0006242404342629015, best_loss = 0.0006246899720281363, model saved at 13\n",
      "val_losses[-1] = 0.0006237049819901586, best_loss = 0.0006242404342629015, model saved at 14\n",
      "val_losses[-1] = 0.0006236443878151476, best_loss = 0.0006237049819901586, model saved at 15\n",
      "val_losses[-1] = 0.0006235123728401959, best_loss = 0.0006236443878151476, model saved at 17\n",
      "val_losses[-1] = 0.0006234995671547949, best_loss = 0.0006235123728401959, model saved at 18\n",
      "val_losses[-1] = 0.0006234740139916539, best_loss = 0.0006234995671547949, model saved at 20\n",
      "val_losses[-1] = 0.0006233888561837375, best_loss = 0.0006234740139916539, model saved at 21\n",
      "val_losses[-1] = 0.0006233706371858716, best_loss = 0.0006233888561837375, model saved at 29\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0008467902662232518, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000715537928044796, best_loss = 0.0008467902662232518, model saved at 1\n",
      "val_losses[-1] = 0.0007081152871251106, best_loss = 0.000715537928044796, model saved at 2\n",
      "val_losses[-1] = 0.0006660821964032948, best_loss = 0.0007081152871251106, model saved at 3\n",
      "val_losses[-1] = 0.0006459002033807337, best_loss = 0.0006660821964032948, model saved at 4\n",
      "val_losses[-1] = 0.0006255941116251051, best_loss = 0.0006459002033807337, model saved at 5\n",
      "val_losses[-1] = 0.0006109433597885072, best_loss = 0.0006255941116251051, model saved at 6\n",
      "val_losses[-1] = 0.0006054664263501763, best_loss = 0.0006109433597885072, model saved at 7\n",
      "val_losses[-1] = 0.0005975054227747023, best_loss = 0.0006054664263501763, model saved at 8\n",
      "val_losses[-1] = 0.0005967197939753532, best_loss = 0.0005975054227747023, model saved at 9\n",
      "val_losses[-1] = 0.0005953123909421265, best_loss = 0.0005967197939753532, model saved at 10\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006312518962658942, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006239463109523058, best_loss = 0.0006312518962658942, model saved at 1\n",
      "val_losses[-1] = 0.0006236029439605772, best_loss = 0.0006239463109523058, model saved at 2\n",
      "val_losses[-1] = 0.000623420812189579, best_loss = 0.0006236029439605772, model saved at 3\n",
      "val_losses[-1] = 0.0006233148742467165, best_loss = 0.000623420812189579, model saved at 5\n",
      "val_losses[-1] = 0.0006231868756003678, best_loss = 0.0006233148742467165, model saved at 11\n",
      "val_losses[-1] = 0.0006231357692740858, best_loss = 0.0006231868756003678, model saved at 15\n",
      "val_losses[-1] = 0.0006230977596715093, best_loss = 0.0006231357692740858, model saved at 16\n",
      "val_losses[-1] = 0.0006230859435163438, best_loss = 0.0006230977596715093, model saved at 17\n",
      "val_losses[-1] = 0.0006230745348148048, best_loss = 0.0006230859435163438, model saved at 18\n",
      "val_losses[-1] = 0.0006230322760529816, best_loss = 0.0006230745348148048, model saved at 19\n",
      "val_losses[-1] = 0.0006230095168575644, best_loss = 0.0006230322760529816, model saved at 20\n",
      "val_losses[-1] = 0.0006229927530512214, best_loss = 0.0006230095168575644, model saved at 21\n",
      "val_losses[-1] = 0.0006229382124729455, best_loss = 0.0006229927530512214, model saved at 22\n",
      "val_losses[-1] = 0.0006228767451830208, best_loss = 0.0006229382124729455, model saved at 23\n",
      "val_losses[-1] = 0.0006228760466910899, best_loss = 0.0006228767451830208, model saved at 24\n",
      "val_losses[-1] = 0.0006228687125258148, best_loss = 0.0006228760466910899, model saved at 25\n",
      "val_losses[-1] = 0.0006227168487384915, best_loss = 0.0006228687125258148, model saved at 26\n",
      "val_losses[-1] = 0.0006225474644452333, best_loss = 0.0006227168487384915, model saved at 27\n",
      "val_losses[-1] = 0.0006222998490557075, best_loss = 0.0006225474644452333, model saved at 28\n",
      "val_losses[-1] = 0.0006220307550393045, best_loss = 0.0006222998490557075, model saved at 29\n",
      "iter 4...\n",
      "val_losses[-1] = 0.000638117897324264, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006273826584219933, best_loss = 0.000638117897324264, model saved at 1\n",
      "val_losses[-1] = 0.0006201767828315496, best_loss = 0.0006273826584219933, model saved at 2\n",
      "val_losses[-1] = 0.0006177539471536875, best_loss = 0.0006201767828315496, model saved at 3\n",
      "val_losses[-1] = 0.0006168030668050051, best_loss = 0.0006177539471536875, model saved at 4\n",
      "val_losses[-1] = 0.000615627970546484, best_loss = 0.0006168030668050051, model saved at 5\n",
      "val_losses[-1] = 0.0006145010120235384, best_loss = 0.000615627970546484, model saved at 6\n",
      "val_losses[-1] = 0.0006131351110525429, best_loss = 0.0006145010120235384, model saved at 7\n",
      "val_losses[-1] = 0.0006116812583059072, best_loss = 0.0006131351110525429, model saved at 8\n",
      "val_losses[-1] = 0.0006095839780755341, best_loss = 0.0006116812583059072, model saved at 9\n",
      "val_losses[-1] = 0.0006065049092285335, best_loss = 0.0006095839780755341, model saved at 10\n",
      "val_losses[-1] = 0.0006014093523845077, best_loss = 0.0006065049092285335, model saved at 12\n",
      "val_losses[-1] = 0.0005025944556109607, best_loss = 0.0006014093523845077, model saved at 13\n",
      "val_losses[-1] = 0.0004012961871922016, best_loss = 0.0005025944556109607, model saved at 14\n",
      "val_losses[-1] = 0.0003332639462314546, best_loss = 0.0004012961871922016, model saved at 15\n",
      "val_losses[-1] = 0.0003106843214482069, best_loss = 0.0003332639462314546, model saved at 16\n",
      "val_losses[-1] = 0.000280985637800768, best_loss = 0.0003106843214482069, model saved at 17\n",
      "val_losses[-1] = 0.000273907178780064, best_loss = 0.000280985637800768, model saved at 18\n",
      "val_losses[-1] = 0.0002684580977074802, best_loss = 0.000273907178780064, model saved at 21\n",
      "val_losses[-1] = 0.0002631991228554398, best_loss = 0.0002684580977074802, model saved at 22\n",
      "val_losses[-1] = 0.0002617284480948001, best_loss = 0.0002631991228554398, model saved at 27\n",
      "val_losses[-1] = 0.00025701176491566, best_loss = 0.0002617284480948001, model saved at 28\n",
      "(0.3, 0.7)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006528352969326079, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000631073780823499, best_loss = 0.0006528352969326079, model saved at 1\n",
      "val_losses[-1] = 0.0006284664268605411, best_loss = 0.000631073780823499, model saved at 2\n",
      "val_losses[-1] = 0.0006257732165977359, best_loss = 0.0006284664268605411, model saved at 3\n",
      "val_losses[-1] = 0.0006244287942536175, best_loss = 0.0006257732165977359, model saved at 4\n",
      "val_losses[-1] = 0.0006239153444766998, best_loss = 0.0006244287942536175, model saved at 6\n",
      "val_losses[-1] = 0.0006226971745491028, best_loss = 0.0006239153444766998, model saved at 7\n",
      "val_losses[-1] = 0.0006223879754543304, best_loss = 0.0006226971745491028, model saved at 8\n",
      "val_losses[-1] = 0.0006220843642950058, best_loss = 0.0006223879754543304, model saved at 9\n",
      "val_losses[-1] = 0.0006218922208063304, best_loss = 0.0006220843642950058, model saved at 10\n",
      "val_losses[-1] = 0.0006218060152605176, best_loss = 0.0006218922208063304, model saved at 11\n",
      "val_losses[-1] = 0.0006217513582669199, best_loss = 0.0006218060152605176, model saved at 12\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006627383409067988, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006256774649955332, best_loss = 0.0006627383409067988, model saved at 1\n",
      "val_losses[-1] = 0.000621274986770004, best_loss = 0.0006256774649955332, model saved at 2\n",
      "val_losses[-1] = 0.0006192925502546132, best_loss = 0.000621274986770004, model saved at 3\n",
      "val_losses[-1] = 0.0006185386446304619, best_loss = 0.0006192925502546132, model saved at 4\n",
      "val_losses[-1] = 0.0006183071527630091, best_loss = 0.0006185386446304619, model saved at 5\n",
      "val_losses[-1] = 0.0006182173965498805, best_loss = 0.0006183071527630091, model saved at 6\n",
      "val_losses[-1] = 0.0006181037169881165, best_loss = 0.0006182173965498805, model saved at 8\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007710939389653504, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006829329649917781, best_loss = 0.0007710939389653504, model saved at 1\n",
      "val_losses[-1] = 0.0006408425397239625, best_loss = 0.0006829329649917781, model saved at 2\n",
      "val_losses[-1] = 0.0006328698946163058, best_loss = 0.0006408425397239625, model saved at 3\n",
      "val_losses[-1] = 0.0006287118885666132, best_loss = 0.0006328698946163058, model saved at 4\n",
      "val_losses[-1] = 0.0006252509774640203, best_loss = 0.0006287118885666132, model saved at 5\n",
      "val_losses[-1] = 0.0006215908797457814, best_loss = 0.0006252509774640203, model saved at 6\n",
      "val_losses[-1] = 0.0006199394119903445, best_loss = 0.0006215908797457814, model saved at 7\n",
      "val_losses[-1] = 0.0006192101864144206, best_loss = 0.0006199394119903445, model saved at 8\n",
      "val_losses[-1] = 0.0006181832286529243, best_loss = 0.0006192101864144206, model saved at 10\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0007148588774725795, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000638010329566896, best_loss = 0.0007148588774725795, model saved at 1\n",
      "val_losses[-1] = 0.0006358852842822671, best_loss = 0.000638010329566896, model saved at 2\n",
      "val_losses[-1] = 0.0006242539966478944, best_loss = 0.0006358852842822671, model saved at 3\n",
      "val_losses[-1] = 0.0006203916273079813, best_loss = 0.0006242539966478944, model saved at 4\n",
      "val_losses[-1] = 0.0006192998262122273, best_loss = 0.0006203916273079813, model saved at 5\n",
      "val_losses[-1] = 0.0006187898688949645, best_loss = 0.0006192998262122273, model saved at 7\n",
      "val_losses[-1] = 0.0006186850368976593, best_loss = 0.0006187898688949645, model saved at 8\n",
      "val_losses[-1] = 0.0006179852643981576, best_loss = 0.0006186850368976593, model saved at 9\n",
      "val_losses[-1] = 0.0006173534202389419, best_loss = 0.0006179852643981576, model saved at 10\n",
      "val_losses[-1] = 0.0006171744898892939, best_loss = 0.0006173534202389419, model saved at 11\n",
      "val_losses[-1] = 0.0006169691332615912, best_loss = 0.0006171744898892939, model saved at 12\n",
      "val_losses[-1] = 0.000616717035882175, best_loss = 0.0006169691332615912, model saved at 14\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006419502315111458, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006262011593207717, best_loss = 0.0006419502315111458, model saved at 1\n",
      "val_losses[-1] = 0.0006244785035960376, best_loss = 0.0006262011593207717, model saved at 2\n",
      "val_losses[-1] = 0.000624477572273463, best_loss = 0.0006244785035960376, model saved at 4\n",
      "val_losses[-1] = 0.0006232751766219735, best_loss = 0.000624477572273463, model saved at 5\n",
      "val_losses[-1] = 0.0006228361744433641, best_loss = 0.0006232751766219735, model saved at 6\n",
      "val_losses[-1] = 0.0006227554986253381, best_loss = 0.0006228361744433641, model saved at 7\n",
      "val_losses[-1] = 0.0006227076519280672, best_loss = 0.0006227554986253381, model saved at 8\n",
      "val_losses[-1] = 0.0006226846599020064, best_loss = 0.0006227076519280672, model saved at 9\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006463323370553553, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000631956965662539, best_loss = 0.0006463323370553553, model saved at 1\n",
      "val_losses[-1] = 0.0006316817598417401, best_loss = 0.000631956965662539, model saved at 2\n",
      "val_losses[-1] = 0.0006255109328776598, best_loss = 0.0006316817598417401, model saved at 3\n",
      "val_losses[-1] = 0.0006250858423300087, best_loss = 0.0006255109328776598, model saved at 4\n",
      "val_losses[-1] = 0.0006221821531653404, best_loss = 0.0006250858423300087, model saved at 5\n",
      "val_losses[-1] = 0.0006199091440066695, best_loss = 0.0006221821531653404, model saved at 6\n",
      "val_losses[-1] = 0.0006183380028232932, best_loss = 0.0006199091440066695, model saved at 7\n",
      "val_losses[-1] = 0.0006174518493935466, best_loss = 0.0006183380028232932, model saved at 8\n",
      "val_losses[-1] = 0.0006166397943161428, best_loss = 0.0006174518493935466, model saved at 9\n",
      "val_losses[-1] = 0.0006165792583487928, best_loss = 0.0006166397943161428, model saved at 10\n",
      "val_losses[-1] = 0.000615753117017448, best_loss = 0.0006165792583487928, model saved at 11\n",
      "val_losses[-1] = 0.000615095894318074, best_loss = 0.000615753117017448, model saved at 12\n",
      "val_losses[-1] = 0.0006144209764897823, best_loss = 0.000615095894318074, model saved at 13\n",
      "val_losses[-1] = 0.0006142780184745789, best_loss = 0.0006144209764897823, model saved at 14\n",
      "val_losses[-1] = 0.0006139680626802146, best_loss = 0.0006142780184745789, model saved at 15\n",
      "val_losses[-1] = 0.0006136161973699927, best_loss = 0.0006139680626802146, model saved at 16\n",
      "val_losses[-1] = 0.0006130434339866042, best_loss = 0.0006136161973699927, model saved at 17\n",
      "val_losses[-1] = 0.0006129511748440564, best_loss = 0.0006130434339866042, model saved at 18\n",
      "val_losses[-1] = 0.0006121131591498852, best_loss = 0.0006129511748440564, model saved at 19\n",
      "val_losses[-1] = 0.000611277821008116, best_loss = 0.0006121131591498852, model saved at 20\n",
      "val_losses[-1] = 0.0006101165199652314, best_loss = 0.000611277821008116, model saved at 21\n",
      "val_losses[-1] = 0.0006090220995247364, best_loss = 0.0006101165199652314, model saved at 22\n",
      "val_losses[-1] = 0.0006077656289562583, best_loss = 0.0006090220995247364, model saved at 23\n",
      "val_losses[-1] = 0.0006068355869501829, best_loss = 0.0006077656289562583, model saved at 24\n",
      "val_losses[-1] = 0.0006052019889466465, best_loss = 0.0006068355869501829, model saved at 25\n",
      "val_losses[-1] = 0.0006040994194336236, best_loss = 0.0006052019889466465, model saved at 26\n",
      "val_losses[-1] = 0.0006019067368470132, best_loss = 0.0006040994194336236, model saved at 27\n",
      "val_losses[-1] = 0.0005949737969785929, best_loss = 0.0006019067368470132, model saved at 28\n",
      "val_losses[-1] = 0.0005387663841247559, best_loss = 0.0005949737969785929, model saved at 29\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0008761098142713308, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006266870768740773, best_loss = 0.0008761098142713308, model saved at 1\n",
      "val_losses[-1] = 0.0006226386176422238, best_loss = 0.0006266870768740773, model saved at 2\n",
      "val_losses[-1] = 0.0006225514225661755, best_loss = 0.0006226386176422238, model saved at 4\n",
      "val_losses[-1] = 0.0006222822121344507, best_loss = 0.0006225514225661755, model saved at 5\n",
      "val_losses[-1] = 0.0006216410547494888, best_loss = 0.0006222822121344507, model saved at 6\n",
      "val_losses[-1] = 0.0006205085664987564, best_loss = 0.0006216410547494888, model saved at 7\n",
      "val_losses[-1] = 0.0006161436322145164, best_loss = 0.0006205085664987564, model saved at 8\n",
      "val_losses[-1] = 0.0006125607760623097, best_loss = 0.0006161436322145164, model saved at 9\n",
      "val_losses[-1] = 0.0006092782132327557, best_loss = 0.0006125607760623097, model saved at 10\n",
      "val_losses[-1] = 0.000606297398917377, best_loss = 0.0006092782132327557, model saved at 11\n",
      "val_losses[-1] = 0.0006049234070815146, best_loss = 0.000606297398917377, model saved at 12\n",
      "val_losses[-1] = 0.0006026740884408355, best_loss = 0.0006049234070815146, model saved at 13\n",
      "val_losses[-1] = 0.0006008346099406481, best_loss = 0.0006026740884408355, model saved at 14\n",
      "val_losses[-1] = 0.0006005995674058795, best_loss = 0.0006008346099406481, model saved at 16\n",
      "val_losses[-1] = 0.0006002960726618767, best_loss = 0.0006005995674058795, model saved at 17\n",
      "val_losses[-1] = 0.0005985821480862796, best_loss = 0.0006002960726618767, model saved at 18\n",
      "val_losses[-1] = 0.0005982067086733878, best_loss = 0.0005985821480862796, model saved at 21\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0008066290174610913, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006750869797542691, best_loss = 0.0008066290174610913, model saved at 1\n",
      "val_losses[-1] = 0.0006207177066244185, best_loss = 0.0006750869797542691, model saved at 2\n",
      "val_losses[-1] = 0.0006061687017790973, best_loss = 0.0006207177066244185, model saved at 3\n",
      "val_losses[-1] = 0.0005948801408521831, best_loss = 0.0006061687017790973, model saved at 4\n",
      "val_losses[-1] = 0.0005912090418860316, best_loss = 0.0005948801408521831, model saved at 5\n",
      "val_losses[-1] = 0.0005883353878743947, best_loss = 0.0005912090418860316, model saved at 6\n",
      "val_losses[-1] = 0.0005849305889569223, best_loss = 0.0005883353878743947, model saved at 7\n",
      "val_losses[-1] = 0.0005751018179580569, best_loss = 0.0005849305889569223, model saved at 8\n",
      "val_losses[-1] = 0.0005055259680375457, best_loss = 0.0005751018179580569, model saved at 9\n",
      "val_losses[-1] = 0.00041256941040046513, best_loss = 0.0005055259680375457, model saved at 10\n",
      "val_losses[-1] = 0.00037210772279649973, best_loss = 0.00041256941040046513, model saved at 11\n",
      "val_losses[-1] = 0.0003582396893762052, best_loss = 0.00037210772279649973, model saved at 12\n",
      "val_losses[-1] = 0.0003556827432475984, best_loss = 0.0003582396893762052, model saved at 13\n",
      "val_losses[-1] = 0.0003447866765782237, best_loss = 0.0003556827432475984, model saved at 14\n",
      "val_losses[-1] = 0.0003409171476960182, best_loss = 0.0003447866765782237, model saved at 15\n",
      "val_losses[-1] = 0.00033579295268282294, best_loss = 0.0003409171476960182, model saved at 17\n",
      "val_losses[-1] = 0.0003329004975967109, best_loss = 0.00033579295268282294, model saved at 19\n",
      "val_losses[-1] = 0.000329813570715487, best_loss = 0.0003329004975967109, model saved at 22\n",
      "val_losses[-1] = 0.00032790316618047655, best_loss = 0.000329813570715487, model saved at 25\n",
      "val_losses[-1] = 0.0003252218593843281, best_loss = 0.00032790316618047655, model saved at 27\n",
      "val_losses[-1] = 0.0003200895735062659, best_loss = 0.0003252218593843281, model saved at 29\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006396697135642171, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006121854530647397, best_loss = 0.0006396697135642171, model saved at 1\n",
      "val_losses[-1] = 0.0006032977835275233, best_loss = 0.0006121854530647397, model saved at 2\n",
      "val_losses[-1] = 0.000601628387812525, best_loss = 0.0006032977835275233, model saved at 3\n",
      "val_losses[-1] = 0.0006011907244101167, best_loss = 0.000601628387812525, model saved at 5\n",
      "val_losses[-1] = 0.0005948187899775803, best_loss = 0.0006011907244101167, model saved at 10\n",
      "val_losses[-1] = 0.0005021335673518479, best_loss = 0.0005948187899775803, model saved at 11\n",
      "val_losses[-1] = 0.00041157237137667835, best_loss = 0.0005021335673518479, model saved at 12\n",
      "val_losses[-1] = 0.000372157315723598, best_loss = 0.00041157237137667835, model saved at 13\n",
      "val_losses[-1] = 0.0003587199025787413, best_loss = 0.000372157315723598, model saved at 14\n",
      "val_losses[-1] = 0.0003406434552744031, best_loss = 0.0003587199025787413, model saved at 15\n",
      "val_losses[-1] = 0.00033874186920002103, best_loss = 0.0003406434552744031, model saved at 16\n",
      "val_losses[-1] = 0.0003317784867249429, best_loss = 0.00033874186920002103, model saved at 17\n",
      "val_losses[-1] = 0.0003251401649322361, best_loss = 0.0003317784867249429, model saved at 21\n",
      "val_losses[-1] = 0.00031745253363624215, best_loss = 0.0003251401649322361, model saved at 23\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006473300745710731, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006273112376220524, best_loss = 0.0006473300745710731, model saved at 1\n",
      "val_losses[-1] = 0.0006250411970540881, best_loss = 0.0006273112376220524, model saved at 2\n",
      "val_losses[-1] = 0.0006242715171538293, best_loss = 0.0006250411970540881, model saved at 3\n",
      "val_losses[-1] = 0.0006212553125806153, best_loss = 0.0006242715171538293, model saved at 5\n",
      "val_losses[-1] = 0.0006202758522704244, best_loss = 0.0006212553125806153, model saved at 6\n",
      "val_losses[-1] = 0.000618786783888936, best_loss = 0.0006202758522704244, model saved at 7\n",
      "val_losses[-1] = 0.0006181644275784492, best_loss = 0.000618786783888936, model saved at 8\n",
      "val_losses[-1] = 0.0006177229224704206, best_loss = 0.0006181644275784492, model saved at 9\n",
      "val_losses[-1] = 0.0006173480651341379, best_loss = 0.0006177229224704206, model saved at 10\n",
      "val_losses[-1] = 0.0006167205283418298, best_loss = 0.0006173480651341379, model saved at 11\n",
      "val_losses[-1] = 0.0006161417113617063, best_loss = 0.0006167205283418298, model saved at 12\n",
      "val_losses[-1] = 0.0006158120231702924, best_loss = 0.0006161417113617063, model saved at 13\n",
      "val_losses[-1] = 0.0006153610302135348, best_loss = 0.0006158120231702924, model saved at 14\n",
      "val_losses[-1] = 0.0006150929839350283, best_loss = 0.0006153610302135348, model saved at 15\n",
      "val_losses[-1] = 0.0006149742403067648, best_loss = 0.0006150929839350283, model saved at 16\n",
      "val_losses[-1] = 0.0006143631762824953, best_loss = 0.0006149742403067648, model saved at 17\n",
      "val_losses[-1] = 0.0006140917539596558, best_loss = 0.0006143631762824953, model saved at 19\n",
      "val_losses[-1] = 0.0006139932665973902, best_loss = 0.0006140917539596558, model saved at 21\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.00063412293093279, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006259201327338815, best_loss = 0.00063412293093279, model saved at 1\n",
      "val_losses[-1] = 0.0006073280819691718, best_loss = 0.0006259201327338815, model saved at 4\n",
      "val_losses[-1] = 0.0005812454037368298, best_loss = 0.0006073280819691718, model saved at 5\n",
      "val_losses[-1] = 0.0005620786105282605, best_loss = 0.0005812454037368298, model saved at 6\n",
      "val_losses[-1] = 0.000545897230040282, best_loss = 0.0005620786105282605, model saved at 7\n",
      "val_losses[-1] = 0.0005442577530629933, best_loss = 0.000545897230040282, model saved at 10\n",
      "val_losses[-1] = 0.0005333998706191778, best_loss = 0.0005442577530629933, model saved at 12\n",
      "val_losses[-1] = 0.000529405428096652, best_loss = 0.0005333998706191778, model saved at 13\n",
      "val_losses[-1] = 0.00028644167468883097, best_loss = 0.000529405428096652, model saved at 14\n",
      "val_losses[-1] = 0.00019262693240307271, best_loss = 0.00028644167468883097, model saved at 15\n",
      "val_losses[-1] = 0.0001675498060649261, best_loss = 0.00019262693240307271, model saved at 16\n",
      "val_losses[-1] = 0.00016748721827752888, best_loss = 0.0001675498060649261, model saved at 18\n",
      "val_losses[-1] = 0.00016025434888433665, best_loss = 0.00016748721827752888, model saved at 19\n",
      "val_losses[-1] = 0.00015934060502331704, best_loss = 0.00016025434888433665, model saved at 20\n",
      "val_losses[-1] = 0.00015900151629466563, best_loss = 0.00015934060502331704, model saved at 21\n",
      "val_losses[-1] = 0.00015884306048974395, best_loss = 0.00015900151629466563, model saved at 26\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006981655606068671, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006663312087766826, best_loss = 0.0006981655606068671, model saved at 1\n",
      "val_losses[-1] = 0.00066297099692747, best_loss = 0.0006663312087766826, model saved at 2\n",
      "val_losses[-1] = 0.0006465848418883979, best_loss = 0.00066297099692747, model saved at 3\n",
      "val_losses[-1] = 0.0006419424316845834, best_loss = 0.0006465848418883979, model saved at 4\n",
      "val_losses[-1] = 0.0006272663013078272, best_loss = 0.0006419424316845834, model saved at 5\n",
      "val_losses[-1] = 0.0006244477117434144, best_loss = 0.0006272663013078272, model saved at 6\n",
      "val_losses[-1] = 0.0006237433990463614, best_loss = 0.0006244477117434144, model saved at 7\n",
      "val_losses[-1] = 0.0006236580666154623, best_loss = 0.0006237433990463614, model saved at 12\n",
      "val_losses[-1] = 0.0006235497421585023, best_loss = 0.0006236580666154623, model saved at 13\n",
      "val_losses[-1] = 0.0006234665052033961, best_loss = 0.0006235497421585023, model saved at 14\n",
      "val_losses[-1] = 0.000623448402620852, best_loss = 0.0006234665052033961, model saved at 15\n",
      "val_losses[-1] = 0.0006233886233530939, best_loss = 0.000623448402620852, model saved at 16\n",
      "val_losses[-1] = 0.0006233878084458411, best_loss = 0.0006233886233530939, model saved at 17\n",
      "val_losses[-1] = 0.0006233532913029194, best_loss = 0.0006233878084458411, model saved at 18\n",
      "val_losses[-1] = 0.0006154355360195041, best_loss = 0.0006233532913029194, model saved at 19\n",
      "val_losses[-1] = 0.0005179309519007802, best_loss = 0.0006154355360195041, model saved at 20\n",
      "val_losses[-1] = 0.00024587978259660304, best_loss = 0.0005179309519007802, model saved at 21\n",
      "val_losses[-1] = 0.0001919297210406512, best_loss = 0.00024587978259660304, model saved at 22\n",
      "val_losses[-1] = 0.00017630221555009484, best_loss = 0.0001919297210406512, model saved at 23\n",
      "val_losses[-1] = 0.00016826909268274903, best_loss = 0.00017630221555009484, model saved at 24\n",
      "val_losses[-1] = 0.0001662775466684252, best_loss = 0.00016826909268274903, model saved at 25\n",
      "val_losses[-1] = 0.0001578476803842932, best_loss = 0.0001662775466684252, model saved at 26\n",
      "val_losses[-1] = 0.00015707231068518013, best_loss = 0.0001578476803842932, model saved at 27\n",
      "val_losses[-1] = 0.00015622680075466633, best_loss = 0.00015707231068518013, model saved at 28\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0008665091590955853, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006757547380402684, best_loss = 0.0008665091590955853, model saved at 1\n",
      "val_losses[-1] = 0.000646426691673696, best_loss = 0.0006757547380402684, model saved at 3\n",
      "val_losses[-1] = 0.0005959945265203714, best_loss = 0.000646426691673696, model saved at 4\n",
      "val_losses[-1] = 0.0005849114386364818, best_loss = 0.0005959945265203714, model saved at 5\n",
      "val_losses[-1] = 0.0005688199307769537, best_loss = 0.0005849114386364818, model saved at 6\n",
      "val_losses[-1] = 0.0005517764366231859, best_loss = 0.0005688199307769537, model saved at 7\n",
      "val_losses[-1] = 0.0005123773589730263, best_loss = 0.0005517764366231859, model saved at 8\n",
      "val_losses[-1] = 0.00043521562474779785, best_loss = 0.0005123773589730263, model saved at 9\n",
      "val_losses[-1] = 0.00033253157744184136, best_loss = 0.00043521562474779785, model saved at 10\n",
      "val_losses[-1] = 0.0002528008189983666, best_loss = 0.00033253157744184136, model saved at 11\n",
      "val_losses[-1] = 0.00022045995865482837, best_loss = 0.0002528008189983666, model saved at 12\n",
      "val_losses[-1] = 0.00019924223306588829, best_loss = 0.00022045995865482837, model saved at 13\n",
      "val_losses[-1] = 0.00019079263438470662, best_loss = 0.00019924223306588829, model saved at 14\n",
      "val_losses[-1] = 0.0001852277055149898, best_loss = 0.00019079263438470662, model saved at 15\n",
      "val_losses[-1] = 0.00018005978199653327, best_loss = 0.0001852277055149898, model saved at 16\n",
      "val_losses[-1] = 0.00017598530394025147, best_loss = 0.00018005978199653327, model saved at 17\n",
      "val_losses[-1] = 0.00017083539569284767, best_loss = 0.00017598530394025147, model saved at 18\n",
      "val_losses[-1] = 0.00016768155910540372, best_loss = 0.00017083539569284767, model saved at 19\n",
      "val_losses[-1] = 0.00016747284098528326, best_loss = 0.00016768155910540372, model saved at 21\n",
      "val_losses[-1] = 0.00016268428589683026, best_loss = 0.00016747284098528326, model saved at 23\n",
      "val_losses[-1] = 0.0001611763145774603, best_loss = 0.00016268428589683026, model saved at 24\n",
      "val_losses[-1] = 0.0001591251348145306, best_loss = 0.0001611763145774603, model saved at 29\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006304485141299665, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006193189765326679, best_loss = 0.0006304485141299665, model saved at 1\n",
      "val_losses[-1] = 0.0005797138437628746, best_loss = 0.0006193189765326679, model saved at 2\n",
      "val_losses[-1] = 0.00021599335013888776, best_loss = 0.0005797138437628746, model saved at 3\n",
      "val_losses[-1] = 0.00017019321967381984, best_loss = 0.00021599335013888776, model saved at 4\n",
      "val_losses[-1] = 0.00015693863679189235, best_loss = 0.00017019321967381984, model saved at 5\n",
      "val_losses[-1] = 0.00015693659952376038, best_loss = 0.00015693863679189235, model saved at 6\n",
      "val_losses[-1] = 0.00015670871653128415, best_loss = 0.00015693659952376038, model saved at 8\n",
      "val_losses[-1] = 0.00014864554395899177, best_loss = 0.00015670871653128415, model saved at 9\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006361401174217463, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006212687585502863, best_loss = 0.0006361401174217463, model saved at 1\n",
      "val_losses[-1] = 0.000616224599070847, best_loss = 0.0006212687585502863, model saved at 2\n",
      "val_losses[-1] = 0.000610105402301997, best_loss = 0.000616224599070847, model saved at 3\n",
      "val_losses[-1] = 0.0006076223216950893, best_loss = 0.000610105402301997, model saved at 4\n",
      "val_losses[-1] = 0.0006042179884389043, best_loss = 0.0006076223216950893, model saved at 5\n",
      "val_losses[-1] = 0.0005992682417854667, best_loss = 0.0006042179884389043, model saved at 6\n",
      "val_losses[-1] = 0.0005988676566630602, best_loss = 0.0005992682417854667, model saved at 7\n",
      "val_losses[-1] = 0.000592390017118305, best_loss = 0.0005988676566630602, model saved at 8\n",
      "val_losses[-1] = 0.0005878761876374483, best_loss = 0.000592390017118305, model saved at 9\n",
      "val_losses[-1] = 0.0005821532104164362, best_loss = 0.0005878761876374483, model saved at 10\n",
      "val_losses[-1] = 0.0005776432226411998, best_loss = 0.0005821532104164362, model saved at 11\n",
      "val_losses[-1] = 0.0005711658159270883, best_loss = 0.0005776432226411998, model saved at 12\n",
      "val_losses[-1] = 0.0005695694708265364, best_loss = 0.0005711658159270883, model saved at 13\n",
      "val_losses[-1] = 0.0005624227342195809, best_loss = 0.0005695694708265364, model saved at 14\n",
      "val_losses[-1] = 0.0005570034845732152, best_loss = 0.0005624227342195809, model saved at 16\n",
      "val_losses[-1] = 0.0005524480948224664, best_loss = 0.0005570034845732152, model saved at 17\n",
      "val_losses[-1] = 0.0005499213584698737, best_loss = 0.0005524480948224664, model saved at 18\n",
      "val_losses[-1] = 0.0005419256631284952, best_loss = 0.0005499213584698737, model saved at 19\n",
      "val_losses[-1] = 0.00023557622625958174, best_loss = 0.0005419256631284952, model saved at 20\n",
      "val_losses[-1] = 0.00018087234639097005, best_loss = 0.00023557622625958174, model saved at 21\n",
      "val_losses[-1] = 0.00016882437921594828, best_loss = 0.00018087234639097005, model saved at 22\n",
      "val_losses[-1] = 0.00016752653755247593, best_loss = 0.00016882437921594828, model saved at 23\n",
      "val_losses[-1] = 0.0001605273428140208, best_loss = 0.00016752653755247593, model saved at 24\n",
      "val_losses[-1] = 0.00015340678510256112, best_loss = 0.0001605273428140208, model saved at 26\n",
      "(0.4, 0.6)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006532337283715606, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006323004490695894, best_loss = 0.0006532337283715606, model saved at 1\n",
      "val_losses[-1] = 0.0006247159908525646, best_loss = 0.0006323004490695894, model saved at 2\n",
      "val_losses[-1] = 0.000622658699285239, best_loss = 0.0006247159908525646, model saved at 3\n",
      "val_losses[-1] = 0.0006181273492984474, best_loss = 0.000622658699285239, model saved at 4\n",
      "val_losses[-1] = 0.0006173921865411103, best_loss = 0.0006181273492984474, model saved at 5\n",
      "val_losses[-1] = 0.000617154932115227, best_loss = 0.0006173921865411103, model saved at 6\n",
      "val_losses[-1] = 0.0006170982960611582, best_loss = 0.000617154932115227, model saved at 7\n",
      "val_losses[-1] = 0.0006169532425701618, best_loss = 0.0006170982960611582, model saved at 9\n",
      "val_losses[-1] = 0.0006169342086650431, best_loss = 0.0006169532425701618, model saved at 11\n",
      "val_losses[-1] = 0.0006166585953906178, best_loss = 0.0006169342086650431, model saved at 12\n",
      "val_losses[-1] = 0.0006162823410704732, best_loss = 0.0006166585953906178, model saved at 13\n",
      "val_losses[-1] = 0.0006158868200145662, best_loss = 0.0006162823410704732, model saved at 14\n",
      "val_losses[-1] = 0.0006156846066005528, best_loss = 0.0006158868200145662, model saved at 15\n",
      "val_losses[-1] = 0.0006153479334898293, best_loss = 0.0006156846066005528, model saved at 16\n",
      "val_losses[-1] = 0.0006149703403934836, best_loss = 0.0006153479334898293, model saved at 17\n",
      "val_losses[-1] = 0.0006141074700281024, best_loss = 0.0006149703403934836, model saved at 18\n",
      "val_losses[-1] = 0.0006136952433735132, best_loss = 0.0006141074700281024, model saved at 19\n",
      "val_losses[-1] = 0.0006133412243798375, best_loss = 0.0006136952433735132, model saved at 20\n",
      "val_losses[-1] = 0.0006126674707047641, best_loss = 0.0006133412243798375, model saved at 21\n",
      "val_losses[-1] = 0.0006120569887571037, best_loss = 0.0006126674707047641, model saved at 22\n",
      "val_losses[-1] = 0.0006115311407484114, best_loss = 0.0006120569887571037, model saved at 23\n",
      "val_losses[-1] = 0.0006112410919740796, best_loss = 0.0006115311407484114, model saved at 24\n",
      "val_losses[-1] = 0.0006106201908551157, best_loss = 0.0006112410919740796, model saved at 25\n",
      "val_losses[-1] = 0.0006098657031543553, best_loss = 0.0006106201908551157, model saved at 26\n",
      "val_losses[-1] = 0.0006096501019783318, best_loss = 0.0006098657031543553, model saved at 27\n",
      "val_losses[-1] = 0.0006092273397371173, best_loss = 0.0006096501019783318, model saved at 29\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006773038767278194, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006332583725452423, best_loss = 0.0006773038767278194, model saved at 1\n",
      "val_losses[-1] = 0.0006253381725400686, best_loss = 0.0006332583725452423, model saved at 2\n",
      "val_losses[-1] = 0.0006230393773876131, best_loss = 0.0006253381725400686, model saved at 4\n",
      "val_losses[-1] = 0.0006223389063961804, best_loss = 0.0006230393773876131, model saved at 5\n",
      "val_losses[-1] = 0.0006223269156180322, best_loss = 0.0006223389063961804, model saved at 6\n",
      "val_losses[-1] = 0.000621562940068543, best_loss = 0.0006223269156180322, model saved at 15\n",
      "val_losses[-1] = 0.0006211755098775029, best_loss = 0.000621562940068543, model saved at 21\n",
      "val_losses[-1] = 0.0006200845818966627, best_loss = 0.0006211755098775029, model saved at 22\n",
      "val_losses[-1] = 0.0006196066387929022, best_loss = 0.0006200845818966627, model saved at 23\n",
      "val_losses[-1] = 0.0006193970912136137, best_loss = 0.0006196066387929022, model saved at 24\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007643127464689314, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006792315398342907, best_loss = 0.0007643127464689314, model saved at 1\n",
      "val_losses[-1] = 0.0006444754544645548, best_loss = 0.0006792315398342907, model saved at 2\n",
      "val_losses[-1] = 0.0006342886481434107, best_loss = 0.0006444754544645548, model saved at 3\n",
      "val_losses[-1] = 0.000625056040007621, best_loss = 0.0006342886481434107, model saved at 4\n",
      "val_losses[-1] = 0.0006140940240584314, best_loss = 0.000625056040007621, model saved at 5\n",
      "val_losses[-1] = 0.0006099644815549254, best_loss = 0.0006140940240584314, model saved at 6\n",
      "val_losses[-1] = 0.0006091430550441146, best_loss = 0.0006099644815549254, model saved at 7\n",
      "val_losses[-1] = 0.000607306370511651, best_loss = 0.0006091430550441146, model saved at 8\n",
      "val_losses[-1] = 0.0006069306982681155, best_loss = 0.000607306370511651, model saved at 9\n",
      "iter 3...\n",
      "val_losses[-1] = 0.000635353964753449, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005522447172552347, best_loss = 0.000635353964753449, model saved at 1\n",
      "val_losses[-1] = 0.0005449676536954939, best_loss = 0.0005522447172552347, model saved at 2\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006313700578175485, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006221704534254968, best_loss = 0.0006313700578175485, model saved at 2\n",
      "val_losses[-1] = 0.0006220038630999625, best_loss = 0.0006221704534254968, model saved at 6\n",
      "val_losses[-1] = 0.0006212236476130784, best_loss = 0.0006220038630999625, model saved at 7\n",
      "val_losses[-1] = 0.000620418693870306, best_loss = 0.0006212236476130784, model saved at 8\n",
      "val_losses[-1] = 0.0006198542541824281, best_loss = 0.000620418693870306, model saved at 9\n",
      "val_losses[-1] = 0.0006193122244440019, best_loss = 0.0006198542541824281, model saved at 10\n",
      "val_losses[-1] = 0.0006190285203047097, best_loss = 0.0006193122244440019, model saved at 11\n",
      "val_losses[-1] = 0.000618545978795737, best_loss = 0.0006190285203047097, model saved at 12\n",
      "val_losses[-1] = 0.0006181620992720127, best_loss = 0.000618545978795737, model saved at 14\n",
      "val_losses[-1] = 0.0006176939932629466, best_loss = 0.0006181620992720127, model saved at 15\n",
      "val_losses[-1] = 0.0006171797285787761, best_loss = 0.0006176939932629466, model saved at 16\n",
      "val_losses[-1] = 0.0006168754189275205, best_loss = 0.0006171797285787761, model saved at 17\n",
      "val_losses[-1] = 0.000616416975390166, best_loss = 0.0006168754189275205, model saved at 18\n",
      "val_losses[-1] = 0.000615897704847157, best_loss = 0.000616416975390166, model saved at 19\n",
      "val_losses[-1] = 0.0006155521841719747, best_loss = 0.000615897704847157, model saved at 20\n",
      "val_losses[-1] = 0.0006154363509267569, best_loss = 0.0006155521841719747, model saved at 22\n",
      "val_losses[-1] = 0.0006152953719720244, best_loss = 0.0006154363509267569, model saved at 23\n",
      "val_losses[-1] = 0.0006149729015305638, best_loss = 0.0006152953719720244, model saved at 24\n",
      "val_losses[-1] = 0.0006146274972707033, best_loss = 0.0006149729015305638, model saved at 25\n",
      "val_losses[-1] = 0.0006143651553429663, best_loss = 0.0006146274972707033, model saved at 26\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.000626431021373719, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006251849699765444, best_loss = 0.000626431021373719, model saved at 1\n",
      "val_losses[-1] = 0.0006241287337616086, best_loss = 0.0006251849699765444, model saved at 4\n",
      "val_losses[-1] = 0.0006234697648324072, best_loss = 0.0006241287337616086, model saved at 5\n",
      "val_losses[-1] = 0.000623465864919126, best_loss = 0.0006234697648324072, model saved at 7\n",
      "val_losses[-1] = 0.0006233972380869091, best_loss = 0.000623465864919126, model saved at 8\n",
      "val_losses[-1] = 0.0006233832100406289, best_loss = 0.0006233972380869091, model saved at 10\n",
      "val_losses[-1] = 0.00062334950780496, best_loss = 0.0006233832100406289, model saved at 11\n",
      "val_losses[-1] = 0.0006233476451598108, best_loss = 0.00062334950780496, model saved at 16\n",
      "val_losses[-1] = 0.0006233312888070941, best_loss = 0.0006233476451598108, model saved at 21\n",
      "val_losses[-1] = 0.00037921679904684424, best_loss = 0.0006233312888070941, model saved at 26\n",
      "val_losses[-1] = 0.00028056156588718295, best_loss = 0.00037921679904684424, model saved at 27\n",
      "val_losses[-1] = 0.0002606491034384817, best_loss = 0.00028056156588718295, model saved at 28\n",
      "val_losses[-1] = 0.000251680874498561, best_loss = 0.0002606491034384817, model saved at 29\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006870537763461471, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006235643522813916, best_loss = 0.0006870537763461471, model saved at 1\n",
      "val_losses[-1] = 0.000623400672338903, best_loss = 0.0006235643522813916, model saved at 2\n",
      "val_losses[-1] = 0.0006233901949599385, best_loss = 0.000623400672338903, model saved at 5\n",
      "val_losses[-1] = 0.0006232804153114557, best_loss = 0.0006233901949599385, model saved at 6\n",
      "val_losses[-1] = 0.0006221865187399089, best_loss = 0.0006232804153114557, model saved at 7\n",
      "val_losses[-1] = 0.0006198273622430861, best_loss = 0.0006221865187399089, model saved at 8\n",
      "val_losses[-1] = 0.0006151970592327416, best_loss = 0.0006198273622430861, model saved at 9\n",
      "val_losses[-1] = 0.0006052461685612798, best_loss = 0.0006151970592327416, model saved at 10\n",
      "val_losses[-1] = 0.0005911135813221335, best_loss = 0.0006052461685612798, model saved at 11\n",
      "val_losses[-1] = 0.0005684770294465125, best_loss = 0.0005911135813221335, model saved at 13\n",
      "val_losses[-1] = 0.0005545862950384617, best_loss = 0.0005684770294465125, model saved at 14\n",
      "val_losses[-1] = 0.0004854137368965894, best_loss = 0.0005545862950384617, model saved at 15\n",
      "val_losses[-1] = 0.00033744386746548116, best_loss = 0.0004854137368965894, model saved at 16\n",
      "val_losses[-1] = 0.0002660827594809234, best_loss = 0.00033744386746548116, model saved at 17\n",
      "val_losses[-1] = 0.0002529644116293639, best_loss = 0.0002660827594809234, model saved at 18\n",
      "val_losses[-1] = 0.00024717077030800283, best_loss = 0.0002529644116293639, model saved at 19\n",
      "val_losses[-1] = 0.0002449807361699641, best_loss = 0.00024717077030800283, model saved at 21\n",
      "val_losses[-1] = 0.000243050730205141, best_loss = 0.0002449807361699641, model saved at 25\n",
      "val_losses[-1] = 0.00024094292894005775, best_loss = 0.000243050730205141, model saved at 27\n",
      "val_losses[-1] = 0.0002390826412010938, best_loss = 0.00024094292894005775, model saved at 28\n",
      "val_losses[-1] = 0.00023868402058724314, best_loss = 0.0002390826412010938, model saved at 29\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0008163937600329518, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0007560254307463765, best_loss = 0.0008163937600329518, model saved at 1\n",
      "val_losses[-1] = 0.0006378248217515647, best_loss = 0.0007560254307463765, model saved at 2\n",
      "val_losses[-1] = 0.0006051662494428456, best_loss = 0.0006378248217515647, model saved at 3\n",
      "val_losses[-1] = 0.0005870502209290862, best_loss = 0.0006051662494428456, model saved at 4\n",
      "val_losses[-1] = 0.0005725484807044268, best_loss = 0.0005870502209290862, model saved at 5\n",
      "val_losses[-1] = 0.0004978960496373475, best_loss = 0.0005725484807044268, model saved at 6\n",
      "val_losses[-1] = 0.0003381379647180438, best_loss = 0.0004978960496373475, model saved at 7\n",
      "val_losses[-1] = 0.0002778179768938571, best_loss = 0.0003381379647180438, model saved at 8\n",
      "val_losses[-1] = 0.0002660620666574687, best_loss = 0.0002778179768938571, model saved at 9\n",
      "val_losses[-1] = 0.0002618056023493409, best_loss = 0.0002660620666574687, model saved at 10\n",
      "val_losses[-1] = 0.00025506780366413295, best_loss = 0.0002618056023493409, model saved at 11\n",
      "val_losses[-1] = 0.0002497172390576452, best_loss = 0.00025506780366413295, model saved at 12\n",
      "val_losses[-1] = 0.0002419494849164039, best_loss = 0.0002497172390576452, model saved at 14\n",
      "val_losses[-1] = 0.00023898862127680331, best_loss = 0.0002419494849164039, model saved at 15\n",
      "val_losses[-1] = 0.00023560340923722833, best_loss = 0.00023898862127680331, model saved at 19\n",
      "val_losses[-1] = 0.00023340596817433834, best_loss = 0.00023560340923722833, model saved at 25\n",
      "val_losses[-1] = 0.00023309308744501323, best_loss = 0.00023340596817433834, model saved at 27\n",
      "iter 3...\n",
      "val_losses[-1] = 0.000625729444436729, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006110109970904887, best_loss = 0.000625729444436729, model saved at 1\n",
      "val_losses[-1] = 0.0005984531599096954, best_loss = 0.0006110109970904887, model saved at 2\n",
      "val_losses[-1] = 0.0005982013535685837, best_loss = 0.0005984531599096954, model saved at 3\n",
      "val_losses[-1] = 0.0005969718913547695, best_loss = 0.0005982013535685837, model saved at 4\n",
      "val_losses[-1] = 0.0005942721618339419, best_loss = 0.0005969718913547695, model saved at 5\n",
      "val_losses[-1] = 0.0005938697140663862, best_loss = 0.0005942721618339419, model saved at 6\n",
      "val_losses[-1] = 0.0005924637080170214, best_loss = 0.0005938697140663862, model saved at 7\n",
      "val_losses[-1] = 0.0005906170699745417, best_loss = 0.0005924637080170214, model saved at 8\n",
      "val_losses[-1] = 0.0005857612122781575, best_loss = 0.0005906170699745417, model saved at 9\n",
      "val_losses[-1] = 0.0005840628873556852, best_loss = 0.0005857612122781575, model saved at 10\n",
      "val_losses[-1] = 0.0005797538324259222, best_loss = 0.0005840628873556852, model saved at 11\n",
      "val_losses[-1] = 0.0005018308875150979, best_loss = 0.0005797538324259222, model saved at 12\n",
      "val_losses[-1] = 0.00030181690817698836, best_loss = 0.0005018308875150979, model saved at 13\n",
      "val_losses[-1] = 0.00028335925890132785, best_loss = 0.00030181690817698836, model saved at 14\n",
      "val_losses[-1] = 0.0002636341378092766, best_loss = 0.00028335925890132785, model saved at 15\n",
      "val_losses[-1] = 0.00026185112074017525, best_loss = 0.0002636341378092766, model saved at 16\n",
      "val_losses[-1] = 0.0002492498606443405, best_loss = 0.00026185112074017525, model saved at 17\n",
      "val_losses[-1] = 0.00024538635625503957, best_loss = 0.0002492498606443405, model saved at 21\n",
      "val_losses[-1] = 0.0002442067489027977, best_loss = 0.00024538635625503957, model saved at 23\n",
      "val_losses[-1] = 0.00024192781711462885, best_loss = 0.0002442067489027977, model saved at 27\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006366607267409563, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006159020704217255, best_loss = 0.0006366607267409563, model saved at 1\n",
      "val_losses[-1] = 0.0006021670997142792, best_loss = 0.0006159020704217255, model saved at 2\n",
      "val_losses[-1] = 0.0005981553113088012, best_loss = 0.0006021670997142792, model saved at 3\n",
      "val_losses[-1] = 0.0005938350805081427, best_loss = 0.0005981553113088012, model saved at 4\n",
      "val_losses[-1] = 0.000589336093980819, best_loss = 0.0005938350805081427, model saved at 5\n",
      "val_losses[-1] = 0.0005865227431058884, best_loss = 0.000589336093980819, model saved at 6\n",
      "val_losses[-1] = 0.0005855421768501401, best_loss = 0.0005865227431058884, model saved at 7\n",
      "val_losses[-1] = 0.0005814195028506219, best_loss = 0.0005855421768501401, model saved at 8\n",
      "val_losses[-1] = 0.0005801588413305581, best_loss = 0.0005814195028506219, model saved at 9\n",
      "val_losses[-1] = 0.0005793475429527462, best_loss = 0.0005801588413305581, model saved at 10\n",
      "val_losses[-1] = 0.0005775161553174257, best_loss = 0.0005793475429527462, model saved at 11\n",
      "val_losses[-1] = 0.0005723449285142124, best_loss = 0.0005775161553174257, model saved at 13\n",
      "val_losses[-1] = 0.000570989097468555, best_loss = 0.0005723449285142124, model saved at 14\n",
      "val_losses[-1] = 0.0005699259345419705, best_loss = 0.000570989097468555, model saved at 15\n",
      "val_losses[-1] = 0.0005693733692169189, best_loss = 0.0005699259345419705, model saved at 16\n",
      "val_losses[-1] = 0.0005676046130247414, best_loss = 0.0005693733692169189, model saved at 17\n",
      "val_losses[-1] = 0.0004000218177679926, best_loss = 0.0005676046130247414, model saved at 18\n",
      "val_losses[-1] = 0.0002857918734662235, best_loss = 0.0004000218177679926, model saved at 19\n",
      "val_losses[-1] = 0.0002622455940581858, best_loss = 0.0002857918734662235, model saved at 20\n",
      "val_losses[-1] = 0.00025462370831519365, best_loss = 0.0002622455940581858, model saved at 21\n",
      "val_losses[-1] = 0.00024655068409629166, best_loss = 0.00025462370831519365, model saved at 22\n",
      "val_losses[-1] = 0.00023953019990585744, best_loss = 0.00024655068409629166, model saved at 23\n",
      "val_losses[-1] = 0.00023672913084737957, best_loss = 0.00023953019990585744, model saved at 27\n",
      "val_losses[-1] = 0.00023114783107303083, best_loss = 0.00023672913084737957, model saved at 28\n",
      "val_losses[-1] = 0.00023058151418808848, best_loss = 0.00023114783107303083, model saved at 29\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006237306515686214, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005996777908876538, best_loss = 0.0006237306515686214, model saved at 1\n",
      "val_losses[-1] = 0.0005965400487184525, best_loss = 0.0005996777908876538, model saved at 2\n",
      "val_losses[-1] = 0.0005800976068712771, best_loss = 0.0005965400487184525, model saved at 3\n",
      "val_losses[-1] = 0.00017092618509195745, best_loss = 0.0005800976068712771, model saved at 4\n",
      "val_losses[-1] = 0.00012937856081407517, best_loss = 0.00017092618509195745, model saved at 5\n",
      "val_losses[-1] = 0.00012636590690817684, best_loss = 0.00012937856081407517, model saved at 6\n",
      "val_losses[-1] = 0.00011680069292197004, best_loss = 0.00012636590690817684, model saved at 7\n",
      "val_losses[-1] = 0.00011224293848499656, best_loss = 0.00011680069292197004, model saved at 13\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0007829265086911619, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006386989844031632, best_loss = 0.0007829265086911619, model saved at 1\n",
      "val_losses[-1] = 0.0006362904678098857, best_loss = 0.0006386989844031632, model saved at 2\n",
      "val_losses[-1] = 0.0006259268266148865, best_loss = 0.0006362904678098857, model saved at 3\n",
      "val_losses[-1] = 0.0005878352094441652, best_loss = 0.0006259268266148865, model saved at 4\n",
      "val_losses[-1] = 0.00014381726214196533, best_loss = 0.0005878352094441652, model saved at 5\n",
      "val_losses[-1] = 0.00012448948109522462, best_loss = 0.00014381726214196533, model saved at 6\n",
      "val_losses[-1] = 0.00011637501302175224, best_loss = 0.00012448948109522462, model saved at 8\n",
      "val_losses[-1] = 0.00011625990009633824, best_loss = 0.00011637501302175224, model saved at 12\n",
      "val_losses[-1] = 0.00011562521103769541, best_loss = 0.00011625990009633824, model saved at 15\n",
      "val_losses[-1] = 0.00011537069076439366, best_loss = 0.00011562521103769541, model saved at 18\n",
      "val_losses[-1] = 0.00011442237882874906, best_loss = 0.00011537069076439366, model saved at 27\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0012357804225757718, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006228665006347001, best_loss = 0.0012357804225757718, model saved at 1\n",
      "val_losses[-1] = 0.0005626619094982743, best_loss = 0.0006228665006347001, model saved at 2\n",
      "val_losses[-1] = 0.0005233267438597977, best_loss = 0.0005626619094982743, model saved at 3\n",
      "val_losses[-1] = 0.00022076295863371342, best_loss = 0.0005233267438597977, model saved at 4\n",
      "val_losses[-1] = 0.00014081186964176595, best_loss = 0.00022076295863371342, model saved at 5\n",
      "val_losses[-1] = 0.0001367056684102863, best_loss = 0.00014081186964176595, model saved at 6\n",
      "val_losses[-1] = 0.00013612919428851455, best_loss = 0.0001367056684102863, model saved at 7\n",
      "val_losses[-1] = 0.00013220086111687124, best_loss = 0.00013612919428851455, model saved at 8\n",
      "val_losses[-1] = 0.00013071177818346769, best_loss = 0.00013220086111687124, model saved at 9\n",
      "val_losses[-1] = 0.00012811884516850114, best_loss = 0.00013071177818346769, model saved at 10\n",
      "val_losses[-1] = 0.00012460470316000283, best_loss = 0.00012811884516850114, model saved at 11\n",
      "val_losses[-1] = 0.00012130029062973335, best_loss = 0.00012460470316000283, model saved at 14\n",
      "val_losses[-1] = 0.0001212510687764734, best_loss = 0.00012130029062973335, model saved at 17\n",
      "val_losses[-1] = 0.0001203407664434053, best_loss = 0.0001212510687764734, model saved at 19\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006296762730926275, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006233187741599977, best_loss = 0.0006296762730926275, model saved at 1\n",
      "val_losses[-1] = 0.000623174593783915, best_loss = 0.0006233187741599977, model saved at 2\n",
      "val_losses[-1] = 0.000623132917098701, best_loss = 0.000623174593783915, model saved at 3\n",
      "val_losses[-1] = 0.0006230564322322607, best_loss = 0.000623132917098701, model saved at 17\n",
      "val_losses[-1] = 0.0006224051467142999, best_loss = 0.0006230564322322607, model saved at 18\n",
      "val_losses[-1] = 0.0006180930649861693, best_loss = 0.0006224051467142999, model saved at 19\n",
      "val_losses[-1] = 0.0006109942914918065, best_loss = 0.0006180930649861693, model saved at 20\n",
      "val_losses[-1] = 0.0006018218700774014, best_loss = 0.0006109942914918065, model saved at 21\n",
      "val_losses[-1] = 0.000578161736484617, best_loss = 0.0006018218700774014, model saved at 22\n",
      "val_losses[-1] = 0.00015317511861212552, best_loss = 0.000578161736484617, model saved at 23\n",
      "val_losses[-1] = 0.0001425362133886665, best_loss = 0.00015317511861212552, model saved at 24\n",
      "val_losses[-1] = 0.00013951672008261085, best_loss = 0.0001425362133886665, model saved at 25\n",
      "val_losses[-1] = 0.0001315933623118326, best_loss = 0.00013951672008261085, model saved at 26\n",
      "val_losses[-1] = 0.00012978185259271413, best_loss = 0.0001315933623118326, model saved at 27\n",
      "val_losses[-1] = 0.00012781354598701, best_loss = 0.00012978185259271413, model saved at 28\n",
      "val_losses[-1] = 0.0001272475637961179, best_loss = 0.00012781354598701, model saved at 29\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006359091494232416, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006288720760494471, best_loss = 0.0006359091494232416, model saved at 1\n",
      "val_losses[-1] = 0.0006174957379698753, best_loss = 0.0006288720760494471, model saved at 2\n",
      "val_losses[-1] = 0.0006147079402580857, best_loss = 0.0006174957379698753, model saved at 6\n",
      "val_losses[-1] = 0.0006066812202334404, best_loss = 0.0006147079402580857, model saved at 7\n",
      "val_losses[-1] = 0.0005965682794339955, best_loss = 0.0006066812202334404, model saved at 8\n",
      "val_losses[-1] = 0.0005923418793827295, best_loss = 0.0005965682794339955, model saved at 9\n",
      "val_losses[-1] = 0.0005820577498525381, best_loss = 0.0005923418793827295, model saved at 10\n",
      "val_losses[-1] = 0.0005766022950410843, best_loss = 0.0005820577498525381, model saved at 11\n",
      "val_losses[-1] = 0.0005749565316364169, best_loss = 0.0005766022950410843, model saved at 12\n",
      "val_losses[-1] = 0.0005684736534021795, best_loss = 0.0005749565316364169, model saved at 13\n",
      "val_losses[-1] = 0.0005640414892695844, best_loss = 0.0005684736534021795, model saved at 14\n",
      "val_losses[-1] = 0.0005581488949246705, best_loss = 0.0005640414892695844, model saved at 15\n",
      "val_losses[-1] = 0.0003278916992712766, best_loss = 0.0005581488949246705, model saved at 17\n",
      "val_losses[-1] = 0.00014627455675508827, best_loss = 0.0003278916992712766, model saved at 18\n",
      "val_losses[-1] = 0.00013168470468372107, best_loss = 0.00014627455675508827, model saved at 19\n",
      "val_losses[-1] = 0.00013063465303275734, best_loss = 0.00013168470468372107, model saved at 20\n",
      "val_losses[-1] = 0.00012121898907935247, best_loss = 0.00013063465303275734, model saved at 21\n",
      "val_losses[-1] = 0.00011665275815175846, best_loss = 0.00012121898907935247, model saved at 24\n",
      "(0.5, 0.5)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006332112825475633, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006266270647756755, best_loss = 0.0006332112825475633, model saved at 1\n",
      "val_losses[-1] = 0.0006248733261600137, best_loss = 0.0006266270647756755, model saved at 2\n",
      "val_losses[-1] = 0.0006221639923751354, best_loss = 0.0006248733261600137, model saved at 7\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006407612236216664, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006194403395056725, best_loss = 0.0006407612236216664, model saved at 1\n",
      "val_losses[-1] = 0.0006191872525960207, best_loss = 0.0006194403395056725, model saved at 2\n",
      "val_losses[-1] = 0.0006135228322818875, best_loss = 0.0006191872525960207, model saved at 15\n",
      "val_losses[-1] = 0.0006061556050553918, best_loss = 0.0006135228322818875, model saved at 16\n",
      "val_losses[-1] = 0.0006019160500727594, best_loss = 0.0006061556050553918, model saved at 17\n",
      "val_losses[-1] = 0.0005953301442787051, best_loss = 0.0006019160500727594, model saved at 18\n",
      "val_losses[-1] = 0.0005877113435417414, best_loss = 0.0005953301442787051, model saved at 19\n",
      "val_losses[-1] = 0.0005833057803101838, best_loss = 0.0005877113435417414, model saved at 20\n",
      "val_losses[-1] = 0.0005727553507313132, best_loss = 0.0005833057803101838, model saved at 21\n",
      "val_losses[-1] = 0.0005645766505040228, best_loss = 0.0005727553507313132, model saved at 22\n",
      "val_losses[-1] = 0.0005631809472106397, best_loss = 0.0005645766505040228, model saved at 23\n",
      "val_losses[-1] = 0.0005596180562861264, best_loss = 0.0005631809472106397, model saved at 24\n",
      "val_losses[-1] = 0.0005588708445429802, best_loss = 0.0005596180562861264, model saved at 25\n",
      "val_losses[-1] = 0.0005545970052480698, best_loss = 0.0005588708445429802, model saved at 26\n",
      "val_losses[-1] = 0.0005532178329303861, best_loss = 0.0005545970052480698, model saved at 27\n",
      "val_losses[-1] = 0.0005509620532393456, best_loss = 0.0005532178329303861, model saved at 29\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007736244588159025, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0007162439869716763, best_loss = 0.0007736244588159025, model saved at 2\n",
      "val_losses[-1] = 0.0006202029762789607, best_loss = 0.0007162439869716763, model saved at 3\n",
      "val_losses[-1] = 0.0006149772671051323, best_loss = 0.0006202029762789607, model saved at 4\n",
      "val_losses[-1] = 0.0006125651998445392, best_loss = 0.0006149772671051323, model saved at 5\n",
      "val_losses[-1] = 0.0006121720070950687, best_loss = 0.0006125651998445392, model saved at 6\n",
      "val_losses[-1] = 0.0006102657644078135, best_loss = 0.0006121720070950687, model saved at 7\n",
      "val_losses[-1] = 0.0006092151161283255, best_loss = 0.0006102657644078135, model saved at 8\n",
      "val_losses[-1] = 0.0006087804795242846, best_loss = 0.0006092151161283255, model saved at 9\n",
      "val_losses[-1] = 0.0006080036400817335, best_loss = 0.0006087804795242846, model saved at 10\n",
      "val_losses[-1] = 0.0006077114376239479, best_loss = 0.0006080036400817335, model saved at 12\n",
      "val_losses[-1] = 0.0006069168448448181, best_loss = 0.0006077114376239479, model saved at 13\n",
      "val_losses[-1] = 0.0006067280191928148, best_loss = 0.0006069168448448181, model saved at 15\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006823024596087635, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006241714581847191, best_loss = 0.0006823024596087635, model saved at 1\n",
      "val_losses[-1] = 0.000617652724031359, best_loss = 0.0006241714581847191, model saved at 2\n",
      "val_losses[-1] = 0.0006134436116553843, best_loss = 0.000617652724031359, model saved at 3\n",
      "val_losses[-1] = 0.000613427022472024, best_loss = 0.0006134436116553843, model saved at 4\n",
      "val_losses[-1] = 0.0006133081042207778, best_loss = 0.000613427022472024, model saved at 7\n",
      "val_losses[-1] = 0.0006129231187514961, best_loss = 0.0006133081042207778, model saved at 8\n",
      "val_losses[-1] = 0.0006117183365859091, best_loss = 0.0006129231187514961, model saved at 9\n",
      "val_losses[-1] = 0.0006111075053922832, best_loss = 0.0006117183365859091, model saved at 10\n",
      "val_losses[-1] = 0.0006102605839259923, best_loss = 0.0006111075053922832, model saved at 11\n",
      "val_losses[-1] = 0.0006098208832554519, best_loss = 0.0006102605839259923, model saved at 12\n",
      "val_losses[-1] = 0.0006079914746806026, best_loss = 0.0006098208832554519, model saved at 13\n",
      "val_losses[-1] = 0.0006054143304936588, best_loss = 0.0006079914746806026, model saved at 15\n",
      "val_losses[-1] = 0.0006044790497981012, best_loss = 0.0006054143304936588, model saved at 16\n",
      "val_losses[-1] = 0.0006031085504218936, best_loss = 0.0006044790497981012, model saved at 17\n",
      "val_losses[-1] = 0.0005915396614000201, best_loss = 0.0006031085504218936, model saved at 18\n",
      "val_losses[-1] = 0.0005728919641114771, best_loss = 0.0005915396614000201, model saved at 19\n",
      "val_losses[-1] = 0.0005676747532561421, best_loss = 0.0005728919641114771, model saved at 20\n",
      "val_losses[-1] = 0.0005566440522670746, best_loss = 0.0005676747532561421, model saved at 21\n",
      "val_losses[-1] = 0.0005512380157597363, best_loss = 0.0005566440522670746, model saved at 22\n",
      "val_losses[-1] = 0.0005429980810731649, best_loss = 0.0005512380157597363, model saved at 23\n",
      "val_losses[-1] = 0.0005396191845647991, best_loss = 0.0005429980810731649, model saved at 24\n",
      "val_losses[-1] = 0.000534669728949666, best_loss = 0.0005396191845647991, model saved at 26\n",
      "val_losses[-1] = 0.000529149838257581, best_loss = 0.000534669728949666, model saved at 27\n",
      "val_losses[-1] = 0.0005288880201987922, best_loss = 0.000529149838257581, model saved at 29\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006275568739511073, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006194195593707263, best_loss = 0.0006275568739511073, model saved at 1\n",
      "val_losses[-1] = 0.000616319477558136, best_loss = 0.0006194195593707263, model saved at 2\n",
      "val_losses[-1] = 0.0006158230826258659, best_loss = 0.000616319477558136, model saved at 3\n",
      "val_losses[-1] = 0.0006148208049125969, best_loss = 0.0006158230826258659, model saved at 4\n",
      "val_losses[-1] = 0.0006144800572656095, best_loss = 0.0006148208049125969, model saved at 5\n",
      "val_losses[-1] = 0.0006128228851594031, best_loss = 0.0006144800572656095, model saved at 6\n",
      "val_losses[-1] = 0.0006117315497249365, best_loss = 0.0006128228851594031, model saved at 7\n",
      "val_losses[-1] = 0.0006115416181273758, best_loss = 0.0006117315497249365, model saved at 8\n",
      "val_losses[-1] = 0.0006108449888415635, best_loss = 0.0006115416181273758, model saved at 9\n",
      "val_losses[-1] = 0.0006106205401010811, best_loss = 0.0006108449888415635, model saved at 10\n",
      "val_losses[-1] = 0.0006101198960095644, best_loss = 0.0006106205401010811, model saved at 11\n",
      "val_losses[-1] = 0.000609224836807698, best_loss = 0.0006101198960095644, model saved at 12\n",
      "val_losses[-1] = 0.0006089661037549376, best_loss = 0.000609224836807698, model saved at 13\n",
      "val_losses[-1] = 0.0006082322215661407, best_loss = 0.0006089661037549376, model saved at 16\n",
      "val_losses[-1] = 0.0006081341998651624, best_loss = 0.0006082322215661407, model saved at 19\n",
      "val_losses[-1] = 0.0006078050937503576, best_loss = 0.0006081341998651624, model saved at 23\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006440440192818642, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006337905069813132, best_loss = 0.0006440440192818642, model saved at 1\n",
      "val_losses[-1] = 0.0006326314760372043, best_loss = 0.0006337905069813132, model saved at 2\n",
      "val_losses[-1] = 0.0006262153037823737, best_loss = 0.0006326314760372043, model saved at 4\n",
      "val_losses[-1] = 0.0006250138394534588, best_loss = 0.0006262153037823737, model saved at 5\n",
      "val_losses[-1] = 0.0006241117371246219, best_loss = 0.0006250138394534588, model saved at 7\n",
      "val_losses[-1] = 0.0006234601023606956, best_loss = 0.0006241117371246219, model saved at 8\n",
      "val_losses[-1] = 0.0006234223255887628, best_loss = 0.0006234601023606956, model saved at 9\n",
      "val_losses[-1] = 0.0006233665044419467, best_loss = 0.0006234223255887628, model saved at 10\n",
      "val_losses[-1] = 0.0006233335006982088, best_loss = 0.0006233665044419467, model saved at 11\n",
      "val_losses[-1] = 0.0002715612936299294, best_loss = 0.0006233335006982088, model saved at 15\n",
      "val_losses[-1] = 0.00020414564642123878, best_loss = 0.0002715612936299294, model saved at 16\n",
      "val_losses[-1] = 0.0001988757139770314, best_loss = 0.00020414564642123878, model saved at 18\n",
      "val_losses[-1] = 0.000198201640159823, best_loss = 0.0001988757139770314, model saved at 19\n",
      "val_losses[-1] = 0.00019609383889473975, best_loss = 0.000198201640159823, model saved at 21\n",
      "val_losses[-1] = 0.00019349399372003973, best_loss = 0.00019609383889473975, model saved at 23\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006154055590741336, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006045515183359385, best_loss = 0.0006154055590741336, model saved at 2\n",
      "val_losses[-1] = 0.0005979700945317745, best_loss = 0.0006045515183359385, model saved at 3\n",
      "val_losses[-1] = 0.0005879378295503557, best_loss = 0.0005979700945317745, model saved at 4\n",
      "val_losses[-1] = 0.0005853195325471461, best_loss = 0.0005879378295503557, model saved at 5\n",
      "val_losses[-1] = 0.0005796290934085846, best_loss = 0.0005853195325471461, model saved at 6\n",
      "val_losses[-1] = 0.0005763021763414145, best_loss = 0.0005796290934085846, model saved at 8\n",
      "val_losses[-1] = 0.0005751937278546393, best_loss = 0.0005763021763414145, model saved at 9\n",
      "val_losses[-1] = 0.0005723377107642591, best_loss = 0.0005751937278546393, model saved at 14\n",
      "val_losses[-1] = 0.0005719605251215398, best_loss = 0.0005723377107642591, model saved at 17\n",
      "val_losses[-1] = 0.0005688237142749131, best_loss = 0.0005719605251215398, model saved at 19\n",
      "val_losses[-1] = 0.0005680520553141832, best_loss = 0.0005688237142749131, model saved at 21\n",
      "val_losses[-1] = 0.0005669551319442689, best_loss = 0.0005680520553141832, model saved at 23\n",
      "val_losses[-1] = 0.0003904631594195962, best_loss = 0.0005669551319442689, model saved at 25\n",
      "val_losses[-1] = 0.00024651255807839334, best_loss = 0.0003904631594195962, model saved at 26\n",
      "val_losses[-1] = 0.00022630186867900193, best_loss = 0.00024651255807839334, model saved at 27\n",
      "val_losses[-1] = 0.00022588054707739502, best_loss = 0.00022630186867900193, model saved at 28\n",
      "val_losses[-1] = 0.0002125515602529049, best_loss = 0.00022588054707739502, model saved at 29\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0008816496701911092, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006610348937101662, best_loss = 0.0008816496701911092, model saved at 1\n",
      "val_losses[-1] = 0.0006600467604584992, best_loss = 0.0006610348937101662, model saved at 2\n",
      "val_losses[-1] = 0.0005960278795100749, best_loss = 0.0006600467604584992, model saved at 3\n",
      "val_losses[-1] = 0.0005828799330629408, best_loss = 0.0005960278795100749, model saved at 4\n",
      "val_losses[-1] = 0.0005681058391928673, best_loss = 0.0005828799330629408, model saved at 5\n",
      "val_losses[-1] = 0.0003853407397400588, best_loss = 0.0005681058391928673, model saved at 6\n",
      "val_losses[-1] = 0.00023167842300608754, best_loss = 0.0003853407397400588, model saved at 7\n",
      "val_losses[-1] = 0.00020780536578968167, best_loss = 0.00023167842300608754, model saved at 8\n",
      "val_losses[-1] = 0.0002042160922428593, best_loss = 0.00020780536578968167, model saved at 9\n",
      "val_losses[-1] = 0.0002025134745053947, best_loss = 0.0002042160922428593, model saved at 10\n",
      "val_losses[-1] = 0.00019985776452813298, best_loss = 0.0002025134745053947, model saved at 11\n",
      "val_losses[-1] = 0.00019786077609751374, best_loss = 0.00019985776452813298, model saved at 12\n",
      "val_losses[-1] = 0.00019163619435857981, best_loss = 0.00019786077609751374, model saved at 14\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006602429202757776, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006118238670751452, best_loss = 0.0006602429202757776, model saved at 1\n",
      "val_losses[-1] = 0.0004948084824718535, best_loss = 0.0006118238670751452, model saved at 2\n",
      "val_losses[-1] = 0.00023734138812869787, best_loss = 0.0004948084824718535, model saved at 3\n",
      "val_losses[-1] = 0.00021104498591739684, best_loss = 0.00023734138812869787, model saved at 4\n",
      "val_losses[-1] = 0.0002061427221633494, best_loss = 0.00021104498591739684, model saved at 6\n",
      "val_losses[-1] = 0.00020344048971310258, best_loss = 0.0002061427221633494, model saved at 7\n",
      "val_losses[-1] = 0.00019754107051994652, best_loss = 0.00020344048971310258, model saved at 8\n",
      "val_losses[-1] = 0.00019525746756698936, best_loss = 0.00019754107051994652, model saved at 10\n",
      "val_losses[-1] = 0.00019123520178254694, best_loss = 0.00019525746756698936, model saved at 17\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006264395196922123, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000614178366959095, best_loss = 0.0006264395196922123, model saved at 1\n",
      "val_losses[-1] = 0.0006053746910765767, best_loss = 0.000614178366959095, model saved at 2\n",
      "val_losses[-1] = 0.0005954132648184896, best_loss = 0.0006053746910765767, model saved at 3\n",
      "val_losses[-1] = 0.0005869491724297404, best_loss = 0.0005954132648184896, model saved at 4\n",
      "val_losses[-1] = 0.000582443957682699, best_loss = 0.0005869491724297404, model saved at 5\n",
      "val_losses[-1] = 0.0005773680750280619, best_loss = 0.000582443957682699, model saved at 6\n",
      "val_losses[-1] = 0.0002499138645362109, best_loss = 0.0005773680750280619, model saved at 7\n",
      "val_losses[-1] = 0.00020079282694496214, best_loss = 0.0002499138645362109, model saved at 8\n",
      "val_losses[-1] = 0.00019190301827620715, best_loss = 0.00020079282694496214, model saved at 13\n",
      "val_losses[-1] = 0.00018868748156819493, best_loss = 0.00019190301827620715, model saved at 18\n",
      "val_losses[-1] = 0.00018572862609289587, best_loss = 0.00018868748156819493, model saved at 28\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006288534495979548, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006206505349837244, best_loss = 0.0006288534495979548, model saved at 1\n",
      "val_losses[-1] = 0.0006125988438725471, best_loss = 0.0006206505349837244, model saved at 3\n",
      "val_losses[-1] = 0.0006031079683452845, best_loss = 0.0006125988438725471, model saved at 4\n",
      "val_losses[-1] = 0.0005945101147517562, best_loss = 0.0006031079683452845, model saved at 5\n",
      "val_losses[-1] = 0.0005817022174596786, best_loss = 0.0005945101147517562, model saved at 6\n",
      "val_losses[-1] = 0.0005740773631259799, best_loss = 0.0005817022174596786, model saved at 7\n",
      "val_losses[-1] = 0.0005422804970294237, best_loss = 0.0005740773631259799, model saved at 8\n",
      "val_losses[-1] = 0.0005031217006035149, best_loss = 0.0005422804970294237, model saved at 9\n",
      "val_losses[-1] = 0.0004249835037626326, best_loss = 0.0005031217006035149, model saved at 10\n",
      "val_losses[-1] = 0.00011898165394086391, best_loss = 0.0004249835037626326, model saved at 11\n",
      "val_losses[-1] = 0.0001085637413780205, best_loss = 0.00011898165394086391, model saved at 12\n",
      "val_losses[-1] = 0.00010090580326505005, best_loss = 0.0001085637413780205, model saved at 13\n",
      "val_losses[-1] = 9.775205398909748e-05, best_loss = 0.00010090580326505005, model saved at 20\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006247294368222356, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006147777894511819, best_loss = 0.0006247294368222356, model saved at 1\n",
      "val_losses[-1] = 0.0001775971904862672, best_loss = 0.0006147777894511819, model saved at 2\n",
      "val_losses[-1] = 0.00011157769768033177, best_loss = 0.0001775971904862672, model saved at 3\n",
      "val_losses[-1] = 0.00010216749797109514, best_loss = 0.00011157769768033177, model saved at 4\n",
      "val_losses[-1] = 0.00010177813965128735, best_loss = 0.00010216749797109514, model saved at 26\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0006928889779374003, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005734259029850364, best_loss = 0.0006928889779374003, model saved at 1\n",
      "val_losses[-1] = 0.0005297561874613166, best_loss = 0.0005734259029850364, model saved at 2\n",
      "val_losses[-1] = 0.0005059235845692456, best_loss = 0.0005297561874613166, model saved at 3\n",
      "val_losses[-1] = 0.00026329499087296426, best_loss = 0.0005059235845692456, model saved at 4\n",
      "val_losses[-1] = 0.00012429215712472796, best_loss = 0.00026329499087296426, model saved at 5\n",
      "val_losses[-1] = 0.00011730814003385603, best_loss = 0.00012429215712472796, model saved at 6\n",
      "val_losses[-1] = 0.00011465205898275599, best_loss = 0.00011730814003385603, model saved at 7\n",
      "val_losses[-1] = 0.00011294741125311702, best_loss = 0.00011465205898275599, model saved at 8\n",
      "val_losses[-1] = 0.00010893854778259993, best_loss = 0.00011294741125311702, model saved at 10\n",
      "val_losses[-1] = 0.00010787758947117254, best_loss = 0.00010893854778259993, model saved at 13\n",
      "val_losses[-1] = 0.00010459133773110807, best_loss = 0.00010787758947117254, model saved at 14\n",
      "val_losses[-1] = 0.00010421843762742355, best_loss = 0.00010459133773110807, model saved at 16\n",
      "val_losses[-1] = 0.00010325913171982393, best_loss = 0.00010421843762742355, model saved at 17\n",
      "val_losses[-1] = 0.00010210114123765379, best_loss = 0.00010325913171982393, model saved at 19\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006299205124378204, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005739791668020189, best_loss = 0.0006299205124378204, model saved at 1\n",
      "val_losses[-1] = 0.0002101474383380264, best_loss = 0.0005739791668020189, model saved at 2\n",
      "val_losses[-1] = 0.00012644293019548059, best_loss = 0.0002101474383380264, model saved at 3\n",
      "val_losses[-1] = 0.00011562200234038755, best_loss = 0.00012644293019548059, model saved at 5\n",
      "val_losses[-1] = 0.00010939108324237168, best_loss = 0.00011562200234038755, model saved at 6\n",
      "val_losses[-1] = 0.00010877003660425544, best_loss = 0.00010939108324237168, model saved at 9\n",
      "val_losses[-1] = 0.00010784575715661049, best_loss = 0.00010877003660425544, model saved at 11\n",
      "val_losses[-1] = 0.00010672988719306886, best_loss = 0.00010784575715661049, model saved at 12\n",
      "val_losses[-1] = 0.00010597120126476511, best_loss = 0.00010672988719306886, model saved at 14\n",
      "val_losses[-1] = 0.00010302790178684518, best_loss = 0.00010597120126476511, model saved at 15\n",
      "val_losses[-1] = 0.0001025411911541596, best_loss = 0.00010302790178684518, model saved at 16\n",
      "val_losses[-1] = 0.00010171258327318355, best_loss = 0.0001025411911541596, model saved at 18\n",
      "val_losses[-1] = 9.842278086580336e-05, best_loss = 0.00010171258327318355, model saved at 20\n",
      "iter 4...\n",
      "val_losses[-1] = 0.00061983079649508, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006004007300361991, best_loss = 0.00061983079649508, model saved at 1\n",
      "val_losses[-1] = 0.0005953012150712311, best_loss = 0.0006004007300361991, model saved at 2\n",
      "val_losses[-1] = 0.0005901145632378757, best_loss = 0.0005953012150712311, model saved at 3\n",
      "val_losses[-1] = 0.0005785389803349972, best_loss = 0.0005901145632378757, model saved at 4\n",
      "val_losses[-1] = 0.0005638364818878472, best_loss = 0.0005785389803349972, model saved at 5\n",
      "val_losses[-1] = 0.0005471933400258422, best_loss = 0.0005638364818878472, model saved at 6\n",
      "val_losses[-1] = 0.00012082445755368099, best_loss = 0.0005471933400258422, model saved at 7\n",
      "val_losses[-1] = 0.00010657227539923042, best_loss = 0.00012082445755368099, model saved at 8\n",
      "val_losses[-1] = 0.00010189633758272976, best_loss = 0.00010657227539923042, model saved at 10\n",
      "val_losses[-1] = 0.00010130166629096493, best_loss = 0.00010189633758272976, model saved at 11\n",
      "val_losses[-1] = 9.532904368825257e-05, best_loss = 0.00010130166629096493, model saved at 21\n",
      "(0.6, 0.4)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006240662187337875, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006219343049451709, best_loss = 0.0006240662187337875, model saved at 2\n",
      "val_losses[-1] = 0.0006209622952155769, best_loss = 0.0006219343049451709, model saved at 3\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0007470205309800804, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006307094590738416, best_loss = 0.0007470205309800804, model saved at 1\n",
      "val_losses[-1] = 0.000619251630268991, best_loss = 0.0006307094590738416, model saved at 2\n",
      "val_losses[-1] = 0.0006153133581392467, best_loss = 0.000619251630268991, model saved at 3\n",
      "val_losses[-1] = 0.0006150635308586061, best_loss = 0.0006153133581392467, model saved at 4\n",
      "val_losses[-1] = 0.0006146191735751927, best_loss = 0.0006150635308586061, model saved at 5\n",
      "val_losses[-1] = 0.0006142813363112509, best_loss = 0.0006146191735751927, model saved at 17\n",
      "val_losses[-1] = 0.0006117554730735719, best_loss = 0.0006142813363112509, model saved at 18\n",
      "val_losses[-1] = 0.0005896775401197374, best_loss = 0.0006117554730735719, model saved at 19\n",
      "val_losses[-1] = 0.0005646032514050603, best_loss = 0.0005896775401197374, model saved at 20\n",
      "val_losses[-1] = 0.0005390436854213476, best_loss = 0.0005646032514050603, model saved at 21\n",
      "val_losses[-1] = 0.0005218202713876963, best_loss = 0.0005390436854213476, model saved at 22\n",
      "val_losses[-1] = 0.000512793892994523, best_loss = 0.0005218202713876963, model saved at 23\n",
      "val_losses[-1] = 0.0005056894151493907, best_loss = 0.000512793892994523, model saved at 24\n",
      "val_losses[-1] = 0.0005015552160330117, best_loss = 0.0005056894151493907, model saved at 25\n",
      "val_losses[-1] = 0.0005010176100768149, best_loss = 0.0005015552160330117, model saved at 26\n",
      "val_losses[-1] = 0.000496661348734051, best_loss = 0.0005010176100768149, model saved at 27\n",
      "val_losses[-1] = 0.0004956322954967618, best_loss = 0.000496661348734051, model saved at 29\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0006991256377659738, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000633321818895638, best_loss = 0.0006991256377659738, model saved at 1\n",
      "val_losses[-1] = 0.0006170497508719563, best_loss = 0.000633321818895638, model saved at 2\n",
      "val_losses[-1] = 0.000610887713264674, best_loss = 0.0006170497508719563, model saved at 3\n",
      "val_losses[-1] = 0.0006080170278437436, best_loss = 0.000610887713264674, model saved at 4\n",
      "val_losses[-1] = 0.0006077406578697264, best_loss = 0.0006080170278437436, model saved at 6\n",
      "val_losses[-1] = 0.0006039097788743675, best_loss = 0.0006077406578697264, model saved at 7\n",
      "val_losses[-1] = 0.0006014688406139612, best_loss = 0.0006039097788743675, model saved at 8\n",
      "val_losses[-1] = 0.0005995930405333638, best_loss = 0.0006014688406139612, model saved at 10\n",
      "val_losses[-1] = 0.0005984429153613746, best_loss = 0.0005995930405333638, model saved at 12\n",
      "val_losses[-1] = 0.0005979126435704529, best_loss = 0.0005984429153613746, model saved at 13\n",
      "val_losses[-1] = 0.0005978525150567293, best_loss = 0.0005979126435704529, model saved at 14\n",
      "val_losses[-1] = 0.0005966438911855221, best_loss = 0.0005978525150567293, model saved at 20\n",
      "val_losses[-1] = 0.0005712733836844563, best_loss = 0.0005966438911855221, model saved at 21\n",
      "val_losses[-1] = 0.0005461992113851011, best_loss = 0.0005712733836844563, model saved at 22\n",
      "val_losses[-1] = 0.0005373944295570254, best_loss = 0.0005461992113851011, model saved at 23\n",
      "val_losses[-1] = 0.0005276369047351182, best_loss = 0.0005373944295570254, model saved at 24\n",
      "val_losses[-1] = 0.0005204118206165731, best_loss = 0.0005276369047351182, model saved at 25\n",
      "val_losses[-1] = 0.0005130866775289178, best_loss = 0.0005204118206165731, model saved at 26\n",
      "val_losses[-1] = 0.0005026650032959878, best_loss = 0.0005130866775289178, model saved at 27\n",
      "val_losses[-1] = 0.0005003276746720076, best_loss = 0.0005026650032959878, model saved at 28\n",
      "val_losses[-1] = 0.0004972872557118535, best_loss = 0.0005003276746720076, model saved at 29\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006202555377967656, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005771786672994494, best_loss = 0.0006202555377967656, model saved at 1\n",
      "val_losses[-1] = 0.00053286028560251, best_loss = 0.0005771786672994494, model saved at 2\n",
      "val_losses[-1] = 0.0005082322168163955, best_loss = 0.00053286028560251, model saved at 3\n",
      "val_losses[-1] = 0.0004991382011212409, best_loss = 0.0005082322168163955, model saved at 4\n",
      "val_losses[-1] = 0.00048826690181158483, best_loss = 0.0004991382011212409, model saved at 5\n",
      "val_losses[-1] = 0.0004861183406319469, best_loss = 0.00048826690181158483, model saved at 7\n",
      "val_losses[-1] = 0.00048441626131534576, best_loss = 0.0004861183406319469, model saved at 10\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006251066806726158, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006195894675329328, best_loss = 0.0006251066806726158, model saved at 1\n",
      "val_losses[-1] = 0.0006157067837193608, best_loss = 0.0006195894675329328, model saved at 2\n",
      "val_losses[-1] = 0.0006113409181125462, best_loss = 0.0006157067837193608, model saved at 3\n",
      "val_losses[-1] = 0.0006083620246499777, best_loss = 0.0006113409181125462, model saved at 5\n",
      "val_losses[-1] = 0.0006068155635148287, best_loss = 0.0006083620246499777, model saved at 7\n",
      "val_losses[-1] = 0.0006058759172447026, best_loss = 0.0006068155635148287, model saved at 8\n",
      "val_losses[-1] = 0.00060532201314345, best_loss = 0.0006058759172447026, model saved at 9\n",
      "val_losses[-1] = 0.0006043465691618621, best_loss = 0.00060532201314345, model saved at 10\n",
      "val_losses[-1] = 0.00060431839665398, best_loss = 0.0006043465691618621, model saved at 11\n",
      "val_losses[-1] = 0.0006040834123268723, best_loss = 0.00060431839665398, model saved at 12\n",
      "val_losses[-1] = 0.0006032124510966241, best_loss = 0.0006040834123268723, model saved at 13\n",
      "val_losses[-1] = 0.0006026827613823116, best_loss = 0.0006032124510966241, model saved at 15\n",
      "val_losses[-1] = 0.0006020495784468949, best_loss = 0.0006026827613823116, model saved at 16\n",
      "val_losses[-1] = 0.000601958716288209, best_loss = 0.0006020495784468949, model saved at 18\n",
      "val_losses[-1] = 0.0006017218111082911, best_loss = 0.000601958716288209, model saved at 20\n",
      "val_losses[-1] = 0.0006009366479702294, best_loss = 0.0006017218111082911, model saved at 26\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006327427108772099, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006210602587088943, best_loss = 0.0006327427108772099, model saved at 2\n",
      "val_losses[-1] = 0.0006203934317454696, best_loss = 0.0006210602587088943, model saved at 4\n",
      "val_losses[-1] = 0.0006187482504174113, best_loss = 0.0006203934317454696, model saved at 10\n",
      "val_losses[-1] = 0.0006093096453696489, best_loss = 0.0006187482504174113, model saved at 11\n",
      "val_losses[-1] = 0.0006002496229484677, best_loss = 0.0006093096453696489, model saved at 12\n",
      "val_losses[-1] = 0.0005845577688887715, best_loss = 0.0006002496229484677, model saved at 13\n",
      "val_losses[-1] = 0.0005838921060785651, best_loss = 0.0005845577688887715, model saved at 14\n",
      "val_losses[-1] = 0.0005716492305509746, best_loss = 0.0005838921060785651, model saved at 15\n",
      "val_losses[-1] = 0.0005670433165505528, best_loss = 0.0005716492305509746, model saved at 16\n",
      "val_losses[-1] = 0.0005657252622768283, best_loss = 0.0005670433165505528, model saved at 17\n",
      "val_losses[-1] = 0.0005621235468424857, best_loss = 0.0005657252622768283, model saved at 18\n",
      "val_losses[-1] = 0.0005594776594080031, best_loss = 0.0005621235468424857, model saved at 19\n",
      "val_losses[-1] = 0.0005583579768426716, best_loss = 0.0005594776594080031, model saved at 20\n",
      "val_losses[-1] = 0.0005562473670579493, best_loss = 0.0005583579768426716, model saved at 22\n",
      "val_losses[-1] = 0.0005535889067687094, best_loss = 0.0005562473670579493, model saved at 25\n",
      "val_losses[-1] = 0.0005531319184228778, best_loss = 0.0005535889067687094, model saved at 26\n",
      "val_losses[-1] = 0.00047752211685292423, best_loss = 0.0005531319184228778, model saved at 27\n",
      "val_losses[-1] = 0.0002233933482784778, best_loss = 0.00047752211685292423, model saved at 28\n",
      "val_losses[-1] = 0.00019280014385003597, best_loss = 0.0002233933482784778, model saved at 29\n",
      "iter 1...\n",
      "val_losses[-1] = 0.000628993206191808, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005960541311651468, best_loss = 0.000628993206191808, model saved at 1\n",
      "val_losses[-1] = 0.00020148388284724206, best_loss = 0.0005960541311651468, model saved at 2\n",
      "val_losses[-1] = 0.0001866129314294085, best_loss = 0.00020148388284724206, model saved at 3\n",
      "val_losses[-1] = 0.00017584397573955357, best_loss = 0.0001866129314294085, model saved at 4\n",
      "val_losses[-1] = 0.00017373285663779825, best_loss = 0.00017584397573955357, model saved at 5\n",
      "val_losses[-1] = 0.0001654941588640213, best_loss = 0.00017373285663779825, model saved at 8\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007565771811641753, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006261886446736753, best_loss = 0.0007565771811641753, model saved at 1\n",
      "val_losses[-1] = 0.0006029008072800934, best_loss = 0.0006261886446736753, model saved at 2\n",
      "val_losses[-1] = 0.0005812648450955749, best_loss = 0.0006029008072800934, model saved at 3\n",
      "val_losses[-1] = 0.0005672150873579085, best_loss = 0.0005812648450955749, model saved at 4\n",
      "val_losses[-1] = 0.0004659809928853065, best_loss = 0.0005672150873579085, model saved at 5\n",
      "val_losses[-1] = 0.0002159602881874889, best_loss = 0.0004659809928853065, model saved at 6\n",
      "val_losses[-1] = 0.00018629491387400776, best_loss = 0.0002159602881874889, model saved at 7\n",
      "val_losses[-1] = 0.00017716425645630807, best_loss = 0.00018629491387400776, model saved at 8\n",
      "val_losses[-1] = 0.00017559398838784546, best_loss = 0.00017716425645630807, model saved at 10\n",
      "val_losses[-1] = 0.00017091947665903717, best_loss = 0.00017559398838784546, model saved at 11\n",
      "val_losses[-1] = 0.00016384929767809808, best_loss = 0.00017091947665903717, model saved at 14\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006257081404328346, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005959493573755026, best_loss = 0.0006257081404328346, model saved at 1\n",
      "val_losses[-1] = 0.0005937633686698973, best_loss = 0.0005959493573755026, model saved at 2\n",
      "val_losses[-1] = 0.0005878843949176371, best_loss = 0.0005937633686698973, model saved at 3\n",
      "val_losses[-1] = 0.0005798244965262711, best_loss = 0.0005878843949176371, model saved at 4\n",
      "val_losses[-1] = 0.000574059842620045, best_loss = 0.0005798244965262711, model saved at 5\n",
      "val_losses[-1] = 0.0002808659919537604, best_loss = 0.000574059842620045, model saved at 7\n",
      "val_losses[-1] = 0.00019257907115388662, best_loss = 0.0002808659919537604, model saved at 8\n",
      "val_losses[-1] = 0.0001859979674918577, best_loss = 0.00019257907115388662, model saved at 11\n",
      "val_losses[-1] = 0.00018429964256938547, best_loss = 0.0001859979674918577, model saved at 12\n",
      "val_losses[-1] = 0.00018308991275262088, best_loss = 0.00018429964256938547, model saved at 13\n",
      "val_losses[-1] = 0.00017756149463821203, best_loss = 0.00018308991275262088, model saved at 15\n",
      "val_losses[-1] = 0.00017320325423497707, best_loss = 0.00017756149463821203, model saved at 17\n",
      "val_losses[-1] = 0.00017098418902605772, best_loss = 0.00017320325423497707, model saved at 21\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006197142065502703, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006042191525921226, best_loss = 0.0006197142065502703, model saved at 1\n",
      "val_losses[-1] = 0.0005782982334494591, best_loss = 0.0006042191525921226, model saved at 2\n",
      "val_losses[-1] = 0.0002852137840818614, best_loss = 0.0005782982334494591, model saved at 3\n",
      "val_losses[-1] = 0.0002130631182808429, best_loss = 0.0002852137840818614, model saved at 4\n",
      "val_losses[-1] = 0.00017952497000806034, best_loss = 0.0002130631182808429, model saved at 5\n",
      "val_losses[-1] = 0.00017484906129539013, best_loss = 0.00017952497000806034, model saved at 7\n",
      "val_losses[-1] = 0.00016770375077612698, best_loss = 0.00017484906129539013, model saved at 8\n",
      "val_losses[-1] = 0.00016461215273011476, best_loss = 0.00016770375077612698, model saved at 18\n",
      "val_losses[-1] = 0.0001631319464650005, best_loss = 0.00016461215273011476, model saved at 27\n",
      "val_losses[-1] = 0.00016094930469989777, best_loss = 0.0001631319464650005, model saved at 28\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006533943233080208, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005832987953908741, best_loss = 0.0006533943233080208, model saved at 1\n",
      "val_losses[-1] = 0.0001158246086561121, best_loss = 0.0005832987953908741, model saved at 2\n",
      "val_losses[-1] = 9.357943781651556e-05, best_loss = 0.0001158246086561121, model saved at 3\n",
      "val_losses[-1] = 8.839052316034213e-05, best_loss = 9.357943781651556e-05, model saved at 7\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006196836475282907, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00017633284733165056, best_loss = 0.0006196836475282907, model saved at 1\n",
      "val_losses[-1] = 9.858788689598441e-05, best_loss = 0.00017633284733165056, model saved at 2\n",
      "val_losses[-1] = 8.929888281272724e-05, best_loss = 9.858788689598441e-05, model saved at 4\n",
      "val_losses[-1] = 8.890804019756615e-05, best_loss = 8.929888281272724e-05, model saved at 8\n",
      "iter 2...\n",
      "val_losses[-1] = 0.000735817477107048, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0007172440527938306, best_loss = 0.000735817477107048, model saved at 1\n",
      "val_losses[-1] = 0.0005348824779503047, best_loss = 0.0007172440527938306, model saved at 2\n",
      "val_losses[-1] = 0.0005197140271775424, best_loss = 0.0005348824779503047, model saved at 3\n",
      "val_losses[-1] = 0.00019651791080832481, best_loss = 0.0005197140271775424, model saved at 4\n",
      "val_losses[-1] = 0.00011480040848255157, best_loss = 0.00019651791080832481, model saved at 5\n",
      "val_losses[-1] = 0.00010852652485482395, best_loss = 0.00011480040848255157, model saved at 6\n",
      "val_losses[-1] = 0.00010496083268662915, best_loss = 0.00010852652485482395, model saved at 8\n",
      "val_losses[-1] = 9.979382593883201e-05, best_loss = 0.00010496083268662915, model saved at 10\n",
      "val_losses[-1] = 9.812945063458756e-05, best_loss = 9.979382593883201e-05, model saved at 11\n",
      "val_losses[-1] = 9.146437514573336e-05, best_loss = 9.812945063458756e-05, model saved at 14\n",
      "val_losses[-1] = 8.949619223130867e-05, best_loss = 9.146437514573336e-05, model saved at 16\n",
      "val_losses[-1] = 8.872295438777655e-05, best_loss = 8.949619223130867e-05, model saved at 24\n",
      "val_losses[-1] = 8.867099677445367e-05, best_loss = 8.872295438777655e-05, model saved at 28\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006218781345523894, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00011879646626766771, best_loss = 0.0006218781345523894, model saved at 1\n",
      "val_losses[-1] = 0.00010409126116428524, best_loss = 0.00011879646626766771, model saved at 2\n",
      "val_losses[-1] = 9.57587908487767e-05, best_loss = 0.00010409126116428524, model saved at 3\n",
      "val_losses[-1] = 9.372192289447412e-05, best_loss = 9.57587908487767e-05, model saved at 9\n",
      "val_losses[-1] = 9.363504068460315e-05, best_loss = 9.372192289447412e-05, model saved at 18\n",
      "val_losses[-1] = 9.036128903971985e-05, best_loss = 9.363504068460315e-05, model saved at 20\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006119862664490938, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005940090049989522, best_loss = 0.0006119862664490938, model saved at 1\n",
      "val_losses[-1] = 0.000578106555622071, best_loss = 0.0005940090049989522, model saved at 2\n",
      "val_losses[-1] = 0.000565147667657584, best_loss = 0.000578106555622071, model saved at 3\n",
      "val_losses[-1] = 0.0005606227787211537, best_loss = 0.000565147667657584, model saved at 4\n",
      "val_losses[-1] = 0.0005432226462289691, best_loss = 0.0005606227787211537, model saved at 5\n",
      "val_losses[-1] = 0.0001337988069280982, best_loss = 0.0005432226462289691, model saved at 6\n",
      "val_losses[-1] = 0.00010415560973342508, best_loss = 0.0001337988069280982, model saved at 7\n",
      "val_losses[-1] = 9.747850708663464e-05, best_loss = 0.00010415560973342508, model saved at 8\n",
      "val_losses[-1] = 9.720314847072586e-05, best_loss = 9.747850708663464e-05, model saved at 9\n",
      "val_losses[-1] = 9.610391134629026e-05, best_loss = 9.720314847072586e-05, model saved at 10\n",
      "val_losses[-1] = 9.561344631947577e-05, best_loss = 9.610391134629026e-05, model saved at 11\n",
      "val_losses[-1] = 9.378548566019163e-05, best_loss = 9.561344631947577e-05, model saved at 12\n",
      "val_losses[-1] = 9.221467189490795e-05, best_loss = 9.378548566019163e-05, model saved at 18\n",
      "val_losses[-1] = 8.629252261016518e-05, best_loss = 9.221467189490795e-05, model saved at 21\n",
      "(0.7, 0.3)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006308731390163302, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006167117971926928, best_loss = 0.0006308731390163302, model saved at 1\n",
      "val_losses[-1] = 0.0006144170765765011, best_loss = 0.0006167117971926928, model saved at 15\n",
      "val_losses[-1] = 0.0006092352559790015, best_loss = 0.0006144170765765011, model saved at 16\n",
      "val_losses[-1] = 0.000596160942222923, best_loss = 0.0006092352559790015, model saved at 17\n",
      "val_losses[-1] = 0.0005705463117919862, best_loss = 0.000596160942222923, model saved at 18\n",
      "val_losses[-1] = 0.0005385581171140075, best_loss = 0.0005705463117919862, model saved at 19\n",
      "val_losses[-1] = 0.00051450589671731, best_loss = 0.0005385581171140075, model saved at 20\n",
      "val_losses[-1] = 0.0004984510596841574, best_loss = 0.00051450589671731, model saved at 21\n",
      "val_losses[-1] = 0.0004849403921980411, best_loss = 0.0004984510596841574, model saved at 22\n",
      "val_losses[-1] = 0.0004836216976400465, best_loss = 0.0004849403921980411, model saved at 23\n",
      "val_losses[-1] = 0.00047375410213135183, best_loss = 0.0004836216976400465, model saved at 24\n",
      "val_losses[-1] = 0.0004685753956437111, best_loss = 0.00047375410213135183, model saved at 25\n",
      "val_losses[-1] = 0.00046693364856764674, best_loss = 0.0004685753956437111, model saved at 29\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006438159616664052, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000575835641939193, best_loss = 0.0006438159616664052, model saved at 1\n",
      "val_losses[-1] = 0.0005136588006280363, best_loss = 0.000575835641939193, model saved at 2\n",
      "val_losses[-1] = 0.0004709769564215094, best_loss = 0.0005136588006280363, model saved at 3\n",
      "val_losses[-1] = 0.00046283897245302796, best_loss = 0.0004709769564215094, model saved at 4\n",
      "val_losses[-1] = 0.00045529784983955324, best_loss = 0.00046283897245302796, model saved at 5\n",
      "val_losses[-1] = 0.000440361414803192, best_loss = 0.00045529784983955324, model saved at 6\n",
      "val_losses[-1] = 0.0004382311599329114, best_loss = 0.000440361414803192, model saved at 9\n",
      "val_losses[-1] = 0.0004354460397735238, best_loss = 0.0004382311599329114, model saved at 12\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007162836845964193, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006359356339089572, best_loss = 0.0007162836845964193, model saved at 1\n",
      "val_losses[-1] = 0.0006283008260652423, best_loss = 0.0006359356339089572, model saved at 2\n",
      "val_losses[-1] = 0.0006234600441530347, best_loss = 0.0006283008260652423, model saved at 3\n",
      "val_losses[-1] = 0.0006077534635551274, best_loss = 0.0006234600441530347, model saved at 4\n",
      "val_losses[-1] = 0.0006010776851326227, best_loss = 0.0006077534635551274, model saved at 5\n",
      "val_losses[-1] = 0.0005989776109345257, best_loss = 0.0006010776851326227, model saved at 6\n",
      "val_losses[-1] = 0.0005957780522294343, best_loss = 0.0005989776109345257, model saved at 7\n",
      "val_losses[-1] = 0.000592411495745182, best_loss = 0.0005957780522294343, model saved at 8\n",
      "val_losses[-1] = 0.0005856253555975854, best_loss = 0.000592411495745182, model saved at 9\n",
      "val_losses[-1] = 0.0005412311875261366, best_loss = 0.0005856253555975854, model saved at 10\n",
      "val_losses[-1] = 0.0004991975147277117, best_loss = 0.0005412311875261366, model saved at 11\n",
      "val_losses[-1] = 0.0004773632390424609, best_loss = 0.0004991975147277117, model saved at 12\n",
      "val_losses[-1] = 0.00047414403525181115, best_loss = 0.0004773632390424609, model saved at 13\n",
      "val_losses[-1] = 0.000457770744105801, best_loss = 0.00047414403525181115, model saved at 14\n",
      "val_losses[-1] = 0.0004550603625830263, best_loss = 0.000457770744105801, model saved at 15\n",
      "val_losses[-1] = 0.00045400066301226616, best_loss = 0.0004550603625830263, model saved at 17\n",
      "val_losses[-1] = 0.00045378124923445284, best_loss = 0.00045400066301226616, model saved at 18\n",
      "val_losses[-1] = 0.00045016579679213464, best_loss = 0.00045378124923445284, model saved at 20\n",
      "val_losses[-1] = 0.00044676661491394043, best_loss = 0.00045016579679213464, model saved at 22\n",
      "val_losses[-1] = 0.00044288262142799795, best_loss = 0.00044676661491394043, model saved at 26\n",
      "val_losses[-1] = 0.00044145865831524134, best_loss = 0.00044288262142799795, model saved at 27\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006268547149375081, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005037856171838939, best_loss = 0.0006268547149375081, model saved at 1\n",
      "val_losses[-1] = 0.0005035318899899721, best_loss = 0.0005037856171838939, model saved at 2\n",
      "val_losses[-1] = 0.0004922166117466986, best_loss = 0.0005035318899899721, model saved at 3\n",
      "val_losses[-1] = 0.00046725792344659567, best_loss = 0.0004922166117466986, model saved at 4\n",
      "val_losses[-1] = 0.0004524036485236138, best_loss = 0.00046725792344659567, model saved at 5\n",
      "val_losses[-1] = 0.00044735308620147407, best_loss = 0.0004524036485236138, model saved at 7\n",
      "val_losses[-1] = 0.0004469998530112207, best_loss = 0.00044735308620147407, model saved at 8\n",
      "val_losses[-1] = 0.0004441372584551573, best_loss = 0.0004469998530112207, model saved at 9\n",
      "val_losses[-1] = 0.00043754911166615784, best_loss = 0.0004441372584551573, model saved at 10\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006228796555660665, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006133901770226657, best_loss = 0.0006228796555660665, model saved at 1\n",
      "val_losses[-1] = 0.0006103970226831734, best_loss = 0.0006133901770226657, model saved at 2\n",
      "val_losses[-1] = 0.000607621856033802, best_loss = 0.0006103970226831734, model saved at 3\n",
      "val_losses[-1] = 0.0006054783007130027, best_loss = 0.000607621856033802, model saved at 5\n",
      "val_losses[-1] = 0.0006045202608220279, best_loss = 0.0006054783007130027, model saved at 6\n",
      "val_losses[-1] = 0.0006027830531820655, best_loss = 0.0006045202608220279, model saved at 7\n",
      "val_losses[-1] = 0.0006012751837261021, best_loss = 0.0006027830531820655, model saved at 10\n",
      "val_losses[-1] = 0.00060009810840711, best_loss = 0.0006012751837261021, model saved at 13\n",
      "val_losses[-1] = 0.0005965814925730228, best_loss = 0.00060009810840711, model saved at 15\n",
      "val_losses[-1] = 0.0005744675290770829, best_loss = 0.0005965814925730228, model saved at 16\n",
      "val_losses[-1] = 0.0005325211677700281, best_loss = 0.0005744675290770829, model saved at 17\n",
      "val_losses[-1] = 0.0004944585962221026, best_loss = 0.0005325211677700281, model saved at 18\n",
      "val_losses[-1] = 0.00048635207349434495, best_loss = 0.0004944585962221026, model saved at 19\n",
      "val_losses[-1] = 0.00046747465967200696, best_loss = 0.00048635207349434495, model saved at 20\n",
      "val_losses[-1] = 0.0004560124652925879, best_loss = 0.00046747465967200696, model saved at 22\n",
      "val_losses[-1] = 0.0004543340764939785, best_loss = 0.0004560124652925879, model saved at 23\n",
      "val_losses[-1] = 0.0004498017951846123, best_loss = 0.0004543340764939785, model saved at 24\n",
      "val_losses[-1] = 0.00044520964729599655, best_loss = 0.0004498017951846123, model saved at 26\n",
      "val_losses[-1] = 0.0004436805611476302, best_loss = 0.00044520964729599655, model saved at 27\n",
      "val_losses[-1] = 0.0004334173572715372, best_loss = 0.0004436805611476302, model saved at 28\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.000627063331194222, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006249493453651667, best_loss = 0.000627063331194222, model saved at 1\n",
      "val_losses[-1] = 0.0006239159847609699, best_loss = 0.0006249493453651667, model saved at 2\n",
      "val_losses[-1] = 0.0006237438647076488, best_loss = 0.0006239159847609699, model saved at 3\n",
      "val_losses[-1] = 0.0006236189510673285, best_loss = 0.0006237438647076488, model saved at 4\n",
      "val_losses[-1] = 0.0006234873435460031, best_loss = 0.0006236189510673285, model saved at 5\n",
      "val_losses[-1] = 0.0006161024793982506, best_loss = 0.0006234873435460031, model saved at 7\n",
      "val_losses[-1] = 0.0005213385447859764, best_loss = 0.0006161024793982506, model saved at 8\n",
      "val_losses[-1] = 0.00019119690114166588, best_loss = 0.0005213385447859764, model saved at 9\n",
      "val_losses[-1] = 0.00017181099974550307, best_loss = 0.00019119690114166588, model saved at 10\n",
      "val_losses[-1] = 0.0001676806714385748, best_loss = 0.00017181099974550307, model saved at 11\n",
      "val_losses[-1] = 0.00015916890697553754, best_loss = 0.0001676806714385748, model saved at 12\n",
      "val_losses[-1] = 0.00015795923536643386, best_loss = 0.00015916890697553754, model saved at 16\n",
      "val_losses[-1] = 0.0001564742560731247, best_loss = 0.00015795923536643386, model saved at 18\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006163464859127998, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005977372638881207, best_loss = 0.0006163464859127998, model saved at 1\n",
      "val_losses[-1] = 0.00020484189735725522, best_loss = 0.0005977372638881207, model saved at 2\n",
      "val_losses[-1] = 0.0001737210841383785, best_loss = 0.00020484189735725522, model saved at 3\n",
      "val_losses[-1] = 0.0001686188334133476, best_loss = 0.0001737210841383785, model saved at 4\n",
      "val_losses[-1] = 0.00016305598546750844, best_loss = 0.0001686188334133476, model saved at 5\n",
      "val_losses[-1] = 0.00016095186583697796, best_loss = 0.00016305598546750844, model saved at 7\n",
      "val_losses[-1] = 0.00015240185894072056, best_loss = 0.00016095186583697796, model saved at 8\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007252770010381937, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006369263282977045, best_loss = 0.0007252770010381937, model saved at 1\n",
      "val_losses[-1] = 0.0005856037023477256, best_loss = 0.0006369263282977045, model saved at 2\n",
      "val_losses[-1] = 0.0005687754601240158, best_loss = 0.0005856037023477256, model saved at 3\n",
      "val_losses[-1] = 0.00021853613725397736, best_loss = 0.0005687754601240158, model saved at 4\n",
      "val_losses[-1] = 0.00019111484289169312, best_loss = 0.00021853613725397736, model saved at 5\n",
      "val_losses[-1] = 0.00016958323249127716, best_loss = 0.00019111484289169312, model saved at 6\n",
      "val_losses[-1] = 0.00016797854914329946, best_loss = 0.00016958323249127716, model saved at 7\n",
      "val_losses[-1] = 0.00016724321176297963, best_loss = 0.00016797854914329946, model saved at 9\n",
      "val_losses[-1] = 0.00016346586926374584, best_loss = 0.00016724321176297963, model saved at 10\n",
      "val_losses[-1] = 0.00015715956396888942, best_loss = 0.00016346586926374584, model saved at 11\n",
      "val_losses[-1] = 0.00015410338528454304, best_loss = 0.00015715956396888942, model saved at 14\n",
      "val_losses[-1] = 0.00015326302673202008, best_loss = 0.00015410338528454304, model saved at 15\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006197555339895189, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00019943361985497177, best_loss = 0.0006197555339895189, model saved at 1\n",
      "val_losses[-1] = 0.0001677252002991736, best_loss = 0.00019943361985497177, model saved at 2\n",
      "val_losses[-1] = 0.00016649991448502988, best_loss = 0.0001677252002991736, model saved at 3\n",
      "val_losses[-1] = 0.00016221975965891033, best_loss = 0.00016649991448502988, model saved at 4\n",
      "val_losses[-1] = 0.00014762244245503098, best_loss = 0.00016221975965891033, model saved at 5\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006137001910246909, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005969629855826497, best_loss = 0.0006137001910246909, model saved at 1\n",
      "val_losses[-1] = 0.0005875731003470719, best_loss = 0.0005969629855826497, model saved at 2\n",
      "val_losses[-1] = 0.0002766895922832191, best_loss = 0.0005875731003470719, model saved at 3\n",
      "val_losses[-1] = 0.0001804868661565706, best_loss = 0.0002766895922832191, model saved at 4\n",
      "val_losses[-1] = 0.00016143426182679832, best_loss = 0.0001804868661565706, model saved at 5\n",
      "val_losses[-1] = 0.00015615703887306154, best_loss = 0.00016143426182679832, model saved at 8\n",
      "val_losses[-1] = 0.00015397548850160092, best_loss = 0.00015615703887306154, model saved at 18\n",
      "val_losses[-1] = 0.00015024669119156897, best_loss = 0.00015397548850160092, model saved at 27\n",
      "val_losses[-1] = 0.00014732705312781036, best_loss = 0.00015024669119156897, model saved at 28\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006342650740407407, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005728252581320703, best_loss = 0.0006342650740407407, model saved at 1\n",
      "val_losses[-1] = 0.00010372569522587582, best_loss = 0.0005728252581320703, model saved at 2\n",
      "val_losses[-1] = 8.602864545537159e-05, best_loss = 0.00010372569522587582, model saved at 3\n",
      "val_losses[-1] = 8.339507621712983e-05, best_loss = 8.602864545537159e-05, model saved at 7\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006410466157831252, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00059785001212731, best_loss = 0.0006410466157831252, model saved at 1\n",
      "val_losses[-1] = 0.0005721533671021461, best_loss = 0.00059785001212731, model saved at 2\n",
      "val_losses[-1] = 0.0005389918806031346, best_loss = 0.0005721533671021461, model saved at 3\n",
      "val_losses[-1] = 0.0005253971903584898, best_loss = 0.0005389918806031346, model saved at 4\n",
      "val_losses[-1] = 0.000453938206192106, best_loss = 0.0005253971903584898, model saved at 5\n",
      "val_losses[-1] = 0.00010173561167903244, best_loss = 0.000453938206192106, model saved at 6\n",
      "val_losses[-1] = 9.353982022730634e-05, best_loss = 0.00010173561167903244, model saved at 7\n",
      "val_losses[-1] = 9.315110219176859e-05, best_loss = 9.353982022730634e-05, model saved at 8\n",
      "val_losses[-1] = 9.128442616201937e-05, best_loss = 9.315110219176859e-05, model saved at 10\n",
      "val_losses[-1] = 8.839778456604108e-05, best_loss = 9.128442616201937e-05, model saved at 15\n",
      "val_losses[-1] = 8.6606691183988e-05, best_loss = 8.839778456604108e-05, model saved at 25\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0006971692200750113, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005412157042883337, best_loss = 0.0006971692200750113, model saved at 1\n",
      "val_losses[-1] = 0.000497270084451884, best_loss = 0.0005412157042883337, model saved at 2\n",
      "val_losses[-1] = 0.0004807792429346591, best_loss = 0.000497270084451884, model saved at 3\n",
      "val_losses[-1] = 0.00024992137332446873, best_loss = 0.0004807792429346591, model saved at 4\n",
      "val_losses[-1] = 0.00010319789726054296, best_loss = 0.00024992137332446873, model saved at 5\n",
      "val_losses[-1] = 9.370706538902596e-05, best_loss = 0.00010319789726054296, model saved at 7\n",
      "val_losses[-1] = 9.245412365999073e-05, best_loss = 9.370706538902596e-05, model saved at 10\n",
      "val_losses[-1] = 8.68179413373582e-05, best_loss = 9.245412365999073e-05, model saved at 11\n",
      "val_losses[-1] = 8.673227421240881e-05, best_loss = 8.68179413373582e-05, model saved at 17\n",
      "iter 3...\n",
      "val_losses[-1] = 0.00063178880373016, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000616823264863342, best_loss = 0.00063178880373016, model saved at 1\n",
      "val_losses[-1] = 0.0006085879867896438, best_loss = 0.000616823264863342, model saved at 5\n",
      "val_losses[-1] = 0.00021562787878792733, best_loss = 0.0006085879867896438, model saved at 6\n",
      "val_losses[-1] = 0.00010013718565460294, best_loss = 0.00021562787878792733, model saved at 7\n",
      "val_losses[-1] = 8.884688577381894e-05, best_loss = 0.00010013718565460294, model saved at 8\n",
      "val_losses[-1] = 8.367480768356472e-05, best_loss = 8.884688577381894e-05, model saved at 9\n",
      "val_losses[-1] = 8.298357715830207e-05, best_loss = 8.367480768356472e-05, model saved at 16\n",
      "val_losses[-1] = 7.99119079601951e-05, best_loss = 8.298357715830207e-05, model saved at 20\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006044500041753054, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005694690044037998, best_loss = 0.0006044500041753054, model saved at 1\n",
      "val_losses[-1] = 0.0003433101228438318, best_loss = 0.0005694690044037998, model saved at 2\n",
      "val_losses[-1] = 9.499896987108514e-05, best_loss = 0.0003433101228438318, model saved at 3\n",
      "val_losses[-1] = 9.450200013816357e-05, best_loss = 9.499896987108514e-05, model saved at 4\n",
      "val_losses[-1] = 8.468433225061744e-05, best_loss = 9.450200013816357e-05, model saved at 5\n",
      "val_losses[-1] = 8.423753024544567e-05, best_loss = 8.468433225061744e-05, model saved at 14\n",
      "val_losses[-1] = 8.05250383564271e-05, best_loss = 8.423753024544567e-05, model saved at 21\n",
      "(0.8, 0.2)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006446390179917216, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006230523576959968, best_loss = 0.0006446390179917216, model saved at 1\n",
      "val_losses[-1] = 0.000622911611571908, best_loss = 0.0006230523576959968, model saved at 3\n",
      "val_losses[-1] = 0.0005962389404885471, best_loss = 0.000622911611571908, model saved at 4\n",
      "val_losses[-1] = 0.0005482094129547477, best_loss = 0.0005962389404885471, model saved at 5\n",
      "val_losses[-1] = 0.000483721902128309, best_loss = 0.0005482094129547477, model saved at 6\n",
      "val_losses[-1] = 0.0004346961504779756, best_loss = 0.000483721902128309, model saved at 7\n",
      "val_losses[-1] = 0.0004139007651247084, best_loss = 0.0004346961504779756, model saved at 8\n",
      "val_losses[-1] = 0.00040688994340598583, best_loss = 0.0004139007651247084, model saved at 11\n",
      "val_losses[-1] = 0.000398370495531708, best_loss = 0.00040688994340598583, model saved at 12\n",
      "val_losses[-1] = 0.00039706623647361994, best_loss = 0.000398370495531708, model saved at 15\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006230763392522931, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006050508236512542, best_loss = 0.0006230763392522931, model saved at 1\n",
      "val_losses[-1] = 0.00048407280701212585, best_loss = 0.0006050508236512542, model saved at 2\n",
      "val_losses[-1] = 0.00044897376210428774, best_loss = 0.00048407280701212585, model saved at 3\n",
      "val_losses[-1] = 0.0004373436968307942, best_loss = 0.00044897376210428774, model saved at 4\n",
      "val_losses[-1] = 0.0004261483554728329, best_loss = 0.0004373436968307942, model saved at 5\n",
      "val_losses[-1] = 0.00042000634130090475, best_loss = 0.0004261483554728329, model saved at 6\n",
      "val_losses[-1] = 0.00040654867189005017, best_loss = 0.00042000634130090475, model saved at 7\n",
      "val_losses[-1] = 0.00040082773193717003, best_loss = 0.00040654867189005017, model saved at 9\n",
      "val_losses[-1] = 0.0003996036248281598, best_loss = 0.00040082773193717003, model saved at 13\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0006498960428871214, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000628907058853656, best_loss = 0.0006498960428871214, model saved at 1\n",
      "val_losses[-1] = 0.0006066484493203461, best_loss = 0.000628907058853656, model saved at 2\n",
      "val_losses[-1] = 0.0006055622943677008, best_loss = 0.0006066484493203461, model saved at 3\n",
      "val_losses[-1] = 0.0005995379760861397, best_loss = 0.0006055622943677008, model saved at 4\n",
      "val_losses[-1] = 0.0005971668870188296, best_loss = 0.0005995379760861397, model saved at 5\n",
      "val_losses[-1] = 0.0005963140283711255, best_loss = 0.0005971668870188296, model saved at 6\n",
      "val_losses[-1] = 0.0005942711140960455, best_loss = 0.0005963140283711255, model saved at 7\n",
      "val_losses[-1] = 0.0005889774765819311, best_loss = 0.0005942711140960455, model saved at 8\n",
      "val_losses[-1] = 0.0005876604118384421, best_loss = 0.0005889774765819311, model saved at 9\n",
      "val_losses[-1] = 0.0005838057841174304, best_loss = 0.0005876604118384421, model saved at 10\n",
      "val_losses[-1] = 0.0005816793418489397, best_loss = 0.0005838057841174304, model saved at 11\n",
      "val_losses[-1] = 0.0005750152631662786, best_loss = 0.0005816793418489397, model saved at 12\n",
      "val_losses[-1] = 0.000548989453818649, best_loss = 0.0005750152631662786, model saved at 13\n",
      "val_losses[-1] = 0.0004865250666625798, best_loss = 0.000548989453818649, model saved at 14\n",
      "val_losses[-1] = 0.0004482047806959599, best_loss = 0.0004865250666625798, model saved at 15\n",
      "val_losses[-1] = 0.00043920057942159474, best_loss = 0.0004482047806959599, model saved at 16\n",
      "val_losses[-1] = 0.0004289254720788449, best_loss = 0.00043920057942159474, model saved at 17\n",
      "val_losses[-1] = 0.00042880058754235506, best_loss = 0.0004289254720788449, model saved at 18\n",
      "val_losses[-1] = 0.0004192858177702874, best_loss = 0.00042880058754235506, model saved at 20\n",
      "val_losses[-1] = 0.0004150965833105147, best_loss = 0.0004192858177702874, model saved at 22\n",
      "val_losses[-1] = 0.0004144588892813772, best_loss = 0.0004150965833105147, model saved at 24\n",
      "val_losses[-1] = 0.0004137983778491616, best_loss = 0.0004144588892813772, model saved at 25\n",
      "val_losses[-1] = 0.0004135502385906875, best_loss = 0.0004137983778491616, model saved at 26\n",
      "val_losses[-1] = 0.0004079531063325703, best_loss = 0.0004135502385906875, model saved at 27\n",
      "val_losses[-1] = 0.00040696494397707283, best_loss = 0.0004079531063325703, model saved at 28\n",
      "val_losses[-1] = 0.00040312152123078704, best_loss = 0.00040696494397707283, model saved at 29\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0005445963470265269, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00046179292257875204, best_loss = 0.0005445963470265269, model saved at 1\n",
      "val_losses[-1] = 0.0004434314905665815, best_loss = 0.00046179292257875204, model saved at 2\n",
      "val_losses[-1] = 0.0004247264005243778, best_loss = 0.0004434314905665815, model saved at 3\n",
      "val_losses[-1] = 0.0004155985952820629, best_loss = 0.0004247264005243778, model saved at 4\n",
      "val_losses[-1] = 0.0004103417741134763, best_loss = 0.0004155985952820629, model saved at 5\n",
      "val_losses[-1] = 0.00040516775334253907, best_loss = 0.0004103417741134763, model saved at 7\n",
      "val_losses[-1] = 0.0003988720418419689, best_loss = 0.00040516775334253907, model saved at 10\n",
      "val_losses[-1] = 0.00039783204556442797, best_loss = 0.0003988720418419689, model saved at 21\n",
      "val_losses[-1] = 0.0003973545099142939, best_loss = 0.00039783204556442797, model saved at 29\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006180654163472354, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006116346339695156, best_loss = 0.0006180654163472354, model saved at 1\n",
      "val_losses[-1] = 0.000608484260737896, best_loss = 0.0006116346339695156, model saved at 2\n",
      "val_losses[-1] = 0.0006064908229745924, best_loss = 0.000608484260737896, model saved at 3\n",
      "val_losses[-1] = 0.0006026516202837229, best_loss = 0.0006064908229745924, model saved at 4\n",
      "val_losses[-1] = 0.0006017754785716534, best_loss = 0.0006026516202837229, model saved at 5\n",
      "val_losses[-1] = 0.0005988088669255376, best_loss = 0.0006017754785716534, model saved at 6\n",
      "val_losses[-1] = 0.0005983952432870865, best_loss = 0.0005988088669255376, model saved at 7\n",
      "val_losses[-1] = 0.0005929058534093201, best_loss = 0.0005983952432870865, model saved at 8\n",
      "val_losses[-1] = 0.00056894012959674, best_loss = 0.0005929058534093201, model saved at 9\n",
      "val_losses[-1] = 0.00049925921484828, best_loss = 0.00056894012959674, model saved at 10\n",
      "val_losses[-1] = 0.0004510183644015342, best_loss = 0.00049925921484828, model saved at 11\n",
      "val_losses[-1] = 0.0004287668562028557, best_loss = 0.0004510183644015342, model saved at 12\n",
      "val_losses[-1] = 0.0004279267741367221, best_loss = 0.0004287668562028557, model saved at 13\n",
      "val_losses[-1] = 0.0004270094505045563, best_loss = 0.0004279267741367221, model saved at 14\n",
      "val_losses[-1] = 0.0004167506122030318, best_loss = 0.0004270094505045563, model saved at 15\n",
      "val_losses[-1] = 0.0004139836528338492, best_loss = 0.0004167506122030318, model saved at 16\n",
      "val_losses[-1] = 0.0004132943577133119, best_loss = 0.0004139836528338492, model saved at 18\n",
      "val_losses[-1] = 0.0004131683672312647, best_loss = 0.0004132943577133119, model saved at 23\n",
      "val_losses[-1] = 0.0004085643740836531, best_loss = 0.0004131683672312647, model saved at 24\n",
      "val_losses[-1] = 0.0004028841794934124, best_loss = 0.0004085643740836531, model saved at 28\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006329460302367806, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006123960483819246, best_loss = 0.0006329460302367806, model saved at 1\n",
      "val_losses[-1] = 0.0006106647779233754, best_loss = 0.0006123960483819246, model saved at 2\n",
      "val_losses[-1] = 0.0005986755131743848, best_loss = 0.0006106647779233754, model saved at 3\n",
      "val_losses[-1] = 0.000565546506550163, best_loss = 0.0005986755131743848, model saved at 4\n",
      "val_losses[-1] = 0.00018383070710115135, best_loss = 0.000565546506550163, model saved at 5\n",
      "val_losses[-1] = 0.0001539824006613344, best_loss = 0.00018383070710115135, model saved at 6\n",
      "val_losses[-1] = 0.00015157024608924985, best_loss = 0.0001539824006613344, model saved at 7\n",
      "val_losses[-1] = 0.00014645489864051342, best_loss = 0.00015157024608924985, model saved at 12\n",
      "val_losses[-1] = 0.00014283067139331251, best_loss = 0.00014645489864051342, model saved at 18\n",
      "iter 1...\n",
      "val_losses[-1] = 0.00062280532438308, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005939938127994537, best_loss = 0.00062280532438308, model saved at 1\n",
      "val_losses[-1] = 0.0005735423183068633, best_loss = 0.0005939938127994537, model saved at 2\n",
      "val_losses[-1] = 0.0005513152573257685, best_loss = 0.0005735423183068633, model saved at 3\n",
      "val_losses[-1] = 0.0005150463548488915, best_loss = 0.0005513152573257685, model saved at 4\n",
      "val_losses[-1] = 0.0001729724754113704, best_loss = 0.0005150463548488915, model saved at 5\n",
      "val_losses[-1] = 0.00016171738388948143, best_loss = 0.0001729724754113704, model saved at 6\n",
      "val_losses[-1] = 0.00015397484821733087, best_loss = 0.00016171738388948143, model saved at 7\n",
      "val_losses[-1] = 0.0001422355999238789, best_loss = 0.00015397484821733087, model saved at 8\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0006898849387653172, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005880518001504242, best_loss = 0.0006898849387653172, model saved at 1\n",
      "val_losses[-1] = 0.0005677574663423002, best_loss = 0.0005880518001504242, model saved at 2\n",
      "val_losses[-1] = 0.0005544482846744359, best_loss = 0.0005677574663423002, model saved at 3\n",
      "val_losses[-1] = 0.0005396935739554465, best_loss = 0.0005544482846744359, model saved at 4\n",
      "val_losses[-1] = 0.0005264637293294072, best_loss = 0.0005396935739554465, model saved at 6\n",
      "val_losses[-1] = 0.0005210248054936528, best_loss = 0.0005264637293294072, model saved at 7\n",
      "val_losses[-1] = 0.00018687288684304804, best_loss = 0.0005210248054936528, model saved at 8\n",
      "val_losses[-1] = 0.0001613191852811724, best_loss = 0.00018687288684304804, model saved at 9\n",
      "val_losses[-1] = 0.0001566370774526149, best_loss = 0.0001613191852811724, model saved at 10\n",
      "val_losses[-1] = 0.00014973845100030303, best_loss = 0.0001566370774526149, model saved at 11\n",
      "val_losses[-1] = 0.0001442831999156624, best_loss = 0.00014973845100030303, model saved at 14\n",
      "val_losses[-1] = 0.00014375067257788032, best_loss = 0.0001442831999156624, model saved at 15\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006281535024754703, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00021870828641112894, best_loss = 0.0006281535024754703, model saved at 1\n",
      "val_losses[-1] = 0.00015186397649813443, best_loss = 0.00021870828641112894, model saved at 2\n",
      "val_losses[-1] = 0.00014705583453178406, best_loss = 0.00015186397649813443, model saved at 8\n",
      "val_losses[-1] = 0.00014538039977196604, best_loss = 0.00014705583453178406, model saved at 11\n",
      "val_losses[-1] = 0.00014161714352667332, best_loss = 0.00014538039977196604, model saved at 17\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0005022240802645683, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00017665726772975177, best_loss = 0.0005022240802645683, model saved at 1\n",
      "val_losses[-1] = 0.00015535492275375873, best_loss = 0.00017665726772975177, model saved at 2\n",
      "val_losses[-1] = 0.00015053294191602618, best_loss = 0.00015535492275375873, model saved at 3\n",
      "val_losses[-1] = 0.0001478858757764101, best_loss = 0.00015053294191602618, model saved at 7\n",
      "val_losses[-1] = 0.0001416686864104122, best_loss = 0.0001478858757764101, model saved at 8\n",
      "val_losses[-1] = 0.0001394867431372404, best_loss = 0.0001416686864104122, model saved at 28\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006599901244044304, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.000626902561634779, best_loss = 0.0006599901244044304, model saved at 1\n",
      "val_losses[-1] = 0.0006228784914128482, best_loss = 0.000626902561634779, model saved at 2\n",
      "val_losses[-1] = 0.0006040849257260561, best_loss = 0.0006228784914128482, model saved at 3\n",
      "val_losses[-1] = 9.924451296683401e-05, best_loss = 0.0006040849257260561, model saved at 4\n",
      "val_losses[-1] = 8.731627895031124e-05, best_loss = 9.924451296683401e-05, model saved at 5\n",
      "val_losses[-1] = 8.195370173780248e-05, best_loss = 8.731627895031124e-05, model saved at 7\n",
      "val_losses[-1] = 8.065643487498164e-05, best_loss = 8.195370173780248e-05, model saved at 13\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006070713279768825, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005499001126736403, best_loss = 0.0006070713279768825, model saved at 1\n",
      "val_losses[-1] = 0.0005256544682197273, best_loss = 0.0005499001126736403, model saved at 2\n",
      "val_losses[-1] = 0.00013315232354216278, best_loss = 0.0005256544682197273, model saved at 3\n",
      "val_losses[-1] = 9.092044638236985e-05, best_loss = 0.00013315232354216278, model saved at 4\n",
      "val_losses[-1] = 8.977477409644052e-05, best_loss = 9.092044638236985e-05, model saved at 8\n",
      "val_losses[-1] = 8.869757584761828e-05, best_loss = 8.977477409644052e-05, model saved at 12\n",
      "val_losses[-1] = 8.393973985221237e-05, best_loss = 8.869757584761828e-05, model saved at 15\n",
      "val_losses[-1] = 8.030838216654956e-05, best_loss = 8.393973985221237e-05, model saved at 25\n",
      "iter 2...\n",
      "val_losses[-1] = 0.000637420394923538, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005735563463531435, best_loss = 0.000637420394923538, model saved at 1\n",
      "val_losses[-1] = 0.0003521982580423355, best_loss = 0.0005735563463531435, model saved at 2\n",
      "val_losses[-1] = 0.00011070377513533458, best_loss = 0.0003521982580423355, model saved at 3\n",
      "val_losses[-1] = 0.00010625094000715762, best_loss = 0.00011070377513533458, model saved at 4\n",
      "val_losses[-1] = 9.178483014693484e-05, best_loss = 0.00010625094000715762, model saved at 5\n",
      "val_losses[-1] = 8.912029443308711e-05, best_loss = 9.178483014693484e-05, model saved at 7\n",
      "val_losses[-1] = 8.89952716534026e-05, best_loss = 8.912029443308711e-05, model saved at 9\n",
      "val_losses[-1] = 8.836518099997193e-05, best_loss = 8.89952716534026e-05, model saved at 10\n",
      "val_losses[-1] = 8.273975981865078e-05, best_loss = 8.836518099997193e-05, model saved at 11\n",
      "val_losses[-1] = 8.196497947210446e-05, best_loss = 8.273975981865078e-05, model saved at 14\n",
      "val_losses[-1] = 8.01923088147305e-05, best_loss = 8.196497947210446e-05, model saved at 16\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0005013470072299242, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00010167573054786772, best_loss = 0.0005013470072299242, model saved at 1\n",
      "val_losses[-1] = 9.379587572766468e-05, best_loss = 0.00010167573054786772, model saved at 2\n",
      "val_losses[-1] = 9.291760216001421e-05, best_loss = 9.379587572766468e-05, model saved at 3\n",
      "val_losses[-1] = 9.145660442300141e-05, best_loss = 9.291760216001421e-05, model saved at 5\n",
      "val_losses[-1] = 9.020220022648573e-05, best_loss = 9.145660442300141e-05, model saved at 6\n",
      "val_losses[-1] = 9.01771491044201e-05, best_loss = 9.020220022648573e-05, model saved at 7\n",
      "val_losses[-1] = 8.759099728194997e-05, best_loss = 9.01771491044201e-05, model saved at 8\n",
      "val_losses[-1] = 8.562292350688949e-05, best_loss = 8.759099728194997e-05, model saved at 9\n",
      "val_losses[-1] = 8.495675137965009e-05, best_loss = 8.562292350688949e-05, model saved at 15\n",
      "val_losses[-1] = 8.481131953885779e-05, best_loss = 8.495675137965009e-05, model saved at 16\n",
      "val_losses[-1] = 8.05789022706449e-05, best_loss = 8.481131953885779e-05, model saved at 20\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0005645169294439256, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00010264589946018532, best_loss = 0.0005645169294439256, model saved at 1\n",
      "val_losses[-1] = 8.715557487448677e-05, best_loss = 0.00010264589946018532, model saved at 2\n",
      "val_losses[-1] = 8.609722863184288e-05, best_loss = 8.715557487448677e-05, model saved at 3\n",
      "val_losses[-1] = 8.515828812960535e-05, best_loss = 8.609722863184288e-05, model saved at 4\n",
      "val_losses[-1] = 8.026028808671981e-05, best_loss = 8.515828812960535e-05, model saved at 5\n",
      "val_losses[-1] = 7.619921234436333e-05, best_loss = 8.026028808671981e-05, model saved at 21\n",
      "(0.9, 0.1)\n",
      "16\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006526230135932565, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006219222559593618, best_loss = 0.0006526230135932565, model saved at 1\n",
      "val_losses[-1] = 0.0006158220348879695, best_loss = 0.0006219222559593618, model saved at 2\n",
      "val_losses[-1] = 0.0006157098105177283, best_loss = 0.0006158220348879695, model saved at 3\n",
      "val_losses[-1] = 0.0005799946957267821, best_loss = 0.0006157098105177283, model saved at 4\n",
      "val_losses[-1] = 0.0004871436976827681, best_loss = 0.0005799946957267821, model saved at 5\n",
      "val_losses[-1] = 0.0004239424888510257, best_loss = 0.0004871436976827681, model saved at 6\n",
      "val_losses[-1] = 0.00039738137274980545, best_loss = 0.0004239424888510257, model saved at 7\n",
      "val_losses[-1] = 0.0003880168660543859, best_loss = 0.00039738137274980545, model saved at 8\n",
      "val_losses[-1] = 0.00038225730531848967, best_loss = 0.0003880168660543859, model saved at 11\n",
      "val_losses[-1] = 0.0003746499714907259, best_loss = 0.00038225730531848967, model saved at 12\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006201863870956004, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00045066274469718337, best_loss = 0.0006201863870956004, model saved at 1\n",
      "val_losses[-1] = 0.0004204794531688094, best_loss = 0.00045066274469718337, model saved at 2\n",
      "val_losses[-1] = 0.0004146072897128761, best_loss = 0.0004204794531688094, model saved at 6\n",
      "val_losses[-1] = 0.0004130180459469557, best_loss = 0.0004146072897128761, model saved at 7\n",
      "val_losses[-1] = 0.0004053286393173039, best_loss = 0.0004130180459469557, model saved at 8\n",
      "val_losses[-1] = 0.0003900239535141736, best_loss = 0.0004053286393173039, model saved at 9\n",
      "val_losses[-1] = 0.00038037836202420294, best_loss = 0.0003900239535141736, model saved at 13\n",
      "val_losses[-1] = 0.0003782806161325425, best_loss = 0.00038037836202420294, model saved at 19\n",
      "val_losses[-1] = 0.0003745643771253526, best_loss = 0.0003782806161325425, model saved at 22\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0007084545795805752, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0007020615739747882, best_loss = 0.0007084545795805752, model saved at 1\n",
      "val_losses[-1] = 0.0006215296452865005, best_loss = 0.0007020615739747882, model saved at 2\n",
      "val_losses[-1] = 0.0006140395416878164, best_loss = 0.0006215296452865005, model saved at 3\n",
      "val_losses[-1] = 0.0005952778155915439, best_loss = 0.0006140395416878164, model saved at 4\n",
      "val_losses[-1] = 0.0005555745447054505, best_loss = 0.0005952778155915439, model saved at 5\n",
      "val_losses[-1] = 0.0004977952921763062, best_loss = 0.0005555745447054505, model saved at 6\n",
      "val_losses[-1] = 0.0004402948834467679, best_loss = 0.0004977952921763062, model saved at 7\n",
      "val_losses[-1] = 0.00041274382965639234, best_loss = 0.0004402948834467679, model saved at 8\n",
      "val_losses[-1] = 0.00039662260678596795, best_loss = 0.00041274382965639234, model saved at 9\n",
      "val_losses[-1] = 0.00037954127765260637, best_loss = 0.00039662260678596795, model saved at 10\n",
      "val_losses[-1] = 0.00037756055826321244, best_loss = 0.00037954127765260637, model saved at 14\n",
      "val_losses[-1] = 0.00037740691914223135, best_loss = 0.00037756055826321244, model saved at 25\n",
      "val_losses[-1] = 0.0003750185715034604, best_loss = 0.00037740691914223135, model saved at 26\n",
      "val_losses[-1] = 0.00037234544288367033, best_loss = 0.0003750185715034604, model saved at 27\n",
      "iter 3...\n",
      "val_losses[-1] = 0.0006101616891101003, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005591961671598256, best_loss = 0.0006101616891101003, model saved at 1\n",
      "val_losses[-1] = 0.000436309608630836, best_loss = 0.0005591961671598256, model saved at 2\n",
      "val_losses[-1] = 0.0004103258834220469, best_loss = 0.000436309608630836, model saved at 3\n",
      "val_losses[-1] = 0.0003922542091459036, best_loss = 0.0004103258834220469, model saved at 4\n",
      "val_losses[-1] = 0.00039138717693276703, best_loss = 0.0003922542091459036, model saved at 7\n",
      "val_losses[-1] = 0.00038788540405221283, best_loss = 0.00039138717693276703, model saved at 9\n",
      "val_losses[-1] = 0.00038761066389270127, best_loss = 0.00038788540405221283, model saved at 10\n",
      "val_losses[-1] = 0.00038586510345339775, best_loss = 0.00038761066389270127, model saved at 16\n",
      "val_losses[-1] = 0.0003834296949207783, best_loss = 0.00038586510345339775, model saved at 21\n",
      "val_losses[-1] = 0.00038114882772788405, best_loss = 0.0003834296949207783, model saved at 29\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0006172875291667879, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006155594019219279, best_loss = 0.0006172875291667879, model saved at 1\n",
      "val_losses[-1] = 0.0006095348508097231, best_loss = 0.0006155594019219279, model saved at 2\n",
      "val_losses[-1] = 0.0005198097787797451, best_loss = 0.0006095348508097231, model saved at 3\n",
      "val_losses[-1] = 0.0004129446460865438, best_loss = 0.0005198097787797451, model saved at 4\n",
      "val_losses[-1] = 0.0003892869863193482, best_loss = 0.0004129446460865438, model saved at 5\n",
      "val_losses[-1] = 0.0003846719046123326, best_loss = 0.0003892869863193482, model saved at 6\n",
      "val_losses[-1] = 0.00038445627433247864, best_loss = 0.0003846719046123326, model saved at 7\n",
      "val_losses[-1] = 0.00037694087950512767, best_loss = 0.00038445627433247864, model saved at 9\n",
      "val_losses[-1] = 0.0003756024525500834, best_loss = 0.00037694087950512767, model saved at 16\n",
      "val_losses[-1] = 0.00037507241358980536, best_loss = 0.0003756024525500834, model saved at 28\n",
      "32\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006342089618556201, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0002233963750768453, best_loss = 0.0006342089618556201, model saved at 2\n",
      "val_losses[-1] = 0.0001477140176575631, best_loss = 0.0002233963750768453, model saved at 3\n",
      "val_losses[-1] = 0.00014531063789036125, best_loss = 0.0001477140176575631, model saved at 4\n",
      "val_losses[-1] = 0.0001374389394186437, best_loss = 0.00014531063789036125, model saved at 6\n",
      "val_losses[-1] = 0.00013616537034977227, best_loss = 0.0001374389394186437, model saved at 18\n",
      "val_losses[-1] = 0.00013587223656941205, best_loss = 0.00013616537034977227, model saved at 27\n",
      "iter 1...\n",
      "val_losses[-1] = 0.0006205094396136701, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0005935993394814432, best_loss = 0.0006205094396136701, model saved at 1\n",
      "val_losses[-1] = 0.00015828877803869545, best_loss = 0.0005935993394814432, model saved at 2\n",
      "val_losses[-1] = 0.00014407560229301453, best_loss = 0.00015828877803869545, model saved at 3\n",
      "val_losses[-1] = 0.00013822629989590496, best_loss = 0.00014407560229301453, model saved at 5\n",
      "val_losses[-1] = 0.0001353880943497643, best_loss = 0.00013822629989590496, model saved at 7\n",
      "val_losses[-1] = 0.00012856791727244854, best_loss = 0.0001353880943497643, model saved at 8\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0006760571268387139, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006262962124310434, best_loss = 0.0006760571268387139, model saved at 1\n",
      "val_losses[-1] = 0.0004660501144826412, best_loss = 0.0006262962124310434, model saved at 2\n",
      "val_losses[-1] = 0.00019828318909276277, best_loss = 0.0004660501144826412, model saved at 3\n",
      "val_losses[-1] = 0.00016778529970906675, best_loss = 0.00019828318909276277, model saved at 4\n",
      "val_losses[-1] = 0.00015506635827478021, best_loss = 0.00016778529970906675, model saved at 5\n",
      "val_losses[-1] = 0.0001469947019359097, best_loss = 0.00015506635827478021, model saved at 6\n",
      "val_losses[-1] = 0.0001449590636184439, best_loss = 0.0001469947019359097, model saved at 7\n",
      "val_losses[-1] = 0.00014178136189002544, best_loss = 0.0001449590636184439, model saved at 8\n",
      "val_losses[-1] = 0.00014021208335179836, best_loss = 0.00014178136189002544, model saved at 9\n",
      "val_losses[-1] = 0.00013814961130265146, best_loss = 0.00014021208335179836, model saved at 10\n",
      "val_losses[-1] = 0.00013409857638180256, best_loss = 0.00013814961130265146, model saved at 11\n",
      "val_losses[-1] = 0.00013332626258488744, best_loss = 0.00013409857638180256, model saved at 15\n",
      "iter 3...\n",
      "val_losses[-1] = 0.00021924872999079525, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00015287124551832676, best_loss = 0.00021924872999079525, model saved at 1\n",
      "val_losses[-1] = 0.00014879829541314393, best_loss = 0.00015287124551832676, model saved at 2\n",
      "val_losses[-1] = 0.00014828717394266278, best_loss = 0.00014879829541314393, model saved at 3\n",
      "val_losses[-1] = 0.00014362232468556613, best_loss = 0.00014828717394266278, model saved at 4\n",
      "val_losses[-1] = 0.00013708682672586292, best_loss = 0.00014362232468556613, model saved at 5\n",
      "val_losses[-1] = 0.00013348483480513096, best_loss = 0.00013708682672586292, model saved at 17\n",
      "iter 4...\n",
      "val_losses[-1] = 0.00058497313875705, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00018014266970567405, best_loss = 0.00058497313875705, model saved at 1\n",
      "val_losses[-1] = 0.00015606230590492487, best_loss = 0.00018014266970567405, model saved at 2\n",
      "val_losses[-1] = 0.00014603522140532732, best_loss = 0.00015606230590492487, model saved at 3\n",
      "val_losses[-1] = 0.0001421488559572026, best_loss = 0.00014603522140532732, model saved at 5\n",
      "val_losses[-1] = 0.0001369724195683375, best_loss = 0.0001421488559572026, model saved at 8\n",
      "val_losses[-1] = 0.0001336187415290624, best_loss = 0.0001369724195683375, model saved at 18\n",
      "val_losses[-1] = 0.0001330952363787219, best_loss = 0.0001336187415290624, model saved at 28\n",
      "64\n",
      "iter 0...\n",
      "val_losses[-1] = 0.0006533973501063883, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0006237865309230983, best_loss = 0.0006533973501063883, model saved at 1\n",
      "val_losses[-1] = 0.00012836686801165342, best_loss = 0.0006237865309230983, model saved at 2\n",
      "val_losses[-1] = 8.326371607836336e-05, best_loss = 0.00012836686801165342, model saved at 3\n",
      "val_losses[-1] = 8.063272980507463e-05, best_loss = 8.326371607836336e-05, model saved at 5\n",
      "val_losses[-1] = 7.871781417634338e-05, best_loss = 8.063272980507463e-05, model saved at 7\n",
      "val_losses[-1] = 7.783078035572544e-05, best_loss = 7.871781417634338e-05, model saved at 13\n",
      "iter 1...\n",
      "val_losses[-1] = 0.000622332445345819, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.0002486874000169337, best_loss = 0.000622332445345819, model saved at 1\n",
      "val_losses[-1] = 9.04949483810924e-05, best_loss = 0.0002486874000169337, model saved at 2\n",
      "val_losses[-1] = 8.925098518375307e-05, best_loss = 9.04949483810924e-05, model saved at 3\n",
      "val_losses[-1] = 7.770998490741476e-05, best_loss = 8.925098518375307e-05, model saved at 4\n",
      "iter 2...\n",
      "val_losses[-1] = 0.0006936436984688044, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00014228867075871676, best_loss = 0.0006936436984688044, model saved at 1\n",
      "val_losses[-1] = 9.910506923915818e-05, best_loss = 0.00014228867075871676, model saved at 2\n",
      "val_losses[-1] = 8.991856157081202e-05, best_loss = 9.910506923915818e-05, model saved at 3\n",
      "val_losses[-1] = 8.560565765947104e-05, best_loss = 8.991856157081202e-05, model saved at 5\n",
      "val_losses[-1] = 8.498056558892131e-05, best_loss = 8.560565765947104e-05, model saved at 6\n",
      "val_losses[-1] = 8.373079617740586e-05, best_loss = 8.498056558892131e-05, model saved at 7\n",
      "val_losses[-1] = 7.971042941790074e-05, best_loss = 8.373079617740586e-05, model saved at 11\n",
      "val_losses[-1] = 7.896015449659899e-05, best_loss = 7.971042941790074e-05, model saved at 15\n",
      "val_losses[-1] = 7.818127778591588e-05, best_loss = 7.896015449659899e-05, model saved at 16\n",
      "iter 3...\n",
      "val_losses[-1] = 0.00025506384554319084, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 9.269430302083492e-05, best_loss = 0.00025506384554319084, model saved at 1\n",
      "val_losses[-1] = 8.567154145566747e-05, best_loss = 9.269430302083492e-05, model saved at 2\n",
      "val_losses[-1] = 8.483381679980084e-05, best_loss = 8.567154145566747e-05, model saved at 3\n",
      "val_losses[-1] = 8.441112004220486e-05, best_loss = 8.483381679980084e-05, model saved at 6\n",
      "val_losses[-1] = 8.206633356167004e-05, best_loss = 8.441112004220486e-05, model saved at 9\n",
      "val_losses[-1] = 8.145932224579155e-05, best_loss = 8.206633356167004e-05, model saved at 15\n",
      "val_losses[-1] = 8.103734580799937e-05, best_loss = 8.145932224579155e-05, model saved at 16\n",
      "val_losses[-1] = 7.887321407906711e-05, best_loss = 8.103734580799937e-05, model saved at 18\n",
      "val_losses[-1] = 7.645175355719402e-05, best_loss = 7.887321407906711e-05, model saved at 20\n",
      "iter 4...\n",
      "val_losses[-1] = 0.0005751796998083591, best_loss = inf, model saved at 0\n",
      "val_losses[-1] = 0.00010464796650921926, best_loss = 0.0005751796998083591, model saved at 1\n",
      "val_losses[-1] = 8.695201540831476e-05, best_loss = 0.00010464796650921926, model saved at 2\n",
      "val_losses[-1] = 8.384617103729397e-05, best_loss = 8.695201540831476e-05, model saved at 3\n",
      "val_losses[-1] = 7.74602813180536e-05, best_loss = 8.384617103729397e-05, model saved at 5\n",
      "val_losses[-1] = 7.458505569957197e-05, best_loss = 7.74602813180536e-05, model saved at 21\n"
     ]
    }
   ],
   "source": [
    "for loss_ratios in all_loss_ratios:\n",
    "    print(loss_ratios)\n",
    "    for seq_length in seq_lengths:\n",
    "        print(seq_length)\n",
    "        models = []\n",
    "        for i in range(num_models):\n",
    "            print(f'iter {i}...')\n",
    "            torch.manual_seed(i)\n",
    "\n",
    "            dataset = torch.load(f\"data/mtl_fs_snr_{num_examples}_{seq_length}.pt\")\n",
    "            train_loader = dataset['train_loader']\n",
    "            val_loader = dataset['val_loader']\n",
    "\n",
    "            detector = preamble_detector_mtl()\n",
    "            detector.cuda()\n",
    "\n",
    "            loss_fn_fs = nn.MSELoss()\n",
    "            loss_fn_snr = nn.MSELoss()\n",
    "            optimizer = optim.Adam(detector.parameters(), lr=0.001, weight_decay=0.001)\n",
    "\n",
    "            num_epochs = 30\n",
    "\n",
    "            detector, losses, val_losses, snr_losses, fs_losses = train_mtl(detector, optimizer, train_loader, val_loader, \n",
    "                                                                            loss_fn_fs, loss_fn_snr, num_epochs=num_epochs,\n",
    "                                                                            loss_ratios=loss_ratios)\n",
    "\n",
    "            model_config = {\"weights\": detector.state_dict(),\n",
    "                            \"losses\": losses,\n",
    "                            \"val_losses\": val_losses,\n",
    "                            \"snr_losses\": snr_losses,\n",
    "                            \"fs_losses\": fs_losses}\n",
    "\n",
    "            models.append(model_config)\n",
    "\n",
    "        torch.save(models, f'models/continuous/mtl_fs_snr_{loss_ratios[0]}_{loss_ratios[1]}_{num_examples}_{seq_length}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for loss_ratios in all_loss_ratios:\n",
    "    print(f\"Evaling {loss_ratios}\")\n",
    "    for seq_length in seq_lengths:\n",
    "        print(seq_length)\n",
    "        results = []\n",
    "        for model in torch.load(f'models/continuous/mtl_fs_snr_{loss_ratios[0]}_{loss_ratios[1]}_{num_examples}_{seq_length}.pt'):\n",
    "            detector = preamble_detector_mtl()\n",
    "            detector.load_state_dict(model['weights'])\n",
    "\n",
    "            accs = test_mtl(detector, max_seq[:seq_length], snr_range=snr_range, num_runs=500)\n",
    "\n",
    "            result = {\"accs\": accs,\n",
    "                       \"snr_range\": snr_range,\n",
    "                       \"model\": model}\n",
    "\n",
    "            results.append(result)\n",
    "        torch.save(results, f'results/continuous/mtl_fs_snr_{loss_ratios[0]}_{loss_ratios[1]}_{num_examples}_{seq_length}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
